{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sticky-spencer",
   "metadata": {},
   "source": [
    "# JOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "private-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import gensim\n",
    "import nltk\n",
    "import requests\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup, Tag, NavigableString\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-anthony",
   "metadata": {},
   "source": [
    "## Job Portal - JOBLUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "auburn-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of jobs per category (JOBLUM)\n",
    "def getNumJobs(soup):\n",
    "    NUM_JOBS = soup.find_all('p',{'class':'no-of-jobs'})\n",
    "    NUM_JOBS =  re.findall(r'(?s)(?<= of ).*?(?= jobs)',str(NUM_JOBS[1]))\n",
    "    if NUM_JOBS:\n",
    "        return int(NUM_JOBS[0])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "shared-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the page and parsing HTML data (JOBLUM)\n",
    "def getSoup(JOBLUM_JOB_URL):\n",
    "    page = requests.get(JOBLUM_JOB_URL)\n",
    "    return BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "nonprofit-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find number of pages (JOBLUM)\n",
    "def getNumPages(NUM_JOBS):\n",
    "    return math.ceil(NUM_JOBS/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cross-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the links of each page (JOBLUM)\n",
    "def getLinks(Num_Pages, JOBLUM_URLs):\n",
    "    JOB_LINKS = []\n",
    "    for j in range(1,NUM_PAGES+1):\n",
    "        JOB_LINKS.append(JOBLUM_URLs + str(j))\n",
    "    return JOB_LINKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "illegal-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geting the URLs of each job posting (JOBLUM)\n",
    "def getJobURL(JOBLUM_SOUP):\n",
    "    JOBLUM_JOBS_URL = JOBLUM_SOUP.find_all('div',{'class':'mobile-company-logo hidden-md hidden-lg'})\n",
    "    return re.findall(r'(?s)(?<= href=\").*?(?=\" )',str(JOBLUM_JOBS_URL))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "oriented-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geting the Job Title (JOBLUM)\n",
    "def getJobTitle(JOB_SOUP):\n",
    "    JOB_TITLE = JOB_SOUP.find('h1',{'class':'job-title'})\n",
    "    if JOB_TITLE is not None:\n",
    "        return JOB_TITLE.text.strip()\n",
    "    else:\n",
    "        return \"Not Specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bound-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geting the Job Company (JOBLUM)\n",
    "def getJobCompany(JOB_SOUP):\n",
    "    JOB_COMPANY = JOB_SOUP.find('a',{'class':'job-company-name'})\n",
    "    if JOB_COMPANY is not None:\n",
    "        return JOB_COMPANY.text.strip()\n",
    "    else:\n",
    "        return \"Not Specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "everyday-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geting the Job Location (JOBLUM)\n",
    "def getJobLocation(JOB_SOUP):\n",
    "    JOB_LOCATION = JOB_SOUP.find('span',{'class':'job-company-location'})\n",
    "    if JOB_LOCATION is not None:\n",
    "        return JOB_LOCATION.text.strip()\n",
    "    else:\n",
    "        return \"Not Specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "suitable-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geting Date Posted (JOBLUM)\n",
    "def getDatePosted(JOB_SOUP):\n",
    "    JOB_DATE = JOB_SOUP.find('time',{'itemprop':'datePosted'}).text.strip()\n",
    "    return datetime.strptime(JOB_DATE, '%B %d, %Y').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "available-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geting Job Description (JOBLUM)\n",
    "def getJobDescription(JOB_SOUP):\n",
    "    JOB_INFO = JOB_SOUP.find('span',{'itemprop':'description'})\n",
    "    JOB_INFO_ARRAY = []\n",
    "    for n in range(len(JOB_INFO.contents[1].contents[0])):\n",
    "        if(isinstance(JOB_INFO.contents[1].contents[0].contents[n],NavigableString)):\n",
    "            JOB_INFO_ARRAY.append(JOB_INFO.contents[1].contents[0].contents[n])\n",
    "        else:\n",
    "            for s in range(len(JOB_INFO.contents[1].contents[0].contents[n])):\n",
    "                if(isinstance(JOB_INFO.contents[1].contents[0].contents[n].contents[s], Tag)):\n",
    "                    JOB_INFO_ARRAY.append(JOB_INFO.contents[1].contents[0].contents[n].contents[s].text)\n",
    "                else:\n",
    "                    JOB_INFO_ARRAY.append(JOB_INFO.contents[1].contents[0].contents[n].contents[s])\n",
    "    JOB_DESCRIPTION = ' '.join(JOB_INFO_ARRAY)\n",
    "    JOB_DESCRIPTION = JOB_DESCRIPTION.replace(\"\\xa0\",\" \")\n",
    "    JOB_DESCRIPTION = re.sub(' +', ' ', JOB_DESCRIPTION) \n",
    "    return JOB_DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "nonprofit-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geting Job Salary (JOBLUM)\n",
    "def getJobSalary(JOB_SOUP):\n",
    "    JOB_INFO = JOB_SOUP.find('span',{'itemprop':'description'})\n",
    "    JOB_SALARY_FINDER = JOB_SOUP.find('p',{'class':'job-subinfo'})\n",
    "    JOB_SALARY_ARRAY = re.findall('[0-9]+,[0-9]+',str(JOB_SALARY_FINDER))\n",
    "    JOB_SALARY = \"\"\n",
    "    JOB_SALARY_MIN = \"Not Specified\"\n",
    "    JOB_SALARY_MAX = \"Not Specified\"\n",
    "    JOB_SALARY_CHECKER = re.findall('(?i)Salary',str(JOB_SALARY_FINDER))\n",
    "    if not JOB_SALARY_CHECKER:\n",
    "        JOB_SALARY_CHECKER = re.findall('(?i)Salary',str(JOB_INFO))\n",
    "    if not JOB_SALARY_CHECKER:\n",
    "        JOB_SALARY_CHECKER = re.findall('(?i)PHP',str(JOB_INFO))\n",
    "    if not JOB_SALARY_CHECKER:\n",
    "        JOB_SALARY_CHECKER = re.findall('(?i)pesos',str(JOB_INFO))\n",
    "    if not JOB_SALARY_ARRAY:\n",
    "        JOB_SALARY_ARRAY = re.findall('[0-9]+,[0-9]+',str(JOB_INFO))\n",
    "    if JOB_SALARY_CHECKER:\n",
    "        if (len(JOB_SALARY_ARRAY)==2):\n",
    "            if (int(JOB_SALARY_ARRAY[1].replace(\",\",\"\")) > int(JOB_SALARY_ARRAY[0].replace(\",\",\"\"))):\n",
    "                if (int(JOB_SALARY_ARRAY[1].replace(\",\",\"\")) > 1000):\n",
    "                    JOB_SALARY = '-'.join(JOB_SALARY_ARRAY)\n",
    "                    JOB_SALARY_MIN = JOB_SALARY_ARRAY[0]\n",
    "                    JOB_SALARY_MAX = JOB_SALARY_ARRAY[1]                \n",
    "        elif (len(JOB_SALARY_ARRAY)==1):\n",
    "            JOB_SALARY = JOB_SALARY_ARRAY[0]\n",
    "            JOB_SALARY_MIN = JOB_SALARY_ARRAY[0]\n",
    "            JOB_SALARY_MAX = JOB_SALARY_ARRAY[0]\n",
    "    return JOB_SALARY, JOB_SALARY_MIN, JOB_SALARY_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "orange-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geting Job Type (JOBLUM)\n",
    "def getJobType(JOB_SOUP):\n",
    "    JOB_INFO = JOB_SOUP.find('div',{'class':'col-sm-8 job-main-col'})\n",
    "    if (len(re.findall('(?i)Full-time',str(JOB_INFO)))>0):\n",
    "        return \"Full Time\"\n",
    "    elif (len(re.findall('(?i)Fulltime',str(JOB_INFO)))>0):\n",
    "        return \"Full Time\"\n",
    "    elif (len(re.findall('(?i)Full time',str(JOB_INFO)))>0):\n",
    "        return \"Full Time\"\n",
    "    elif (len(re.findall('(?i)Part-time',str(JOB_INFO)))>0):\n",
    "        return \"Part Time\"\n",
    "    elif (len(re.findall('(?i)Parttime',str(JOB_INFO)))>0):\n",
    "        return \"Part Time\"\n",
    "    elif (len(re.findall('(?i)Parttime',str(JOB_INFO)))>0):\n",
    "        return \"Part Time\"\n",
    "    elif (len(re.findall('(?i)Temporary',str(JOB_INFO)))>0):\n",
    "        return \"Contract\"\n",
    "    elif (len(re.findall('(?i)Contract',str(JOB_INFO)))>0):\n",
    "        return \"Contract\"\n",
    "    elif (len(re.findall('(?i)Permanent',str(JOB_INFO)))>0):\n",
    "        return \"Full Time\"\n",
    "    elif (len(re.findall('(?i)Regular',str(JOB_INFO)))>0):\n",
    "        return \"Full Time\"\n",
    "    elif (len(re.findall('(?i)OJT',str(JOB_INFO)))>0):\n",
    "        return \"OJT\"\n",
    "    elif (len(re.findall('(?i)Intern',str(JOB_INFO)))>0):\n",
    "        return \"OJT\"\n",
    "    elif (len(re.findall('(?i)Freelance',str(JOB_INFO)))>0):\n",
    "        return \"Freelance\"\n",
    "    elif (len(re.findall('(?i)Project Base',str(JOB_INFO)))>0):\n",
    "        return \"Project Base\"\n",
    "    else:\n",
    "        return \"Not Specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "biological-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of each job posting (JOBLUM)\n",
    "def scrapeJob(URL, JOB_TITLE_LIST, JOB_COMPANY_LIST, JOB_DATE_LIST, \n",
    "              JOB_STATUS_LIST, JOB_LOCATION_LIST, JOB_SALARY_LIST, \n",
    "              JOB_SALARY_MIN_LIST, JOB_SALARY_MAX_LIST, JOB_DESCRIPTION_LIST):\n",
    "    \n",
    "    for m in range(len(URL)):\n",
    "        JOB_SOUP = getSoup('https://ph.joblum.com' + URL[m])\n",
    "        JOB_TITLE = getJobTitle(JOB_SOUP)\n",
    "        JOB_COMPANY = getJobCompany(JOB_SOUP)\n",
    "        JOB_LOCATION = getJobLocation(JOB_SOUP)\n",
    "        JOB_DATEPOSTED = getDatePosted(JOB_SOUP)\n",
    "        JOB_DESCRIPTION = getJobDescription(JOB_SOUP)\n",
    "        JOB_SALARY, JOB_SALARY_MIN, JOB_SALARY_MAX = getJobSalary(JOB_SOUP)\n",
    "        JOB_STATUS = getJobType(JOB_SOUP)\n",
    "        JOB_TITLE_LIST.append(JOB_TITLE)\n",
    "        JOB_COMPANY_LIST.append(JOB_COMPANY)\n",
    "        JOB_DATE_LIST.append(JOB_DATEPOSTED)\n",
    "        JOB_STATUS_LIST.append(JOB_STATUS)\n",
    "        JOB_LOCATION_LIST.append(JOB_LOCATION)\n",
    "        JOB_SALARY_LIST.append(JOB_SALARY)\n",
    "        JOB_SALARY_MIN_LIST.append(JOB_SALARY_MIN)\n",
    "        JOB_SALARY_MAX_LIST.append(JOB_SALARY_MAX)\n",
    "        JOB_DESCRIPTION_LIST.append(JOB_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "competent-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Actuarial/Statistics (JOBLUM) - FIRST HALF\n",
    "\n",
    "STAT_TITLE_FIRST = []\n",
    "STAT_COMPANY_FIRST = []\n",
    "STAT_DATE_FIRST = []\n",
    "STAT_LOCATION_FIRST = []\n",
    "STAT_STATUS_FIRST = []\n",
    "STAT_SALARY_FIRST = []\n",
    "STAT_SALARY_MIN_FIRST = []\n",
    "STAT_SALARY_MAX_FIRST = []\n",
    "STAT_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-actuarial-statistics?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, STAT_TITLE_FIRST, STAT_COMPANY_FIRST, STAT_DATE_FIRST, \n",
    "              STAT_STATUS_FIRST, STAT_LOCATION_FIRST, STAT_SALARY_FIRST, \n",
    "              STAT_SALARY_MIN_FIRST, STAT_SALARY_MAX_FIRST, STAT_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "blind-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Actuarial/Statistics (JOBLUM) - SECOND HALF\n",
    "\n",
    "STAT_TITLE_SECOND = []\n",
    "STAT_COMPANY_SECOND = []\n",
    "STAT_DATE_SECOND = []\n",
    "STAT_LOCATION_SECOND = []\n",
    "STAT_STATUS_SECOND = []\n",
    "STAT_SALARY_SECOND = []\n",
    "STAT_SALARY_MIN_SECOND = []\n",
    "STAT_SALARY_MAX_SECOND = []\n",
    "STAT_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, STAT_TITLE_SECOND, STAT_COMPANY_SECOND, STAT_DATE_SECOND, \n",
    "              STAT_STATUS_SECOND, STAT_LOCATION_SECOND, STAT_SALARY_SECOND, \n",
    "              STAT_SALARY_MIN_SECOND, STAT_SALARY_MAX_SECOND, STAT_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "vocational-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Actuarial/Statistics (JOBLUM) \n",
    "\n",
    "STAT_TITLE_LIST = np.concatenate((STAT_TITLE_FIRST, STAT_TITLE_SECOND))\n",
    "STAT_COMPANY_LIST = np.concatenate((STAT_COMPANY_FIRST, STAT_COMPANY_SECOND))\n",
    "STAT_DATE_LIST = np.concatenate((STAT_DATE_FIRST, STAT_DATE_SECOND))\n",
    "STAT_LOCATION_LIST = np.concatenate((STAT_LOCATION_FIRST, STAT_LOCATION_SECOND))\n",
    "STAT_STATUS_LIST = np.concatenate((STAT_STATUS_FIRST, STAT_STATUS_SECOND))\n",
    "STAT_SALARY_LIST = np.concatenate((STAT_SALARY_FIRST, STAT_SALARY_SECOND))\n",
    "STAT_SALARY_MIN_LIST = np.concatenate((STAT_SALARY_MIN_FIRST, STAT_SALARY_MIN_SECOND))\n",
    "STAT_SALARY_MAX_LIST = np.concatenate((STAT_SALARY_MAX_FIRST, STAT_SALARY_MAX_SECOND))\n",
    "STAT_DESCRIPTION_LIST = np.concatenate((STAT_DESCRIPTION_FIRST, STAT_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cloudy-poker",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Education</th>\n",
       "      <th>Years of Work Expirience</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>Min Years of Work Expirience</th>\n",
       "      <th>Max Years of Work Expirience</th>\n",
       "      <th>Field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>With Signing Bonus* | Data Visualization Senio...</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Central Luzon, National Capital Reg, Calabarzo...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Go through a faster and more convenient recrui...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Statistician 1</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Philippine National Police Region X - Government</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Northern Mindanao</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : June 11,...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Statistician I</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Municipal Government of Surallah, South Cotaba...</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Soccsksargen</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : June 11,...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Risk Underwriter</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Lightspeed</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>Pasig City</td>\n",
       "      <td>Full Time</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Perks and Benefits Participate in the Lightspe...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Statistician III</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Civil Service Commission - Government</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 31, ...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Statistician Aide (010-0465)</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Provincial Government of Albay - Government</td>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>Bicol Region</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 7, 2...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>ELECTION ASSISTANT II</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Commission on Elections REGION II - Government</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Cagayan Valley</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 15, ...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>ELECTION ASSISTANT I</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Commission on Elections REGION II - Government</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Cagayan Valley</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 15, ...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Reporting Analyst</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Alta Resources (Philippines) Corporation</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>Contract</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>The Reporting Analyst will be responsible for ...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>NIGHT SHIFT &amp; TEMPORARY WFH | Data Scientist (...</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>MicroSourcing</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>Contract</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>MicroSourcing is looking for a Data Scientist ...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Website                                          Job Title  \\\n",
       "0    Joblum  With Signing Bonus* | Data Visualization Senio...   \n",
       "1    Joblum                                     Statistician 1   \n",
       "2    Joblum                                     Statistician I   \n",
       "3    Joblum                                   Risk Underwriter   \n",
       "4    Joblum                                   Statistician III   \n",
       "..      ...                                                ...   \n",
       "244  Joblum                       Statistician Aide (010-0465)   \n",
       "245  Joblum                              ELECTION ASSISTANT II   \n",
       "246  Joblum                               ELECTION ASSISTANT I   \n",
       "247  Joblum                                  Reporting Analyst   \n",
       "248  Joblum  NIGHT SHIFT & TEMPORARY WFH | Data Scientist (...   \n",
       "\n",
       "                 Category                                            Company  \\\n",
       "0    Actuarial/Statistics                                          Accenture   \n",
       "1    Actuarial/Statistics   Philippine National Police Region X - Government   \n",
       "2    Actuarial/Statistics  Municipal Government of Surallah, South Cotaba...   \n",
       "3    Actuarial/Statistics                                         Lightspeed   \n",
       "4    Actuarial/Statistics              Civil Service Commission - Government   \n",
       "..                    ...                                                ...   \n",
       "244  Actuarial/Statistics        Provincial Government of Albay - Government   \n",
       "245  Actuarial/Statistics     Commission on Elections REGION II - Government   \n",
       "246  Actuarial/Statistics     Commission on Elections REGION II - Government   \n",
       "247  Actuarial/Statistics           Alta Resources (Philippines) Corporation   \n",
       "248  Actuarial/Statistics                                      MicroSourcing   \n",
       "\n",
       "    Date Posted                                           Location  \\\n",
       "0    2021-05-29  Central Luzon, National Capital Reg, Calabarzo...   \n",
       "1    2021-05-29                                  Northern Mindanao   \n",
       "2    2021-05-29                                       Soccsksargen   \n",
       "3    2021-05-28                                         Pasig City   \n",
       "4    2021-05-28                               National Capital Reg   \n",
       "..          ...                                                ...   \n",
       "244  2021-05-01                                       Bicol Region   \n",
       "245  2021-04-30                                     Cagayan Valley   \n",
       "246  2021-04-30                                     Cagayan Valley   \n",
       "247  2021-04-29                               National Capital Reg   \n",
       "248  2021-04-29                               National Capital Reg   \n",
       "\n",
       "            Status Salary                       Education  \\\n",
       "0    Not Specified         Not Specified / In Description   \n",
       "1    Not Specified         Not Specified / In Description   \n",
       "2    Not Specified         Not Specified / In Description   \n",
       "3        Full Time         Not Specified / In Description   \n",
       "4    Not Specified         Not Specified / In Description   \n",
       "..             ...    ...                             ...   \n",
       "244  Not Specified         Not Specified / In Description   \n",
       "245  Not Specified         Not Specified / In Description   \n",
       "246  Not Specified         Not Specified / In Description   \n",
       "247       Contract         Not Specified / In Description   \n",
       "248       Contract         Not Specified / In Description   \n",
       "\n",
       "           Years of Work Expirience  \\\n",
       "0    Not Specified / In Description   \n",
       "1    Not Specified / In Description   \n",
       "2    Not Specified / In Description   \n",
       "3    Not Specified / In Description   \n",
       "4    Not Specified / In Description   \n",
       "..                              ...   \n",
       "244  Not Specified / In Description   \n",
       "245  Not Specified / In Description   \n",
       "246  Not Specified / In Description   \n",
       "247  Not Specified / In Description   \n",
       "248  Not Specified / In Description   \n",
       "\n",
       "                                       Job Description     Min Salary  \\\n",
       "0    Go through a faster and more convenient recrui...  Not Specified   \n",
       "1    Deadline for accepting applications : June 11,...  Not Specified   \n",
       "2    Deadline for accepting applications : June 11,...  Not Specified   \n",
       "3    Perks and Benefits Participate in the Lightspe...  Not Specified   \n",
       "4    Deadline for accepting applications : May 31, ...  Not Specified   \n",
       "..                                                 ...            ...   \n",
       "244  Deadline for accepting applications : May 7, 2...  Not Specified   \n",
       "245  Deadline for accepting applications : May 15, ...  Not Specified   \n",
       "246  Deadline for accepting applications : May 15, ...  Not Specified   \n",
       "247  The Reporting Analyst will be responsible for ...  Not Specified   \n",
       "248  MicroSourcing is looking for a Data Scientist ...  Not Specified   \n",
       "\n",
       "        Max Salary Min Years of Work Expirience Max Years of Work Expirience  \\\n",
       "0    Not Specified                Not Specified                Not Specified   \n",
       "1    Not Specified                Not Specified                Not Specified   \n",
       "2    Not Specified                Not Specified                Not Specified   \n",
       "3    Not Specified                Not Specified                Not Specified   \n",
       "4    Not Specified                Not Specified                Not Specified   \n",
       "..             ...                          ...                          ...   \n",
       "244  Not Specified                Not Specified                Not Specified   \n",
       "245  Not Specified                Not Specified                Not Specified   \n",
       "246  Not Specified                Not Specified                Not Specified   \n",
       "247  Not Specified                Not Specified                Not Specified   \n",
       "248  Not Specified                Not Specified                Not Specified   \n",
       "\n",
       "           Field  \n",
       "0    Mathematics  \n",
       "1    Mathematics  \n",
       "2    Mathematics  \n",
       "3    Mathematics  \n",
       "4    Mathematics  \n",
       "..           ...  \n",
       "244  Mathematics  \n",
       "245  Mathematics  \n",
       "246  Mathematics  \n",
       "247  Mathematics  \n",
       "248  Mathematics  \n",
       "\n",
       "[249 rows x 16 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Data Frame for Actuarial/Statistics (JOBLUM) \n",
    "STAT={'Website': \"Joblum\",\n",
    "      'Job Title': STAT_TITLE_LIST, \n",
    "      'Category': \"Actuarial/Statistics\", \n",
    "      'Company': STAT_COMPANY_LIST, \n",
    "      'Date Posted': STAT_DATE_LIST, \n",
    "      'Location': STAT_LOCATION_LIST, \n",
    "      'Status': STAT_STATUS_LIST, \n",
    "      'Salary': STAT_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': STAT_DESCRIPTION_LIST,\n",
    "      'Min Salary': STAT_SALARY_MIN_LIST,\n",
    "      'Max Salary': STAT_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Mathematics\"}\n",
    "STAT_df = pd.DataFrame(data=STAT)\n",
    "STAT_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "environmental-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT_df.to_csv ('JOBLUM-STAT.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "editorial-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Agriculture (JOBLUM) - FIRST HALF\n",
    "\n",
    "AGRI_TITLE_FIRST = []\n",
    "AGRI_COMPANY_FIRST = []\n",
    "AGRI_DATE_FIRST = []\n",
    "AGRI_LOCATION_FIRST = []\n",
    "AGRI_STATUS_FIRST = []\n",
    "AGRI_SALARY_FIRST = []\n",
    "AGRI_SALARY_MIN_FIRST = []\n",
    "AGRI_SALARY_MAX_FIRST = []\n",
    "AGRI_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-agriculture?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, AGRI_TITLE_FIRST, AGRI_COMPANY_FIRST, AGRI_DATE_FIRST, \n",
    "              AGRI_STATUS_FIRST, AGRI_LOCATION_FIRST, AGRI_SALARY_FIRST, \n",
    "              AGRI_SALARY_MIN_FIRST, AGRI_SALARY_MAX_FIRST, AGRI_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "noticed-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Agriculture (JOBLUM) - SECOND HALF\n",
    "\n",
    "AGRI_TITLE_SECOND = []\n",
    "AGRI_COMPANY_SECOND = []\n",
    "AGRI_DATE_SECOND = []\n",
    "AGRI_LOCATION_SECOND = []\n",
    "AGRI_STATUS_SECOND = []\n",
    "AGRI_SALARY_SECOND = []\n",
    "AGRI_SALARY_MIN_SECOND = []\n",
    "AGRI_SALARY_MAX_SECOND = []\n",
    "AGRI_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, AGRI_TITLE_SECOND, AGRI_COMPANY_SECOND, AGRI_DATE_SECOND, \n",
    "              AGRI_STATUS_SECOND, AGRI_LOCATION_SECOND, AGRI_SALARY_SECOND, \n",
    "              AGRI_SALARY_MIN_SECOND, AGRI_SALARY_MAX_SECOND, AGRI_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "coastal-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Agriculture (JOBLUM) \n",
    "\n",
    "AGRI_TITLE_LIST = np.concatenate((AGRI_TITLE_FIRST, AGRI_TITLE_SECOND))\n",
    "AGRI_COMPANY_LIST = np.concatenate((AGRI_COMPANY_FIRST, AGRI_COMPANY_SECOND))\n",
    "AGRI_DATE_LIST = np.concatenate((AGRI_DATE_FIRST, AGRI_DATE_SECOND))\n",
    "AGRI_LOCATION_LIST = np.concatenate((AGRI_LOCATION_FIRST, AGRI_LOCATION_SECOND))\n",
    "AGRI_STATUS_LIST = np.concatenate((AGRI_STATUS_FIRST, AGRI_STATUS_SECOND))\n",
    "AGRI_SALARY_LIST = np.concatenate((AGRI_SALARY_FIRST, AGRI_SALARY_SECOND))\n",
    "AGRI_SALARY_MIN_LIST = np.concatenate((AGRI_SALARY_MIN_FIRST, AGRI_SALARY_MIN_SECOND))\n",
    "AGRI_SALARY_MAX_LIST = np.concatenate((AGRI_SALARY_MAX_FIRST, AGRI_SALARY_MAX_SECOND))\n",
    "AGRI_DESCRIPTION_LIST = np.concatenate((AGRI_DESCRIPTION_FIRST, AGRI_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "moved-demographic",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Education</th>\n",
       "      <th>Years of Work Expirience</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>Min Years of Work Expirience</th>\n",
       "      <th>Max Years of Work Expirience</th>\n",
       "      <th>Field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Technical Sales Representative (Mindanao)</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>La Filipina Uy Gongco Group of Companies</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Bukidnon</td>\n",
       "      <td>Contract</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>QUALIFICATIONS Candidate must possess at least...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Farm Worker II</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Municipal Government of Agoo, La Union</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Ilocos Region</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>12,960</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : June 4, ...</td>\n",
       "      <td>12,960</td>\n",
       "      <td>12,960</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>AGRICULTURAL TECHNOLOGIST</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Municipal Government of Magdiwang, Romblon</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Calabarzon &amp; Mimaropa</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>14,153</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : June 4, ...</td>\n",
       "      <td>14,153</td>\n",
       "      <td>14,153</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Farm Worker - I</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Municipal Government of Santa Teresita, Cagayan</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Cagayan Valley</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>9,207</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : June 7, ...</td>\n",
       "      <td>9,207</td>\n",
       "      <td>9,207</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Senior Aquaculturist</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Municipal Government of Parang, Maguindanao</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Armm</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>37,943</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : June 1, ...</td>\n",
       "      <td>37,943</td>\n",
       "      <td>37,943</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Agriculturist I</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>City Government of Surigao, Surigao del Norte</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Caraga</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>21,489</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 9, 2...</td>\n",
       "      <td>21,489</td>\n",
       "      <td>21,489</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Agricultural Technologist</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>City Government of Surigao, Surigao del Norte</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Caraga</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>19,085</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 9, 2...</td>\n",
       "      <td>19,085</td>\n",
       "      <td>19,085</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Greenhouse Farm Worker</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Czark Mak Group of Companies</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Cavite</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Candidate must possess at least Bachelor's/Col...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Municipal Agricultural Officer</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Municipal Government of Alburquerque, Bohol - ...</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Central Visayas</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>36,892</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 7, 2...</td>\n",
       "      <td>36,892</td>\n",
       "      <td>36,892</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Farm Officer</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Primary Group of Builders</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Cebu (Cebu City)</td>\n",
       "      <td>Contract</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Job Qualifications: Candidate must possess at ...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Website                                  Job Title     Category  \\\n",
       "0    Joblum  Technical Sales Representative (Mindanao)  Agriculture   \n",
       "1    Joblum                             Farm Worker II  Agriculture   \n",
       "2    Joblum                  AGRICULTURAL TECHNOLOGIST  Agriculture   \n",
       "3    Joblum                            Farm Worker - I  Agriculture   \n",
       "4    Joblum                       Senior Aquaculturist  Agriculture   \n",
       "..      ...                                        ...          ...   \n",
       "692  Joblum                            Agriculturist I  Agriculture   \n",
       "693  Joblum                  Agricultural Technologist  Agriculture   \n",
       "694  Joblum                     Greenhouse Farm Worker  Agriculture   \n",
       "695  Joblum             Municipal Agricultural Officer  Agriculture   \n",
       "696  Joblum                               Farm Officer  Agriculture   \n",
       "\n",
       "                                               Company Date Posted  \\\n",
       "0             La Filipina Uy Gongco Group of Companies  2021-05-29   \n",
       "1               Municipal Government of Agoo, La Union  2021-05-29   \n",
       "2           Municipal Government of Magdiwang, Romblon  2021-05-29   \n",
       "3      Municipal Government of Santa Teresita, Cagayan  2021-05-29   \n",
       "4          Municipal Government of Parang, Maguindanao  2021-05-29   \n",
       "..                                                 ...         ...   \n",
       "692      City Government of Surigao, Surigao del Norte  2021-04-30   \n",
       "693      City Government of Surigao, Surigao del Norte  2021-04-30   \n",
       "694                       Czark Mak Group of Companies  2021-04-30   \n",
       "695  Municipal Government of Alburquerque, Bohol - ...  2021-04-30   \n",
       "696                          Primary Group of Builders  2021-04-30   \n",
       "\n",
       "                  Location         Status  Salary  \\\n",
       "0                 Bukidnon       Contract           \n",
       "1            Ilocos Region  Not Specified  12,960   \n",
       "2    Calabarzon & Mimaropa  Not Specified  14,153   \n",
       "3           Cagayan Valley  Not Specified   9,207   \n",
       "4                     Armm  Not Specified  37,943   \n",
       "..                     ...            ...     ...   \n",
       "692                 Caraga  Not Specified  21,489   \n",
       "693                 Caraga  Not Specified  19,085   \n",
       "694                 Cavite  Not Specified           \n",
       "695        Central Visayas  Not Specified  36,892   \n",
       "696       Cebu (Cebu City)       Contract           \n",
       "\n",
       "                          Education        Years of Work Expirience  \\\n",
       "0    Not Specified / In Description  Not Specified / In Description   \n",
       "1    Not Specified / In Description  Not Specified / In Description   \n",
       "2    Not Specified / In Description  Not Specified / In Description   \n",
       "3    Not Specified / In Description  Not Specified / In Description   \n",
       "4    Not Specified / In Description  Not Specified / In Description   \n",
       "..                              ...                             ...   \n",
       "692  Not Specified / In Description  Not Specified / In Description   \n",
       "693  Not Specified / In Description  Not Specified / In Description   \n",
       "694  Not Specified / In Description  Not Specified / In Description   \n",
       "695  Not Specified / In Description  Not Specified / In Description   \n",
       "696  Not Specified / In Description  Not Specified / In Description   \n",
       "\n",
       "                                       Job Description     Min Salary  \\\n",
       "0    QUALIFICATIONS Candidate must possess at least...  Not Specified   \n",
       "1    Deadline for accepting applications : June 4, ...         12,960   \n",
       "2    Deadline for accepting applications : June 4, ...         14,153   \n",
       "3    Deadline for accepting applications : June 7, ...          9,207   \n",
       "4    Deadline for accepting applications : June 1, ...         37,943   \n",
       "..                                                 ...            ...   \n",
       "692  Deadline for accepting applications : May 9, 2...         21,489   \n",
       "693  Deadline for accepting applications : May 9, 2...         19,085   \n",
       "694  Candidate must possess at least Bachelor's/Col...  Not Specified   \n",
       "695  Deadline for accepting applications : May 7, 2...         36,892   \n",
       "696  Job Qualifications: Candidate must possess at ...  Not Specified   \n",
       "\n",
       "        Max Salary Min Years of Work Expirience Max Years of Work Expirience  \\\n",
       "0    Not Specified                Not Specified                Not Specified   \n",
       "1           12,960                Not Specified                Not Specified   \n",
       "2           14,153                Not Specified                Not Specified   \n",
       "3            9,207                Not Specified                Not Specified   \n",
       "4           37,943                Not Specified                Not Specified   \n",
       "..             ...                          ...                          ...   \n",
       "692         21,489                Not Specified                Not Specified   \n",
       "693         19,085                Not Specified                Not Specified   \n",
       "694  Not Specified                Not Specified                Not Specified   \n",
       "695         36,892                Not Specified                Not Specified   \n",
       "696  Not Specified                Not Specified                Not Specified   \n",
       "\n",
       "           Field  \n",
       "0    Mathematics  \n",
       "1    Mathematics  \n",
       "2    Mathematics  \n",
       "3    Mathematics  \n",
       "4    Mathematics  \n",
       "..           ...  \n",
       "692  Mathematics  \n",
       "693  Mathematics  \n",
       "694  Mathematics  \n",
       "695  Mathematics  \n",
       "696  Mathematics  \n",
       "\n",
       "[697 rows x 16 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Data Frame for Agriculture (JOBLUM) \n",
    "AGRI={'Website': \"Joblum\",\n",
    "      'Job Title': AGRI_TITLE_LIST, \n",
    "      'Category': \"Agriculture\", \n",
    "      'Company': AGRI_COMPANY_LIST, \n",
    "      'Date Posted': AGRI_DATE_LIST, \n",
    "      'Location': AGRI_LOCATION_LIST, \n",
    "      'Status': AGRI_STATUS_LIST, \n",
    "      'Salary': AGRI_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': AGRI_DESCRIPTION_LIST,\n",
    "      'Min Salary': AGRI_SALARY_MIN_LIST,\n",
    "      'Max Salary': AGRI_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Agriculture\"}\n",
    "AGRI_df = pd.DataFrame(data=AGRI)\n",
    "AGRI_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "simplified-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGRI_df.to_csv ('JOBLUM-AGRI.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "through-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Architect/Interior Design (JOBLUM) - FIRST HALF\n",
    "\n",
    "ARCHI_TITLE_FIRST = []\n",
    "ARCHI_COMPANY_FIRST = []\n",
    "ARCHI_DATE_FIRST = []\n",
    "ARCHI_LOCATION_FIRST = []\n",
    "ARCHI_STATUS_FIRST = []\n",
    "ARCHI_SALARY_FIRST = []\n",
    "ARCHI_SALARY_MIN_FIRST = []\n",
    "ARCHI_SALARY_MAX_FIRST = []\n",
    "ARCHI_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-architect-interior-design?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ARCHI_TITLE_FIRST, ARCHI_COMPANY_FIRST, ARCHI_DATE_FIRST, \n",
    "              ARCHI_STATUS_FIRST, ARCHI_LOCATION_FIRST, ARCHI_SALARY_FIRST, \n",
    "              ARCHI_SALARY_MIN_FIRST, ARCHI_SALARY_MAX_FIRST, ARCHI_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "inappropriate-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Architect/Interior Design (JOBLUM) - SECOND HALF\n",
    "\n",
    "ARCHI_TITLE_SECOND = []\n",
    "ARCHI_COMPANY_SECOND = []\n",
    "ARCHI_DATE_SECOND = []\n",
    "ARCHI_LOCATION_SECOND = []\n",
    "ARCHI_STATUS_SECOND = []\n",
    "ARCHI_SALARY_SECOND = []\n",
    "ARCHI_SALARY_MIN_SECOND = []\n",
    "ARCHI_SALARY_MAX_SECOND = []\n",
    "ARCHI_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ARCHI_TITLE_SECOND, ARCHI_COMPANY_SECOND, ARCHI_DATE_SECOND, \n",
    "              ARCHI_STATUS_SECOND, ARCHI_LOCATION_SECOND, ARCHI_SALARY_SECOND, \n",
    "              ARCHI_SALARY_MIN_SECOND, ARCHI_SALARY_MAX_SECOND, ARCHI_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "excited-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Architect/Interior Design (JOBLUM) \n",
    "\n",
    "ARCHI_TITLE_LIST = np.concatenate((ARCHI_TITLE_FIRST, ARCHI_TITLE_SECOND))\n",
    "ARCHI_COMPANY_LIST = np.concatenate((ARCHI_COMPANY_FIRST, ARCHI_COMPANY_SECOND))\n",
    "ARCHI_DATE_LIST = np.concatenate((ARCHI_DATE_FIRST, ARCHI_DATE_SECOND))\n",
    "ARCHI_LOCATION_LIST = np.concatenate((ARCHI_LOCATION_FIRST, ARCHI_LOCATION_SECOND))\n",
    "ARCHI_STATUS_LIST = np.concatenate((ARCHI_STATUS_FIRST, ARCHI_STATUS_SECOND))\n",
    "ARCHI_SALARY_LIST = np.concatenate((ARCHI_SALARY_FIRST, ARCHI_SALARY_SECOND))\n",
    "ARCHI_SALARY_MIN_LIST = np.concatenate((ARCHI_SALARY_MIN_FIRST, ARCHI_SALARY_MIN_SECOND))\n",
    "ARCHI_SALARY_MAX_LIST = np.concatenate((ARCHI_SALARY_MAX_FIRST, ARCHI_SALARY_MAX_SECOND))\n",
    "ARCHI_DESCRIPTION_LIST = np.concatenate((ARCHI_DESCRIPTION_FIRST, ARCHI_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "wrapped-brazilian",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Education</th>\n",
       "      <th>Years of Work Expirience</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>Min Years of Work Expirience</th>\n",
       "      <th>Max Years of Work Expirience</th>\n",
       "      <th>Field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>ARCHITECT</td>\n",
       "      <td>Architect/Interior Design</td>\n",
       "      <td>Puyat Sports Inc.</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Makati City</td>\n",
       "      <td>Full Time</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Qualifications: BS Architecture graduate from ...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Interior Designer</td>\n",
       "      <td>Architect/Interior Design</td>\n",
       "      <td>DMCI Homes</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>Contract</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>&lt;&gt;QUALIFICATIONS Graduate of Bachelor's/Colleg...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>SALES DESIGNER (Luxury Home Furnishing Brands)</td>\n",
       "      <td>Architect/Interior Design</td>\n",
       "      <td>Focus Global Inc.</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>Contract</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>The Sales Designer will join Focus Global’s te...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Product Designer - Furniture</td>\n",
       "      <td>Architect/Interior Design</td>\n",
       "      <td>ELECTROPARTS DEVELOPMENT CORPORATION</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>San Juan City</td>\n",
       "      <td>OJT</td>\n",
       "      <td>18,000-30,000</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Lead representative for communications with bo...</td>\n",
       "      <td>18,000</td>\n",
       "      <td>30,000</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Archtectural Draftsman</td>\n",
       "      <td>Architect/Interior Design</td>\n",
       "      <td>TRANSFORMATIONAL HUB CORPORATION</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Cebu (Cebu City)</td>\n",
       "      <td>OJT</td>\n",
       "      <td>25,000-30,000</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Experience in BIM modelling / workflow - parti...</td>\n",
       "      <td>25,000</td>\n",
       "      <td>30,000</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>CAD Operator</td>\n",
       "      <td>Architect/Interior Design</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Misamis Oriental (CDO)</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Cad Operators are responsible for the: Prepara...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Architect/Interior Design</td>\n",
       "      <td>ARBOR VITAE CONSTRUCTION GROUP</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Cebu (Cebu City)</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>30,000-42,000</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>We are looking for interior designers and arch...</td>\n",
       "      <td>30,000</td>\n",
       "      <td>42,000</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Junior Project Architect</td>\n",
       "      <td>Architect/Interior Design</td>\n",
       "      <td>DMC Urban Property Developers, Inc.</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Makati City</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>19,000-21,000</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Graduate of B.S Architecture At least 2-3 year...</td>\n",
       "      <td>19,000</td>\n",
       "      <td>21,000</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Ht doctor test saved 1 [Don't apply]</td>\n",
       "      <td>Architect/Interior Design</td>\n",
       "      <td>Maxicare Healthcare Corporation</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>7,000-9,800</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Included some rr question test save in ph test...</td>\n",
       "      <td>7,000</td>\n",
       "      <td>9,800</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>ARCHITECT (DEPARTMENT HEAD ROLE)</td>\n",
       "      <td>Architect/Interior Design</td>\n",
       "      <td>Shera Building Solution (Philippines) Corp.</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>Contract</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>As we continue to translate our success in the...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Website                                       Job Title  \\\n",
       "0    Joblum                                       ARCHITECT   \n",
       "1    Joblum                               Interior Designer   \n",
       "2    Joblum  SALES DESIGNER (Luxury Home Furnishing Brands)   \n",
       "3    Joblum                    Product Designer - Furniture   \n",
       "4    Joblum                          Archtectural Draftsman   \n",
       "..      ...                                             ...   \n",
       "347  Joblum                                    CAD Operator   \n",
       "348  Joblum                                       Architect   \n",
       "349  Joblum                        Junior Project Architect   \n",
       "350  Joblum            Ht doctor test saved 1 [Don't apply]   \n",
       "351  Joblum                ARCHITECT (DEPARTMENT HEAD ROLE)   \n",
       "\n",
       "                      Category                                      Company  \\\n",
       "0    Architect/Interior Design                            Puyat Sports Inc.   \n",
       "1    Architect/Interior Design                                   DMCI Homes   \n",
       "2    Architect/Interior Design                            Focus Global Inc.   \n",
       "3    Architect/Interior Design         ELECTROPARTS DEVELOPMENT CORPORATION   \n",
       "4    Architect/Interior Design             TRANSFORMATIONAL HUB CORPORATION   \n",
       "..                         ...                                          ...   \n",
       "347  Architect/Interior Design                                Not Specified   \n",
       "348  Architect/Interior Design               ARBOR VITAE CONSTRUCTION GROUP   \n",
       "349  Architect/Interior Design          DMC Urban Property Developers, Inc.   \n",
       "350  Architect/Interior Design              Maxicare Healthcare Corporation   \n",
       "351  Architect/Interior Design  Shera Building Solution (Philippines) Corp.   \n",
       "\n",
       "    Date Posted                Location         Status         Salary  \\\n",
       "0    2021-05-29             Makati City      Full Time                  \n",
       "1    2021-05-29    National Capital Reg       Contract                  \n",
       "2    2021-05-29    National Capital Reg       Contract                  \n",
       "3    2021-05-29           San Juan City            OJT  18,000-30,000   \n",
       "4    2021-05-29        Cebu (Cebu City)            OJT  25,000-30,000   \n",
       "..          ...                     ...            ...            ...   \n",
       "347  2021-04-30  Misamis Oriental (CDO)  Not Specified                  \n",
       "348  2021-04-30        Cebu (Cebu City)      Full Time  30,000-42,000   \n",
       "349  2021-04-30             Makati City  Not Specified  19,000-21,000   \n",
       "350  2021-04-29             Philippines      Part Time    7,000-9,800   \n",
       "351  2021-04-29    National Capital Reg       Contract                  \n",
       "\n",
       "                          Education        Years of Work Expirience  \\\n",
       "0    Not Specified / In Description  Not Specified / In Description   \n",
       "1    Not Specified / In Description  Not Specified / In Description   \n",
       "2    Not Specified / In Description  Not Specified / In Description   \n",
       "3    Not Specified / In Description  Not Specified / In Description   \n",
       "4    Not Specified / In Description  Not Specified / In Description   \n",
       "..                              ...                             ...   \n",
       "347  Not Specified / In Description  Not Specified / In Description   \n",
       "348  Not Specified / In Description  Not Specified / In Description   \n",
       "349  Not Specified / In Description  Not Specified / In Description   \n",
       "350  Not Specified / In Description  Not Specified / In Description   \n",
       "351  Not Specified / In Description  Not Specified / In Description   \n",
       "\n",
       "                                       Job Description     Min Salary  \\\n",
       "0    Qualifications: BS Architecture graduate from ...  Not Specified   \n",
       "1    <>QUALIFICATIONS Graduate of Bachelor's/Colleg...  Not Specified   \n",
       "2    The Sales Designer will join Focus Global’s te...  Not Specified   \n",
       "3    Lead representative for communications with bo...         18,000   \n",
       "4    Experience in BIM modelling / workflow - parti...         25,000   \n",
       "..                                                 ...            ...   \n",
       "347  Cad Operators are responsible for the: Prepara...  Not Specified   \n",
       "348  We are looking for interior designers and arch...         30,000   \n",
       "349  Graduate of B.S Architecture At least 2-3 year...         19,000   \n",
       "350  Included some rr question test save in ph test...          7,000   \n",
       "351  As we continue to translate our success in the...  Not Specified   \n",
       "\n",
       "        Max Salary Min Years of Work Expirience Max Years of Work Expirience  \\\n",
       "0    Not Specified                Not Specified                Not Specified   \n",
       "1    Not Specified                Not Specified                Not Specified   \n",
       "2    Not Specified                Not Specified                Not Specified   \n",
       "3           30,000                Not Specified                Not Specified   \n",
       "4           30,000                Not Specified                Not Specified   \n",
       "..             ...                          ...                          ...   \n",
       "347  Not Specified                Not Specified                Not Specified   \n",
       "348         42,000                Not Specified                Not Specified   \n",
       "349         21,000                Not Specified                Not Specified   \n",
       "350          9,800                Not Specified                Not Specified   \n",
       "351  Not Specified                Not Specified                Not Specified   \n",
       "\n",
       "           Field  \n",
       "0    Engineering  \n",
       "1    Engineering  \n",
       "2    Engineering  \n",
       "3    Engineering  \n",
       "4    Engineering  \n",
       "..           ...  \n",
       "347  Engineering  \n",
       "348  Engineering  \n",
       "349  Engineering  \n",
       "350  Engineering  \n",
       "351  Engineering  \n",
       "\n",
       "[352 rows x 16 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Data Frame for Architect/Interior Design (JOBLUM) \n",
    "ARCHI={'Website': \"Joblum\",\n",
    "      'Job Title': ARCHI_TITLE_LIST, \n",
    "      'Category': \"Architect/Interior Design\", \n",
    "      'Company': ARCHI_COMPANY_LIST, \n",
    "      'Date Posted': ARCHI_DATE_LIST, \n",
    "      'Location': ARCHI_LOCATION_LIST, \n",
    "      'Status': ARCHI_STATUS_LIST, \n",
    "      'Salary': ARCHI_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': ARCHI_DESCRIPTION_LIST,\n",
    "      'Min Salary': ARCHI_SALARY_MIN_LIST,\n",
    "      'Max Salary': ARCHI_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "ARCHI_df = pd.DataFrame(data=ARCHI)\n",
    "ARCHI_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "integrated-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHI_df.to_csv ('JOBLUM-ARCHI.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "damaged-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Aviation (JOBLUM) - FIRST HALF\n",
    "\n",
    "AVI_TITLE_FIRST = []\n",
    "AVI_COMPANY_FIRST = []\n",
    "AVI_DATE_FIRST = []\n",
    "AVI_LOCATION_FIRST = []\n",
    "AVI_STATUS_FIRST = []\n",
    "AVI_SALARY_FIRST = []\n",
    "AVI_SALARY_MIN_FIRST = []\n",
    "AVI_SALARY_MAX_FIRST = []\n",
    "AVI_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-aviation?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, AVI_TITLE_FIRST, AVI_COMPANY_FIRST, AVI_DATE_FIRST, \n",
    "              AVI_STATUS_FIRST, AVI_LOCATION_FIRST, AVI_SALARY_FIRST, \n",
    "              AVI_SALARY_MIN_FIRST, AVI_SALARY_MAX_FIRST, AVI_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "familiar-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Aviation (JOBLUM) - SECOND HALF\n",
    "\n",
    "AVI_TITLE_SECOND = []\n",
    "AVI_COMPANY_SECOND = []\n",
    "AVI_DATE_SECOND = []\n",
    "AVI_LOCATION_SECOND = []\n",
    "AVI_STATUS_SECOND = []\n",
    "AVI_SALARY_SECOND = []\n",
    "AVI_SALARY_MIN_SECOND = []\n",
    "AVI_SALARY_MAX_SECOND = []\n",
    "AVI_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, AVI_TITLE_SECOND, AVI_COMPANY_SECOND, AVI_DATE_SECOND, \n",
    "              AVI_STATUS_SECOND, AVI_LOCATION_SECOND, AVI_SALARY_SECOND, \n",
    "              AVI_SALARY_MIN_SECOND, AVI_SALARY_MAX_SECOND, AVI_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "exposed-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Aviation (JOBLUM) \n",
    "\n",
    "AVI_TITLE_LIST = np.concatenate((AVI_TITLE_FIRST, AVI_TITLE_SECOND))\n",
    "AVI_COMPANY_LIST = np.concatenate((AVI_COMPANY_FIRST, AVI_COMPANY_SECOND))\n",
    "AVI_DATE_LIST = np.concatenate((AVI_DATE_FIRST, AVI_DATE_SECOND))\n",
    "AVI_LOCATION_LIST = np.concatenate((AVI_LOCATION_FIRST, AVI_LOCATION_SECOND))\n",
    "AVI_STATUS_LIST = np.concatenate((AVI_STATUS_FIRST, AVI_STATUS_SECOND))\n",
    "AVI_SALARY_LIST = np.concatenate((AVI_SALARY_FIRST, AVI_SALARY_SECOND))\n",
    "AVI_SALARY_MIN_LIST = np.concatenate((AVI_SALARY_MIN_FIRST, AVI_SALARY_MIN_SECOND))\n",
    "AVI_SALARY_MAX_LIST = np.concatenate((AVI_SALARY_MAX_FIRST, AVI_SALARY_MAX_SECOND))\n",
    "AVI_DESCRIPTION_LIST = np.concatenate((AVI_DESCRIPTION_FIRST, AVI_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cordless-interval",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Education</th>\n",
       "      <th>Years of Work Expirience</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>Min Years of Work Expirience</th>\n",
       "      <th>Max Years of Work Expirience</th>\n",
       "      <th>Field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Maintenance Support Analyst</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>Traxxall Technologies, Inc. - Philippine Branch</td>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>Pampanga (Angeles City)</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Role and Responsibilities In the role of Aircr...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Technician</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>ARAM ENTERPRISES INC</td>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Full Time</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Candidate must possess at least a Professional...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Compensation and Benefits Supervisor</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>Asian Aerospace</td>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>Pasay City</td>\n",
       "      <td>OJT</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Job Summary The Compensation and Benefits Supe...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Storekeeper</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>Airbus Helicopters Philippines Inc.</td>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>Pasay City</td>\n",
       "      <td>Full Time</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Job Qualifications BS in Aircraft Maintenance ...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>System Data Analyst</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>Global Virtuoso, Inc.</td>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Global Virtuoso is actively looking for System...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Mechanic II (18-1998)</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>PHILIPPINE AIR FORCE - Government</td>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 17, ...</td>\n",
       "      <td>18,251</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Mechanic II (34-1998)</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>PHILIPPINE AIR FORCE - Government</td>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 17, ...</td>\n",
       "      <td>18,251</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Mechanic II (27-1998)</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>PHILIPPINE AIR FORCE - Government</td>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 17, ...</td>\n",
       "      <td>18,251</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Maintenance Technologist III</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>PHILIPPINE AIR FORCE - Government</td>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td>43,681</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 17, ...</td>\n",
       "      <td>43,681</td>\n",
       "      <td>43,681</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Maintenance Technologist III</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>PHILIPPINE AIR FORCE - Government</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td>43,681</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 17, ...</td>\n",
       "      <td>43,681</td>\n",
       "      <td>43,681</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Mechanic II (18-1998)</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>PHILIPPINE AIR FORCE - Government</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 14, ...</td>\n",
       "      <td>18,251</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Mechanic II (34-1998)</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>PHILIPPINE AIR FORCE - Government</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 14, ...</td>\n",
       "      <td>18,251</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Mechanic II (27-1998)</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>PHILIPPINE AIR FORCE - Government</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 14, ...</td>\n",
       "      <td>18,251</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Service Performance Manager</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>1Aviation Groundhandling Services Corporation</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>Pasay City</td>\n",
       "      <td>OJT</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Job Summary Responsible for managing a team to...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Line Mechanic</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>Sumifru (Philippines) Corporation</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>Davao</td>\n",
       "      <td>Full Time</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>The Line Mechanic is responsible for conductin...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Quality Assurance Officer</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>Sumifru (Philippines) Corporation</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>Davao</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>The Quality Assurance Officer is responsible f...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Website                              Job Title  Category  \\\n",
       "0   Joblum   Aircraft Maintenance Support Analyst  Aviation   \n",
       "1   Joblum                    Aircraft Technician  Aviation   \n",
       "2   Joblum   Compensation and Benefits Supervisor  Aviation   \n",
       "3   Joblum                            Storekeeper  Aviation   \n",
       "4   Joblum                    System Data Analyst  Aviation   \n",
       "5   Joblum         Aircraft Mechanic II (18-1998)  Aviation   \n",
       "6   Joblum         Aircraft Mechanic II (34-1998)  Aviation   \n",
       "7   Joblum         Aircraft Mechanic II (27-1998)  Aviation   \n",
       "8   Joblum  Aircraft Maintenance Technologist III  Aviation   \n",
       "9   Joblum  Aircraft Maintenance Technologist III  Aviation   \n",
       "10  Joblum         Aircraft Mechanic II (18-1998)  Aviation   \n",
       "11  Joblum         Aircraft Mechanic II (34-1998)  Aviation   \n",
       "12  Joblum         Aircraft Mechanic II (27-1998)  Aviation   \n",
       "13  Joblum            Service Performance Manager  Aviation   \n",
       "14  Joblum                          Line Mechanic  Aviation   \n",
       "15  Joblum              Quality Assurance Officer  Aviation   \n",
       "\n",
       "                                            Company Date Posted  \\\n",
       "0   Traxxall Technologies, Inc. - Philippine Branch  2021-05-27   \n",
       "1                              ARAM ENTERPRISES INC  2021-05-27   \n",
       "2                                   Asian Aerospace  2021-05-25   \n",
       "3               Airbus Helicopters Philippines Inc.  2021-05-23   \n",
       "4                             Global Virtuoso, Inc.  2021-05-17   \n",
       "5                 PHILIPPINE AIR FORCE - Government  2021-05-14   \n",
       "6                 PHILIPPINE AIR FORCE - Government  2021-05-14   \n",
       "7                 PHILIPPINE AIR FORCE - Government  2021-05-14   \n",
       "8                 PHILIPPINE AIR FORCE - Government  2021-05-14   \n",
       "9                 PHILIPPINE AIR FORCE - Government  2021-05-12   \n",
       "10                PHILIPPINE AIR FORCE - Government  2021-05-12   \n",
       "11                PHILIPPINE AIR FORCE - Government  2021-05-12   \n",
       "12                PHILIPPINE AIR FORCE - Government  2021-05-12   \n",
       "13    1Aviation Groundhandling Services Corporation  2021-05-11   \n",
       "14                Sumifru (Philippines) Corporation  2021-05-09   \n",
       "15                Sumifru (Philippines) Corporation  2021-05-09   \n",
       "\n",
       "                   Location         Status  Salary  \\\n",
       "0   Pampanga (Angeles City)  Not Specified           \n",
       "1              Saudi Arabia      Full Time           \n",
       "2                Pasay City            OJT           \n",
       "3                Pasay City      Full Time           \n",
       "4      National Capital Reg            OJT           \n",
       "5      National Capital Reg            OJT  18,251   \n",
       "6      National Capital Reg            OJT  18,251   \n",
       "7      National Capital Reg            OJT  18,251   \n",
       "8      National Capital Reg            OJT  43,681   \n",
       "9      National Capital Reg            OJT  43,681   \n",
       "10     National Capital Reg            OJT  18,251   \n",
       "11     National Capital Reg            OJT  18,251   \n",
       "12     National Capital Reg            OJT  18,251   \n",
       "13               Pasay City            OJT           \n",
       "14                    Davao      Full Time           \n",
       "15                    Davao  Not Specified           \n",
       "\n",
       "                         Education        Years of Work Expirience  \\\n",
       "0   Not Specified / In Description  Not Specified / In Description   \n",
       "1   Not Specified / In Description  Not Specified / In Description   \n",
       "2   Not Specified / In Description  Not Specified / In Description   \n",
       "3   Not Specified / In Description  Not Specified / In Description   \n",
       "4   Not Specified / In Description  Not Specified / In Description   \n",
       "5   Not Specified / In Description  Not Specified / In Description   \n",
       "6   Not Specified / In Description  Not Specified / In Description   \n",
       "7   Not Specified / In Description  Not Specified / In Description   \n",
       "8   Not Specified / In Description  Not Specified / In Description   \n",
       "9   Not Specified / In Description  Not Specified / In Description   \n",
       "10  Not Specified / In Description  Not Specified / In Description   \n",
       "11  Not Specified / In Description  Not Specified / In Description   \n",
       "12  Not Specified / In Description  Not Specified / In Description   \n",
       "13  Not Specified / In Description  Not Specified / In Description   \n",
       "14  Not Specified / In Description  Not Specified / In Description   \n",
       "15  Not Specified / In Description  Not Specified / In Description   \n",
       "\n",
       "                                      Job Description     Min Salary  \\\n",
       "0   Role and Responsibilities In the role of Aircr...  Not Specified   \n",
       "1   Candidate must possess at least a Professional...  Not Specified   \n",
       "2   Job Summary The Compensation and Benefits Supe...  Not Specified   \n",
       "3   Job Qualifications BS in Aircraft Maintenance ...  Not Specified   \n",
       "4   Global Virtuoso is actively looking for System...  Not Specified   \n",
       "5   Deadline for accepting applications : May 17, ...         18,251   \n",
       "6   Deadline for accepting applications : May 17, ...         18,251   \n",
       "7   Deadline for accepting applications : May 17, ...         18,251   \n",
       "8   Deadline for accepting applications : May 17, ...         43,681   \n",
       "9   Deadline for accepting applications : May 17, ...         43,681   \n",
       "10  Deadline for accepting applications : May 14, ...         18,251   \n",
       "11  Deadline for accepting applications : May 14, ...         18,251   \n",
       "12  Deadline for accepting applications : May 14, ...         18,251   \n",
       "13  Job Summary Responsible for managing a team to...  Not Specified   \n",
       "14  The Line Mechanic is responsible for conductin...  Not Specified   \n",
       "15  The Quality Assurance Officer is responsible f...  Not Specified   \n",
       "\n",
       "       Max Salary Min Years of Work Expirience Max Years of Work Expirience  \\\n",
       "0   Not Specified                Not Specified                Not Specified   \n",
       "1   Not Specified                Not Specified                Not Specified   \n",
       "2   Not Specified                Not Specified                Not Specified   \n",
       "3   Not Specified                Not Specified                Not Specified   \n",
       "4   Not Specified                Not Specified                Not Specified   \n",
       "5          18,251                Not Specified                Not Specified   \n",
       "6          18,251                Not Specified                Not Specified   \n",
       "7          18,251                Not Specified                Not Specified   \n",
       "8          43,681                Not Specified                Not Specified   \n",
       "9          43,681                Not Specified                Not Specified   \n",
       "10         18,251                Not Specified                Not Specified   \n",
       "11         18,251                Not Specified                Not Specified   \n",
       "12         18,251                Not Specified                Not Specified   \n",
       "13  Not Specified                Not Specified                Not Specified   \n",
       "14  Not Specified                Not Specified                Not Specified   \n",
       "15  Not Specified                Not Specified                Not Specified   \n",
       "\n",
       "          Field  \n",
       "0   Mathematics  \n",
       "1   Mathematics  \n",
       "2   Mathematics  \n",
       "3   Mathematics  \n",
       "4   Mathematics  \n",
       "5   Mathematics  \n",
       "6   Mathematics  \n",
       "7   Mathematics  \n",
       "8   Mathematics  \n",
       "9   Mathematics  \n",
       "10  Mathematics  \n",
       "11  Mathematics  \n",
       "12  Mathematics  \n",
       "13  Mathematics  \n",
       "14  Mathematics  \n",
       "15  Mathematics  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Data Frame for Aviation (JOBLUM) \n",
    "AVI={'Website': \"Joblum\",\n",
    "      'Job Title': AVI_TITLE_LIST, \n",
    "      'Category': \"Aviation\", \n",
    "      'Company': AVI_COMPANY_LIST, \n",
    "      'Date Posted': AVI_DATE_LIST, \n",
    "      'Location': AVI_LOCATION_LIST, \n",
    "      'Status': AVI_STATUS_LIST, \n",
    "      'Salary': AVI_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': AVI_DESCRIPTION_LIST,\n",
    "      'Min Salary': AVI_SALARY_MIN_LIST,\n",
    "      'Max Salary': AVI_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "AVI_df = pd.DataFrame(data=AVI)\n",
    "AVI_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "indonesian-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVI_df.to_csv ('JOBLUM-AVI.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Biomedical (JOBLUM) - FIRST HALF\n",
    "\n",
    "BIOMED_TITLE_FIRST = []\n",
    "BIOMED_COMPANY_FIRST = []\n",
    "BIOMED_DATE_FIRST = []\n",
    "BIOMED_LOCATION_FIRST = []\n",
    "BIOMED_STATUS_FIRST = []\n",
    "BIOMED_SALARY_FIRST = []\n",
    "BIOMED_SALARY_MIN_FIRST = []\n",
    "BIOMED_SALARY_MAX_FIRST = []\n",
    "BIOMED_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-biomedical?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, BIOMED_TITLE_FIRST, BIOMED_COMPANY_FIRST, BIOMED_DATE_FIRST, \n",
    "              BIOMED_STATUS_FIRST, BIOMED_LOCATION_FIRST, BIOMED_SALARY_FIRST, \n",
    "              BIOMED_SALARY_MIN_FIRST, BIOMED_SALARY_MAX_FIRST, BIOMED_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Biomedical (JOBLUM) - SECOND HALF\n",
    "\n",
    "BIOMED_TITLE_SECOND = []\n",
    "BIOMED_COMPANY_SECOND = []\n",
    "BIOMED_DATE_SECOND = []\n",
    "BIOMED_LOCATION_SECOND = []\n",
    "BIOMED_STATUS_SECOND = []\n",
    "BIOMED_SALARY_SECOND = []\n",
    "BIOMED_SALARY_MIN_SECOND = []\n",
    "BIOMED_SALARY_MAX_SECOND = []\n",
    "BIOMED_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, BIOMED_TITLE_SECOND, BIOMED_COMPANY_SECOND, BIOMED_DATE_SECOND, \n",
    "              BIOMED_STATUS_SECOND, BIOMED_LOCATION_SECOND, BIOMED_SALARY_SECOND, \n",
    "              BIOMED_SALARY_MIN_SECOND, BIOMED_SALARY_MAX_SECOND, BIOMED_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Biomedical (JOBLUM) \n",
    "\n",
    "BIOMED_TITLE_LIST = np.concatenate((BIOMED_TITLE_FIRST, BIOMED_TITLE_SECOND))\n",
    "BIOMED_COMPANY_LIST = np.concatenate((BIOMED_COMPANY_FIRST, BIOMED_COMPANY_SECOND))\n",
    "BIOMED_DATE_LIST = np.concatenate((BIOMED_DATE_FIRST, BIOMED_DATE_SECOND))\n",
    "BIOMED_LOCATION_LIST = np.concatenate((BIOMED_LOCATION_FIRST, BIOMED_LOCATION_SECOND))\n",
    "BIOMED_STATUS_LIST = np.concatenate((BIOMED_STATUS_FIRST, BIOMED_STATUS_SECOND))\n",
    "BIOMED_SALARY_LIST = np.concatenate((BIOMED_SALARY_FIRST, BIOMED_SALARY_SECOND))\n",
    "BIOMED_SALARY_MIN_LIST = np.concatenate((BIOMED_SALARY_MIN_FIRST, BIOMED_SALARY_MIN_SECOND))\n",
    "BIOMED_SALARY_MAX_LIST = np.concatenate((BIOMED_SALARY_MAX_FIRST, BIOMED_SALARY_MAX_SECOND))\n",
    "BIOMED_DESCRIPTION_LIST = np.concatenate((BIOMED_DESCRIPTION_FIRST, BIOMED_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Biomedical (JOBLUM) \n",
    "BIOMED={'Website': \"Joblum\",\n",
    "      'Job Title': BIOMED_TITLE_LIST, \n",
    "      'Category': \"Biomedical\", \n",
    "      'Company': BIOMED_COMPANY_LIST, \n",
    "      'Date Posted': BIOMED_DATE_LIST, \n",
    "      'Location': BIOMED_LOCATION_LIST, \n",
    "      'Status': BIOMED_STATUS_LIST, \n",
    "      'Salary': BIOMED_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': BIOMED_DESCRIPTION_LIST,\n",
    "      'Min Salary': BIOMED_SALARY_MIN_LIST,\n",
    "      'Max Salary': BIOMED_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Medicine\"}\n",
    "BIOMED_df = pd.DataFrame(data=BIOMED)\n",
    "BIOMED_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIOMED_df.to_csv ('JOBLUM-BIOMED.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Biotechnology (JOBLUM) - FIRST HALF\n",
    "\n",
    "BIOTECH_TITLE_FIRST = []\n",
    "BIOTECH_COMPANY_FIRST = []\n",
    "BIOTECH_DATE_FIRST = []\n",
    "BIOTECH_LOCATION_FIRST = []\n",
    "BIOTECH_STATUS_FIRST = []\n",
    "BIOTECH_SALARY_FIRST = []\n",
    "BIOTECH_SALARY_MIN_FIRST = []\n",
    "BIOTECH_SALARY_MAX_FIRST = []\n",
    "BIOTECH_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-biotechnology?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, BIOTECH_TITLE_FIRST, BIOTECH_COMPANY_FIRST, BIOTECH_DATE_FIRST, \n",
    "              BIOTECH_STATUS_FIRST, BIOTECH_LOCATION_FIRST, BIOTECH_SALARY_FIRST, \n",
    "              BIOTECH_SALARY_MIN_FIRST, BIOTECH_SALARY_MAX_FIRST, BIOTECH_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Biotechnology (JOBLUM) - SECOND HALF\n",
    "\n",
    "BIOTECH_TITLE_SECOND = []\n",
    "BIOTECH_COMPANY_SECOND = []\n",
    "BIOTECH_DATE_SECOND = []\n",
    "BIOTECH_LOCATION_SECOND = []\n",
    "BIOTECH_STATUS_SECOND = []\n",
    "BIOTECH_SALARY_SECOND = []\n",
    "BIOTECH_SALARY_MIN_SECOND = []\n",
    "BIOTECH_SALARY_MAX_SECOND = []\n",
    "BIOTECH_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, BIOTECH_TITLE_SECOND, BIOTECH_COMPANY_SECOND, BIOTECH_DATE_SECOND, \n",
    "              BIOTECH_STATUS_SECOND, BIOTECH_LOCATION_SECOND, BIOTECH_SALARY_SECOND, \n",
    "              BIOTECH_SALARY_MIN_SECOND, BIOTECH_SALARY_MAX_SECOND, BIOTECH_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Biotechnology (JOBLUM) \n",
    "\n",
    "BIOTECH_TITLE_LIST = np.concatenate((BIOTECH_TITLE_FIRST, BIOTECH_TITLE_SECOND))\n",
    "BIOTECH_COMPANY_LIST = np.concatenate((BIOTECH_COMPANY_FIRST, BIOTECH_COMPANY_SECOND))\n",
    "BIOTECH_DATE_LIST = np.concatenate((BIOTECH_DATE_FIRST, BIOTECH_DATE_SECOND))\n",
    "BIOTECH_LOCATION_LIST = np.concatenate((BIOTECH_LOCATION_FIRST, BIOTECH_LOCATION_SECOND))\n",
    "BIOTECH_STATUS_LIST = np.concatenate((BIOTECH_STATUS_FIRST, BIOTECH_STATUS_SECOND))\n",
    "BIOTECH_SALARY_LIST = np.concatenate((BIOTECH_SALARY_FIRST, BIOTECH_SALARY_SECOND))\n",
    "BIOTECH_SALARY_MIN_LIST = np.concatenate((BIOTECH_SALARY_MIN_FIRST, BIOTECH_SALARY_MIN_SECOND))\n",
    "BIOTECH_SALARY_MAX_LIST = np.concatenate((BIOTECH_SALARY_MAX_FIRST, BIOTECH_SALARY_MAX_SECOND))\n",
    "BIOTECH_DESCRIPTION_LIST = np.concatenate((BIOTECH_DESCRIPTION_FIRST, BIOTECH_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Biotechnology (JOBLUM) \n",
    "BIOTECH={'Website': \"Joblum\",\n",
    "      'Job Title': BIOTECH_TITLE_LIST, \n",
    "      'Category': \"Biotechnology\", \n",
    "      'Company': BIOTECH_COMPANY_LIST, \n",
    "      'Date Posted': BIOTECH_DATE_LIST, \n",
    "      'Location': BIOTECH_LOCATION_LIST, \n",
    "      'Status': BIOTECH_STATUS_LIST, \n",
    "      'Salary': BIOTECH_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': BIOTECH_DESCRIPTION_LIST,\n",
    "      'Min Salary': BIOTECH_SALARY_MIN_LIST,\n",
    "      'Max Salary': BIOTECH_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Science\"}\n",
    "BIOTECH_df = pd.DataFrame(data=BIOTECH)\n",
    "BIOTECH_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIOTECH_df.to_csv ('JOBLUM-BIOTECH.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Chemical Engineering (JOBLUM) - FIRST HALF\n",
    "\n",
    "CHEMENG_TITLE_FIRST = []\n",
    "CHEMENG_COMPANY_FIRST = []\n",
    "CHEMENG_DATE_FIRST = []\n",
    "CHEMENG_LOCATION_FIRST = []\n",
    "CHEMENG_STATUS_FIRST = []\n",
    "CHEMENG_SALARY_FIRST = []\n",
    "CHEMENG_SALARY_MIN_FIRST = []\n",
    "CHEMENG_SALARY_MAX_FIRST = []\n",
    "CHEMENG_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-chemical-engineering?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, CHEMENG_TITLE_FIRST, CHEMENG_COMPANY_FIRST, CHEMENG_DATE_FIRST, \n",
    "              CHEMENG_STATUS_FIRST, CHEMENG_LOCATION_FIRST, CHEMENG_SALARY_FIRST, \n",
    "              CHEMENG_SALARY_MIN_FIRST, CHEMENG_SALARY_MAX_FIRST, CHEMENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Chemical Engineering (JOBLUM) - SECOND HALF\n",
    "\n",
    "CHEMENG_TITLE_SECOND = []\n",
    "CHEMENG_COMPANY_SECOND = []\n",
    "CHEMENG_DATE_SECOND = []\n",
    "CHEMENG_LOCATION_SECOND = []\n",
    "CHEMENG_STATUS_SECOND = []\n",
    "CHEMENG_SALARY_SECOND = []\n",
    "CHEMENG_SALARY_MIN_SECOND = []\n",
    "CHEMENG_SALARY_MAX_SECOND = []\n",
    "CHEMENG_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, CHEMENG_TITLE_SECOND, CHEMENG_COMPANY_SECOND, CHEMENG_DATE_SECOND, \n",
    "              CHEMENG_STATUS_SECOND, CHEMENG_LOCATION_SECOND, CHEMENG_SALARY_SECOND, \n",
    "              CHEMENG_SALARY_MIN_SECOND, CHEMENG_SALARY_MAX_SECOND, CHEMENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Chemical Engineering (JOBLUM) \n",
    "\n",
    "CHEMENG_TITLE_LIST = np.concatenate((CHEMENG_TITLE_FIRST, CHEMENG_TITLE_SECOND))\n",
    "CHEMENG_COMPANY_LIST = np.concatenate((CHEMENG_COMPANY_FIRST, CHEMENG_COMPANY_SECOND))\n",
    "CHEMENG_DATE_LIST = np.concatenate((CHEMENG_DATE_FIRST, CHEMENG_DATE_SECOND))\n",
    "CHEMENG_LOCATION_LIST = np.concatenate((CHEMENG_LOCATION_FIRST, CHEMENG_LOCATION_SECOND))\n",
    "CHEMENG_STATUS_LIST = np.concatenate((CHEMENG_STATUS_FIRST, CHEMENG_STATUS_SECOND))\n",
    "CHEMENG_SALARY_LIST = np.concatenate((CHEMENG_SALARY_FIRST, CHEMENG_SALARY_SECOND))\n",
    "CHEMENG_SALARY_MIN_LIST = np.concatenate((CHEMENG_SALARY_MIN_FIRST, CHEMENG_SALARY_MIN_SECOND))\n",
    "CHEMENG_SALARY_MAX_LIST = np.concatenate((CHEMENG_SALARY_MAX_FIRST, CHEMENG_SALARY_MAX_SECOND))\n",
    "CHEMENG_DESCRIPTION_LIST = np.concatenate((CHEMENG_DESCRIPTION_FIRST, CHEMENG_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Chemical Engineering (JOBLUM) \n",
    "CHEMENG={'Website': \"Joblum\",\n",
    "      'Job Title': CHEMENG_TITLE_LIST, \n",
    "      'Category': \"Chemical Engineering\", \n",
    "      'Company': CHEMENG_COMPANY_LIST, \n",
    "      'Date Posted': CHEMENG_DATE_LIST, \n",
    "      'Location': CHEMENG_LOCATION_LIST, \n",
    "      'Status': CHEMENG_STATUS_LIST, \n",
    "      'Salary': CHEMENG_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': CHEMENG_DESCRIPTION_LIST,\n",
    "      'Min Salary': CHEMENG_SALARY_MIN_LIST,\n",
    "      'Max Salary': CHEMENG_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "CHEMENG_df = pd.DataFrame(data=CHEMENG)\n",
    "CHEMENG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHEMENG_df.to_csv ('JOBLUM-CHEMENG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Chemistry (JOBLUM) - FIRST HALF\n",
    "\n",
    "CHEM_TITLE_FIRST = []\n",
    "CHEM_COMPANY_FIRST = []\n",
    "CHEM_DATE_FIRST = []\n",
    "CHEM_LOCATION_FIRST = []\n",
    "CHEM_STATUS_FIRST = []\n",
    "CHEM_SALARY_FIRST = []\n",
    "CHEM_SALARY_MIN_FIRST = []\n",
    "CHEM_SALARY_MAX_FIRST = []\n",
    "CHEM_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-chemistry?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, CHEM_TITLE_FIRST, CHEM_COMPANY_FIRST, CHEM_DATE_FIRST, \n",
    "              CHEM_STATUS_FIRST, CHEM_LOCATION_FIRST, CHEM_SALARY_FIRST, \n",
    "              CHEM_SALARY_MIN_FIRST, CHEM_SALARY_MAX_FIRST, CHEM_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Chemistry (JOBLUM) - SECOND HALF\n",
    "\n",
    "CHEM_TITLE_SECOND = []\n",
    "CHEM_COMPANY_SECOND = []\n",
    "CHEM_DATE_SECOND = []\n",
    "CHEM_LOCATION_SECOND = []\n",
    "CHEM_STATUS_SECOND = []\n",
    "CHEM_SALARY_SECOND = []\n",
    "CHEM_SALARY_MIN_SECOND = []\n",
    "CHEM_SALARY_MAX_SECOND = []\n",
    "CHEM_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, CHEM_TITLE_SECOND, CHEM_COMPANY_SECOND, CHEM_DATE_SECOND, \n",
    "              CHEM_STATUS_SECOND, CHEM_LOCATION_SECOND, CHEM_SALARY_SECOND, \n",
    "              CHEM_SALARY_MIN_SECOND, CHEM_SALARY_MAX_SECOND, CHEM_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Chemistry (JOBLUM) \n",
    "\n",
    "CHEM_TITLE_LIST = np.concatenate((CHEM_TITLE_FIRST, CHEM_TITLE_SECOND))\n",
    "CHEM_COMPANY_LIST = np.concatenate((CHEM_COMPANY_FIRST, CHEM_COMPANY_SECOND))\n",
    "CHEM_DATE_LIST = np.concatenate((CHEM_DATE_FIRST, CHEM_DATE_SECOND))\n",
    "CHEM_LOCATION_LIST = np.concatenate((CHEM_LOCATION_FIRST, CHEM_LOCATION_SECOND))\n",
    "CHEM_STATUS_LIST = np.concatenate((CHEM_STATUS_FIRST, CHEM_STATUS_SECOND))\n",
    "CHEM_SALARY_LIST = np.concatenate((CHEM_SALARY_FIRST, CHEM_SALARY_SECOND))\n",
    "CHEM_SALARY_MIN_LIST = np.concatenate((CHEM_SALARY_MIN_FIRST, CHEM_SALARY_MIN_SECOND))\n",
    "CHEM_SALARY_MAX_LIST = np.concatenate((CHEM_SALARY_MAX_FIRST, CHEM_SALARY_MAX_SECOND))\n",
    "CHEM_DESCRIPTION_LIST = np.concatenate((CHEM_DESCRIPTION_FIRST, CHEM_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Chemistry (JOBLUM) \n",
    "CHEM={'Website': \"Joblum\",\n",
    "      'Job Title': CHEM_TITLE_LIST, \n",
    "      'Category': \"Chemistry\", \n",
    "      'Company': CHEM_COMPANY_LIST, \n",
    "      'Date Posted': CHEM_DATE_LIST, \n",
    "      'Location': CHEM_LOCATION_LIST, \n",
    "      'Status': CHEM_STATUS_LIST, \n",
    "      'Salary': CHEM_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': CHEM_DESCRIPTION_LIST,\n",
    "      'Min Salary': CHEM_SALARY_MIN_LIST,\n",
    "      'Max Salary': CHEM_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Science\"}\n",
    "CHEM_df = pd.DataFrame(data=CHEM)\n",
    "CHEM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHEM_df.to_csv ('JOBLUM-CHEM.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Civil Engineering/Construction (JOBLUM) - FIRST HALF\n",
    "\n",
    "CIVILENG_TITLE_FIRST = []\n",
    "CIVILENG_COMPANY_FIRST = []\n",
    "CIVILENG_DATE_FIRST = []\n",
    "CIVILENG_LOCATION_FIRST = []\n",
    "CIVILENG_STATUS_FIRST = []\n",
    "CIVILENG_SALARY_FIRST = []\n",
    "CIVILENG_SALARY_MIN_FIRST = []\n",
    "CIVILENG_SALARY_MAX_FIRST = []\n",
    "CIVILENG_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-civil-engineering-construction?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, CIVILENG_TITLE_FIRST, CIVILENG_COMPANY_FIRST, CIVILENG_DATE_FIRST, \n",
    "              CIVILENG_STATUS_FIRST, CIVILENG_LOCATION_FIRST, CIVILENG_SALARY_FIRST, \n",
    "              CIVILENG_SALARY_MIN_FIRST, CIVILENG_SALARY_MAX_FIRST, CIVILENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Civil Engineering/Construction (JOBLUM) - SECOND HALF\n",
    "\n",
    "CIVILENG_TITLE_SECOND = []\n",
    "CIVILENG_COMPANY_SECOND = []\n",
    "CIVILENG_DATE_SECOND = []\n",
    "CIVILENG_LOCATION_SECOND = []\n",
    "CIVILENG_STATUS_SECOND = []\n",
    "CIVILENG_SALARY_SECOND = []\n",
    "CIVILENG_SALARY_MIN_SECOND = []\n",
    "CIVILENG_SALARY_MAX_SECOND = []\n",
    "CIVILENG_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, CIVILENG_TITLE_SECOND, CIVILENG_COMPANY_SECOND, CIVILENG_DATE_SECOND, \n",
    "              CIVILENG_STATUS_SECOND, CIVILENG_LOCATION_SECOND, CIVILENG_SALARY_SECOND, \n",
    "              CIVILENG_SALARY_MIN_SECOND, CIVILENG_SALARY_MAX_SECOND, CIVILENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Civil Engineering/Construction (JOBLUM) \n",
    "\n",
    "CIVILENG_TITLE_LIST = np.concatenate((CIVILENG_TITLE_FIRST, CIVILENG_TITLE_SECOND))\n",
    "CIVILENG_COMPANY_LIST = np.concatenate((CIVILENG_COMPANY_FIRST, CIVILENG_COMPANY_SECOND))\n",
    "CIVILENG_DATE_LIST = np.concatenate((CIVILENG_DATE_FIRST, CIVILENG_DATE_SECOND))\n",
    "CIVILENG_LOCATION_LIST = np.concatenate((CIVILENG_LOCATION_FIRST, CIVILENG_LOCATION_SECOND))\n",
    "CIVILENG_STATUS_LIST = np.concatenate((CIVILENG_STATUS_FIRST, CIVILENG_STATUS_SECOND))\n",
    "CIVILENG_SALARY_LIST = np.concatenate((CIVILENG_SALARY_FIRST, CIVILENG_SALARY_SECOND))\n",
    "CIVILENG_SALARY_MIN_LIST = np.concatenate((CIVILENG_SALARY_MIN_FIRST, CIVILENG_SALARY_MIN_SECOND))\n",
    "CIVILENG_SALARY_MAX_LIST = np.concatenate((CIVILENG_SALARY_MAX_FIRST, CIVILENG_SALARY_MAX_SECOND))\n",
    "CIVILENG_DESCRIPTION_LIST = np.concatenate((CIVILENG_DESCRIPTION_FIRST, CIVILENG_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Civil Engineering/Construction (JOBLUM) \n",
    "CIVILENG={'Website': \"Joblum\",\n",
    "      'Job Title': CIVILENG_TITLE_LIST, \n",
    "      'Category': \"Civil Engineering/Construction\", \n",
    "      'Company': CIVILENG_COMPANY_LIST, \n",
    "      'Date Posted': CIVILENG_DATE_LIST, \n",
    "      'Location': CIVILENG_LOCATION_LIST, \n",
    "      'Status': CIVILENG_STATUS_LIST, \n",
    "      'Salary': CIVILENG_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': CIVILENG_DESCRIPTION_LIST,\n",
    "      'Min Salary': CIVILENG_SALARY_MIN_LIST,\n",
    "      'Max Salary': CIVILENG_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "CIVILENG_df = pd.DataFrame(data=CIVILENG)\n",
    "CIVILENG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIVILENG_df.to_csv ('JOBLUM-CIVILENG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Civil/Construction (JOBLUM) - FIRST HALF\n",
    "\n",
    "CONSTRUCTION_TITLE_FIRST = []\n",
    "CONSTRUCTION_COMPANY_FIRST = []\n",
    "CONSTRUCTION_DATE_FIRST = []\n",
    "CONSTRUCTION_LOCATION_FIRST = []\n",
    "CONSTRUCTION_STATUS_FIRST = []\n",
    "CONSTRUCTION_SALARY_FIRST = []\n",
    "CONSTRUCTION_SALARY_MIN_FIRST = []\n",
    "CONSTRUCTION_SALARY_MAX_FIRST = []\n",
    "CONSTRUCTION_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-civil-construction?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, CONSTRUCTION_TITLE_FIRST, CONSTRUCTION_COMPANY_FIRST, CONSTRUCTION_DATE_FIRST, \n",
    "              CONSTRUCTION_STATUS_FIRST, CONSTRUCTION_LOCATION_FIRST, CONSTRUCTION_SALARY_FIRST, \n",
    "              CONSTRUCTION_SALARY_MIN_FIRST, CONSTRUCTION_SALARY_MAX_FIRST, CONSTRUCTION_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Civil/Construction (JOBLUM) - SECOND HALF\n",
    "\n",
    "CONSTRUCTION_TITLE_SECOND = []\n",
    "CONSTRUCTION_COMPANY_SECOND = []\n",
    "CONSTRUCTION_DATE_SECOND = []\n",
    "CONSTRUCTION_LOCATION_SECOND = []\n",
    "CONSTRUCTION_STATUS_SECOND = []\n",
    "CONSTRUCTION_SALARY_SECOND = []\n",
    "CONSTRUCTION_SALARY_MIN_SECOND = []\n",
    "CONSTRUCTION_SALARY_MAX_SECOND = []\n",
    "CONSTRUCTION_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, CONSTRUCTION_TITLE_SECOND, CONSTRUCTION_COMPANY_SECOND, CONSTRUCTION_DATE_SECOND, \n",
    "              CONSTRUCTION_STATUS_SECOND, CONSTRUCTION_LOCATION_SECOND, CONSTRUCTION_SALARY_SECOND, \n",
    "              CONSTRUCTION_SALARY_MIN_SECOND, CONSTRUCTION_SALARY_MAX_SECOND, CONSTRUCTION_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Civil/Construction (JOBLUM) \n",
    "\n",
    "CONSTRUCTION_TITLE_LIST = np.concatenate((CONSTRUCTION_TITLE_FIRST, CONSTRUCTION_TITLE_SECOND))\n",
    "CONSTRUCTION_COMPANY_LIST = np.concatenate((CONSTRUCTION_COMPANY_FIRST, CONSTRUCTION_COMPANY_SECOND))\n",
    "CONSTRUCTION_DATE_LIST = np.concatenate((CONSTRUCTION_DATE_FIRST, CONSTRUCTION_DATE_SECOND))\n",
    "CONSTRUCTION_LOCATION_LIST = np.concatenate((CONSTRUCTION_LOCATION_FIRST, CONSTRUCTION_LOCATION_SECOND))\n",
    "CONSTRUCTION_STATUS_LIST = np.concatenate((CONSTRUCTION_STATUS_FIRST, CONSTRUCTION_STATUS_SECOND))\n",
    "CONSTRUCTION_SALARY_LIST = np.concatenate((CONSTRUCTION_SALARY_FIRST, CONSTRUCTION_SALARY_SECOND))\n",
    "CONSTRUCTION_SALARY_MIN_LIST = np.concatenate((CONSTRUCTION_SALARY_MIN_FIRST, CONSTRUCTION_SALARY_MIN_SECOND))\n",
    "CONSTRUCTION_SALARY_MAX_LIST = np.concatenate((CONSTRUCTION_SALARY_MAX_FIRST, CONSTRUCTION_SALARY_MAX_SECOND))\n",
    "CONSTRUCTION_DESCRIPTION_LIST = np.concatenate((CONSTRUCTION_DESCRIPTION_FIRST, CONSTRUCTION_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Civil/Construction (JOBLUM) \n",
    "CONSTRUCTION={'Website': \"Joblum\",\n",
    "      'Job Title': CONSTRUCTION_TITLE_LIST, \n",
    "      'Category': \"Civil/Construction\", \n",
    "      'Company': CONSTRUCTION_COMPANY_LIST, \n",
    "      'Date Posted': CONSTRUCTION_DATE_LIST, \n",
    "      'Location': CONSTRUCTION_LOCATION_LIST, \n",
    "      'Status': CONSTRUCTION_STATUS_LIST, \n",
    "      'Salary': CONSTRUCTION_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': CONSTRUCTION_DESCRIPTION_LIST,\n",
    "      'Min Salary': CONSTRUCTION_SALARY_MIN_LIST,\n",
    "      'Max Salary': CONSTRUCTION_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "CONSTRUCTION_df = pd.DataFrame(data=CONSTRUCTION)\n",
    "CONSTRUCTION_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSTRUCTION_df.to_csv ('JOBLUM-CONSTRUCTION.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Diagnosis/Others (JOBLUM) - FIRST HALF\n",
    "\n",
    "DIAGNOSIS_TITLE_FIRST = []\n",
    "DIAGNOSIS_COMPANY_FIRST = []\n",
    "DIAGNOSIS_DATE_FIRST = []\n",
    "DIAGNOSIS_LOCATION_FIRST = []\n",
    "DIAGNOSIS_STATUS_FIRST = []\n",
    "DIAGNOSIS_SALARY_FIRST = []\n",
    "DIAGNOSIS_SALARY_MIN_FIRST = []\n",
    "DIAGNOSIS_SALARY_MAX_FIRST = []\n",
    "DIAGNOSIS_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-diagnosis-others?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, DIAGNOSIS_TITLE_FIRST, DIAGNOSIS_COMPANY_FIRST, DIAGNOSIS_DATE_FIRST, \n",
    "              DIAGNOSIS_STATUS_FIRST, DIAGNOSIS_LOCATION_FIRST, DIAGNOSIS_SALARY_FIRST, \n",
    "              DIAGNOSIS_SALARY_MIN_FIRST, DIAGNOSIS_SALARY_MAX_FIRST, DIAGNOSIS_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Diagnosis/Others (JOBLUM) - SECOND HALF\n",
    "\n",
    "DIAGNOSIS_TITLE_SECOND = []\n",
    "DIAGNOSIS_COMPANY_SECOND = []\n",
    "DIAGNOSIS_DATE_SECOND = []\n",
    "DIAGNOSIS_LOCATION_SECOND = []\n",
    "DIAGNOSIS_STATUS_SECOND = []\n",
    "DIAGNOSIS_SALARY_SECOND = []\n",
    "DIAGNOSIS_SALARY_MIN_SECOND = []\n",
    "DIAGNOSIS_SALARY_MAX_SECOND = []\n",
    "DIAGNOSIS_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, DIAGNOSIS_TITLE_SECOND, DIAGNOSIS_COMPANY_SECOND, DIAGNOSIS_DATE_SECOND, \n",
    "              DIAGNOSIS_STATUS_SECOND, DIAGNOSIS_LOCATION_SECOND, DIAGNOSIS_SALARY_SECOND, \n",
    "              DIAGNOSIS_SALARY_MIN_SECOND, DIAGNOSIS_SALARY_MAX_SECOND, DIAGNOSIS_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Diagnosis/Others (JOBLUM) \n",
    "\n",
    "DIAGNOSIS_TITLE_LIST = np.concatenate((DIAGNOSIS_TITLE_FIRST, DIAGNOSIS_TITLE_SECOND))\n",
    "DIAGNOSIS_COMPANY_LIST = np.concatenate((DIAGNOSIS_COMPANY_FIRST, DIAGNOSIS_COMPANY_SECOND))\n",
    "DIAGNOSIS_DATE_LIST = np.concatenate((DIAGNOSIS_DATE_FIRST, DIAGNOSIS_DATE_SECOND))\n",
    "DIAGNOSIS_LOCATION_LIST = np.concatenate((DIAGNOSIS_LOCATION_FIRST, DIAGNOSIS_LOCATION_SECOND))\n",
    "DIAGNOSIS_STATUS_LIST = np.concatenate((DIAGNOSIS_STATUS_FIRST, DIAGNOSIS_STATUS_SECOND))\n",
    "DIAGNOSIS_SALARY_LIST = np.concatenate((DIAGNOSIS_SALARY_FIRST, DIAGNOSIS_SALARY_SECOND))\n",
    "DIAGNOSIS_SALARY_MIN_LIST = np.concatenate((DIAGNOSIS_SALARY_MIN_FIRST, DIAGNOSIS_SALARY_MIN_SECOND))\n",
    "DIAGNOSIS_SALARY_MAX_LIST = np.concatenate((DIAGNOSIS_SALARY_MAX_FIRST, DIAGNOSIS_SALARY_MAX_SECOND))\n",
    "DIAGNOSIS_DESCRIPTION_LIST = np.concatenate((DIAGNOSIS_DESCRIPTION_FIRST, DIAGNOSIS_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Diagnosis/Others (JOBLUM) \n",
    "DIAGNOSIS={'Website': \"Joblum\",\n",
    "      'Job Title': DIAGNOSIS_TITLE_LIST, \n",
    "      'Category': \"Diagnosis/Others\", \n",
    "      'Company': DIAGNOSIS_COMPANY_LIST, \n",
    "      'Date Posted': DIAGNOSIS_DATE_LIST, \n",
    "      'Location': DIAGNOSIS_LOCATION_LIST, \n",
    "      'Status': DIAGNOSIS_STATUS_LIST, \n",
    "      'Salary': DIAGNOSIS_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': DIAGNOSIS_DESCRIPTION_LIST,\n",
    "      'Min Salary': DIAGNOSIS_SALARY_MIN_LIST,\n",
    "      'Max Salary': DIAGNOSIS_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Medicine\"}\n",
    "DIAGNOSIS_df = pd.DataFrame(data=DIAGNOSIS)\n",
    "DIAGNOSIS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIAGNOSIS_df.to_csv ('JOBLUM-DIAGNOSIS.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Doctor/Diagnosis (JOBLUM) - FIRST HALF\n",
    "\n",
    "DOCTOR_TITLE_FIRST = []\n",
    "DOCTOR_COMPANY_FIRST = []\n",
    "DOCTOR_DATE_FIRST = []\n",
    "DOCTOR_LOCATION_FIRST = []\n",
    "DOCTOR_STATUS_FIRST = []\n",
    "DOCTOR_SALARY_FIRST = []\n",
    "DOCTOR_SALARY_MIN_FIRST = []\n",
    "DOCTOR_SALARY_MAX_FIRST = []\n",
    "DOCTOR_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-doctor-diagnosis?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, DOCTOR_TITLE_FIRST, DOCTOR_COMPANY_FIRST, DOCTOR_DATE_FIRST, \n",
    "              DOCTOR_STATUS_FIRST, DOCTOR_LOCATION_FIRST, DOCTOR_SALARY_FIRST, \n",
    "              DOCTOR_SALARY_MIN_FIRST, DOCTOR_SALARY_MAX_FIRST, DOCTOR_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Doctor/Diagnosis (JOBLUM) - SECOND HALF\n",
    "\n",
    "DOCTOR_TITLE_SECOND = []\n",
    "DOCTOR_COMPANY_SECOND = []\n",
    "DOCTOR_DATE_SECOND = []\n",
    "DOCTOR_LOCATION_SECOND = []\n",
    "DOCTOR_STATUS_SECOND = []\n",
    "DOCTOR_SALARY_SECOND = []\n",
    "DOCTOR_SALARY_MIN_SECOND = []\n",
    "DOCTOR_SALARY_MAX_SECOND = []\n",
    "DOCTOR_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, DOCTOR_TITLE_SECOND, DOCTOR_COMPANY_SECOND, DOCTOR_DATE_SECOND, \n",
    "              DOCTOR_STATUS_SECOND, DOCTOR_LOCATION_SECOND, DOCTOR_SALARY_SECOND, \n",
    "              DOCTOR_SALARY_MIN_SECOND, DOCTOR_SALARY_MAX_SECOND, DOCTOR_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Doctor/Diagnosis (JOBLUM) \n",
    "\n",
    "DOCTOR_TITLE_LIST = np.concatenate((DOCTOR_TITLE_FIRST, DOCTOR_TITLE_SECOND))\n",
    "DOCTOR_COMPANY_LIST = np.concatenate((DOCTOR_COMPANY_FIRST, DOCTOR_COMPANY_SECOND))\n",
    "DOCTOR_DATE_LIST = np.concatenate((DOCTOR_DATE_FIRST, DOCTOR_DATE_SECOND))\n",
    "DOCTOR_LOCATION_LIST = np.concatenate((DOCTOR_LOCATION_FIRST, DOCTOR_LOCATION_SECOND))\n",
    "DOCTOR_STATUS_LIST = np.concatenate((DOCTOR_STATUS_FIRST, DOCTOR_STATUS_SECOND))\n",
    "DOCTOR_SALARY_LIST = np.concatenate((DOCTOR_SALARY_FIRST, DOCTOR_SALARY_SECOND))\n",
    "DOCTOR_SALARY_MIN_LIST = np.concatenate((DOCTOR_SALARY_MIN_FIRST, DOCTOR_SALARY_MIN_SECOND))\n",
    "DOCTOR_SALARY_MAX_LIST = np.concatenate((DOCTOR_SALARY_MAX_FIRST, DOCTOR_SALARY_MAX_SECOND))\n",
    "DOCTOR_DESCRIPTION_LIST = np.concatenate((DOCTOR_DESCRIPTION_FIRST, DOCTOR_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Doctor/Diagnosis (JOBLUM) \n",
    "DOCTOR={'Website': \"Joblum\",\n",
    "      'Job Title': DOCTOR_TITLE_LIST, \n",
    "      'Category': \"Doctor/DOCTOR\", \n",
    "      'Company': DOCTOR_COMPANY_LIST, \n",
    "      'Date Posted': DOCTOR_DATE_LIST, \n",
    "      'Location': DOCTOR_LOCATION_LIST, \n",
    "      'Status': DOCTOR_STATUS_LIST, \n",
    "      'Salary': DOCTOR_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': DOCTOR_DESCRIPTION_LIST,\n",
    "      'Min Salary': DOCTOR_SALARY_MIN_LIST,\n",
    "      'Max Salary': DOCTOR_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Medicine\"}\n",
    "DOCTOR_df = pd.DataFrame(data=DOCTOR)\n",
    "DOCTOR_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCTOR_df.to_csv ('JOBLUM-DOCTOR.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Electrical (JOBLUM) - FIRST HALF\n",
    "\n",
    "ELEC_TITLE_FIRST = []\n",
    "ELEC_COMPANY_FIRST = []\n",
    "ELEC_DATE_FIRST = []\n",
    "ELEC_LOCATION_FIRST = []\n",
    "ELEC_STATUS_FIRST = []\n",
    "ELEC_SALARY_FIRST = []\n",
    "ELEC_SALARY_MIN_FIRST = []\n",
    "ELEC_SALARY_MAX_FIRST = []\n",
    "ELEC_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-electrical?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ELEC_TITLE_FIRST, ELEC_COMPANY_FIRST, ELEC_DATE_FIRST, \n",
    "              ELEC_STATUS_FIRST, ELEC_LOCATION_FIRST, ELEC_SALARY_FIRST, \n",
    "              ELEC_SALARY_MIN_FIRST, ELEC_SALARY_MAX_FIRST, ELEC_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Electrical (JOBLUM) - SECOND HALF\n",
    "\n",
    "ELEC_TITLE_SECOND = []\n",
    "ELEC_COMPANY_SECOND = []\n",
    "ELEC_DATE_SECOND = []\n",
    "ELEC_LOCATION_SECOND = []\n",
    "ELEC_STATUS_SECOND = []\n",
    "ELEC_SALARY_SECOND = []\n",
    "ELEC_SALARY_MIN_SECOND = []\n",
    "ELEC_SALARY_MAX_SECOND = []\n",
    "ELEC_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ELEC_TITLE_SECOND, ELEC_COMPANY_SECOND, ELEC_DATE_SECOND, \n",
    "              ELEC_STATUS_SECOND, ELEC_LOCATION_SECOND, ELEC_SALARY_SECOND, \n",
    "              ELEC_SALARY_MIN_SECOND, ELEC_SALARY_MAX_SECOND, ELEC_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Electrical (JOBLUM) \n",
    "\n",
    "ELEC_TITLE_LIST = np.concatenate((ELEC_TITLE_FIRST, ELEC_TITLE_SECOND))\n",
    "ELEC_COMPANY_LIST = np.concatenate((ELEC_COMPANY_FIRST, ELEC_COMPANY_SECOND))\n",
    "ELEC_DATE_LIST = np.concatenate((ELEC_DATE_FIRST, ELEC_DATE_SECOND))\n",
    "ELEC_LOCATION_LIST = np.concatenate((ELEC_LOCATION_FIRST, ELEC_LOCATION_SECOND))\n",
    "ELEC_STATUS_LIST = np.concatenate((ELEC_STATUS_FIRST, ELEC_STATUS_SECOND))\n",
    "ELEC_SALARY_LIST = np.concatenate((ELEC_SALARY_FIRST, ELEC_SALARY_SECOND))\n",
    "ELEC_SALARY_MIN_LIST = np.concatenate((ELEC_SALARY_MIN_FIRST, ELEC_SALARY_MIN_SECOND))\n",
    "ELEC_SALARY_MAX_LIST = np.concatenate((ELEC_SALARY_MAX_FIRST, ELEC_SALARY_MAX_SECOND))\n",
    "ELEC_DESCRIPTION_LIST = np.concatenate((ELEC_DESCRIPTION_FIRST, ELEC_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Electrical (JOBLUM) \n",
    "ELEC={'Website': \"Joblum\",\n",
    "      'Job Title': ELEC_TITLE_LIST, \n",
    "      'Category': \"Electrical\", \n",
    "      'Company': ELEC_COMPANY_LIST, \n",
    "      'Date Posted': ELEC_DATE_LIST, \n",
    "      'Location': ELEC_LOCATION_LIST, \n",
    "      'Status': ELEC_STATUS_LIST, \n",
    "      'Salary': ELEC_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': ELEC_DESCRIPTION_LIST,\n",
    "      'Min Salary': ELEC_SALARY_MIN_LIST,\n",
    "      'Max Salary': ELEC_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "ELEC_df = pd.DataFrame(data=ELEC)\n",
    "ELEC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELEC_df.to_csv ('JOBLUM-ELEC.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Electrical Engineering (JOBLUM) - FIRST HALF\n",
    "\n",
    "ELECENG_TITLE_FIRST = []\n",
    "ELECENG_COMPANY_FIRST = []\n",
    "ELECENG_DATE_FIRST = []\n",
    "ELECENG_LOCATION_FIRST = []\n",
    "ELECENG_STATUS_FIRST = []\n",
    "ELECENG_SALARY_FIRST = []\n",
    "ELECENG_SALARY_MIN_FIRST = []\n",
    "ELECENG_SALARY_MAX_FIRST = []\n",
    "ELECENG_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-electrical-engineering?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ELECENG_TITLE_FIRST, ELECENG_COMPANY_FIRST, ELECENG_DATE_FIRST, \n",
    "              ELECENG_STATUS_FIRST, ELECENG_LOCATION_FIRST, ELECENG_SALARY_FIRST, \n",
    "              ELECENG_SALARY_MIN_FIRST, ELECENG_SALARY_MAX_FIRST, ELECENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Electrical Engineering (JOBLUM) - SECOND HALF\n",
    "\n",
    "ELECENG_TITLE_SECOND = []\n",
    "ELECENG_COMPANY_SECOND = []\n",
    "ELECENG_DATE_SECOND = []\n",
    "ELECENG_LOCATION_SECOND = []\n",
    "ELECENG_STATUS_SECOND = []\n",
    "ELECENG_SALARY_SECOND = []\n",
    "ELECENG_SALARY_MIN_SECOND = []\n",
    "ELECENG_SALARY_MAX_SECOND = []\n",
    "ELECENG_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ELECENG_TITLE_SECOND, ELECENG_COMPANY_SECOND, ELECENG_DATE_SECOND, \n",
    "              ELECENG_STATUS_SECOND, ELECENG_LOCATION_SECOND, ELECENG_SALARY_SECOND, \n",
    "              ELECENG_SALARY_MIN_SECOND, ELECENG_SALARY_MAX_SECOND, ELECENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Electrical Engineering (JOBLUM) \n",
    "\n",
    "ELECENG_TITLE_LIST = np.concatenate((ELECENG_TITLE_FIRST, ELECENG_TITLE_SECOND))\n",
    "ELECENG_COMPANY_LIST = np.concatenate((ELECENG_COMPANY_FIRST, ELECENG_COMPANY_SECOND))\n",
    "ELECENG_DATE_LIST = np.concatenate((ELECENG_DATE_FIRST, ELECENG_DATE_SECOND))\n",
    "ELECENG_LOCATION_LIST = np.concatenate((ELECENG_LOCATION_FIRST, ELECENG_LOCATION_SECOND))\n",
    "ELECENG_STATUS_LIST = np.concatenate((ELECENG_STATUS_FIRST, ELECENG_STATUS_SECOND))\n",
    "ELECENG_SALARY_LIST = np.concatenate((ELECENG_SALARY_FIRST, ELECENG_SALARY_SECOND))\n",
    "ELECENG_SALARY_MIN_LIST = np.concatenate((ELECENG_SALARY_MIN_FIRST, ELECENG_SALARY_MIN_SECOND))\n",
    "ELECENG_SALARY_MAX_LIST = np.concatenate((ELECENG_SALARY_MAX_FIRST, ELECENG_SALARY_MAX_SECOND))\n",
    "ELECENG_DESCRIPTION_LIST = np.concatenate((ELECENG_DESCRIPTION_FIRST, ELECENG_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Electrical Engineering (JOBLUM) \n",
    "ELECENG={'Website': \"Joblum\",\n",
    "      'Job Title': ELECENG_TITLE_LIST, \n",
    "      'Category': \"Electrical Engineering\", \n",
    "      'Company': ELECENG_COMPANY_LIST, \n",
    "      'Date Posted': ELECENG_DATE_LIST, \n",
    "      'Location': ELECENG_LOCATION_LIST, \n",
    "      'Status': ELECENG_STATUS_LIST, \n",
    "      'Salary': ELECENG_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': ELECENG_DESCRIPTION_LIST,\n",
    "      'Min Salary': ELECENG_SALARY_MIN_LIST,\n",
    "      'Max Salary': ELECENG_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "ELECENG_df = pd.DataFrame(data=ELECENG)\n",
    "ELECENG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELECENG_df.to_csv ('JOBLUM-ELECENG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Electronics (JOBLUM) - FIRST HALF\n",
    "\n",
    "ELECTRO_TITLE_FIRST = []\n",
    "ELECTRO_COMPANY_FIRST = []\n",
    "ELECTRO_DATE_FIRST = []\n",
    "ELECTRO_LOCATION_FIRST = []\n",
    "ELECTRO_STATUS_FIRST = []\n",
    "ELECTRO_SALARY_FIRST = []\n",
    "ELECTRO_SALARY_MIN_FIRST = []\n",
    "ELECTRO_SALARY_MAX_FIRST = []\n",
    "ELECTRO_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-electronics?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ELECTRO_TITLE_FIRST, ELECTRO_COMPANY_FIRST, ELECTRO_DATE_FIRST, \n",
    "              ELECTRO_STATUS_FIRST, ELECTRO_LOCATION_FIRST, ELECTRO_SALARY_FIRST, \n",
    "              ELECTRO_SALARY_MIN_FIRST, ELECTRO_SALARY_MAX_FIRST, ELECTRO_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Electronics (JOBLUM) - SECOND HALF\n",
    "\n",
    "ELECTRO_TITLE_SECOND = []\n",
    "ELECTRO_COMPANY_SECOND = []\n",
    "ELECTRO_DATE_SECOND = []\n",
    "ELECTRO_LOCATION_SECOND = []\n",
    "ELECTRO_STATUS_SECOND = []\n",
    "ELECTRO_SALARY_SECOND = []\n",
    "ELECTRO_SALARY_MIN_SECOND = []\n",
    "ELECTRO_SALARY_MAX_SECOND = []\n",
    "ELECTRO_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ELECTRO_TITLE_SECOND, ELECTRO_COMPANY_SECOND, ELECTRO_DATE_SECOND, \n",
    "              ELECTRO_STATUS_SECOND, ELECTRO_LOCATION_SECOND, ELECTRO_SALARY_SECOND, \n",
    "              ELECTRO_SALARY_MIN_SECOND, ELECTRO_SALARY_MAX_SECOND, ELECTRO_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Electronics (JOBLUM) \n",
    "\n",
    "ELECTRO_TITLE_LIST = np.concatenate((ELECTRO_TITLE_FIRST, ELECTRO_TITLE_SECOND))\n",
    "ELECTRO_COMPANY_LIST = np.concatenate((ELECTRO_COMPANY_FIRST, ELECTRO_COMPANY_SECOND))\n",
    "ELECTRO_DATE_LIST = np.concatenate((ELECTRO_DATE_FIRST, ELECTRO_DATE_SECOND))\n",
    "ELECTRO_LOCATION_LIST = np.concatenate((ELECTRO_LOCATION_FIRST, ELECTRO_LOCATION_SECOND))\n",
    "ELECTRO_STATUS_LIST = np.concatenate((ELECTRO_STATUS_FIRST, ELECTRO_STATUS_SECOND))\n",
    "ELECTRO_SALARY_LIST = np.concatenate((ELECTRO_SALARY_FIRST, ELECTRO_SALARY_SECOND))\n",
    "ELECTRO_SALARY_MIN_LIST = np.concatenate((ELECTRO_SALARY_MIN_FIRST, ELECTRO_SALARY_MIN_SECOND))\n",
    "ELECTRO_SALARY_MAX_LIST = np.concatenate((ELECTRO_SALARY_MAX_FIRST, ELECTRO_SALARY_MAX_SECOND))\n",
    "ELECTRO_DESCRIPTION_LIST = np.concatenate((ELECTRO_DESCRIPTION_FIRST, ELECTRO_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Electronics (JOBLUM) \n",
    "ELECTRO={'Website': \"Joblum\",\n",
    "      'Job Title': ELECTRO_TITLE_LIST, \n",
    "      'Category': \"Electronics\", \n",
    "      'Company': ELECTRO_COMPANY_LIST, \n",
    "      'Date Posted': ELECTRO_DATE_LIST, \n",
    "      'Location': ELECTRO_LOCATION_LIST, \n",
    "      'Status': ELECTRO_STATUS_LIST, \n",
    "      'Salary': ELECTRO_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': ELECTRO_DESCRIPTION_LIST,\n",
    "      'Min Salary': ELECTRO_SALARY_MIN_LIST,\n",
    "      'Max Salary': ELECTRO_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "ELECTRO_df = pd.DataFrame(data=ELECTRO)\n",
    "ELECTRO_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELECTRO_df.to_csv ('JOBLUM-ELECTRO.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Electronics Engineering (JOBLUM) - FIRST HALF\n",
    "\n",
    "ELECTROENG_TITLE_FIRST = []\n",
    "ELECTROENG_COMPANY_FIRST = []\n",
    "ELECTROENG_DATE_FIRST = []\n",
    "ELECTROENG_LOCATION_FIRST = []\n",
    "ELECTROENG_STATUS_FIRST = []\n",
    "ELECTROENG_SALARY_FIRST = []\n",
    "ELECTROENG_SALARY_MIN_FIRST = []\n",
    "ELECTROENG_SALARY_MAX_FIRST = []\n",
    "ELECTROENG_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-electronics-engineering?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ELECTROENG_TITLE_FIRST, ELECTROENG_COMPANY_FIRST, ELECTROENG_DATE_FIRST, \n",
    "              ELECTROENG_STATUS_FIRST, ELECTROENG_LOCATION_FIRST, ELECTROENG_SALARY_FIRST, \n",
    "              ELECTROENG_SALARY_MIN_FIRST, ELECTROENG_SALARY_MAX_FIRST, ELECTROENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Electronics Engineering (JOBLUM) - SECOND HALF\n",
    "\n",
    "ELECTROENG_TITLE_SECOND = []\n",
    "ELECTROENG_COMPANY_SECOND = []\n",
    "ELECTROENG_DATE_SECOND = []\n",
    "ELECTROENG_LOCATION_SECOND = []\n",
    "ELECTROENG_STATUS_SECOND = []\n",
    "ELECTROENG_SALARY_SECOND = []\n",
    "ELECTROENG_SALARY_MIN_SECOND = []\n",
    "ELECTROENG_SALARY_MAX_SECOND = []\n",
    "ELECTROENG_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ELECTROENG_TITLE_SECOND, ELECTROENG_COMPANY_SECOND, ELECTROENG_DATE_SECOND, \n",
    "              ELECTROENG_STATUS_SECOND, ELECTROENG_LOCATION_SECOND, ELECTROENG_SALARY_SECOND, \n",
    "              ELECTROENG_SALARY_MIN_SECOND, ELECTROENG_SALARY_MAX_SECOND, ELECTROENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Electronics Engineering (JOBLUM) \n",
    "\n",
    "ELECTROENG_TITLE_LIST = np.concatenate((ELECTROENG_TITLE_FIRST, ELECTROENG_TITLE_SECOND))\n",
    "ELECTROENG_COMPANY_LIST = np.concatenate((ELECTROENG_COMPANY_FIRST, ELECTROENG_COMPANY_SECOND))\n",
    "ELECTROENG_DATE_LIST = np.concatenate((ELECTROENG_DATE_FIRST, ELECTROENG_DATE_SECOND))\n",
    "ELECTROENG_LOCATION_LIST = np.concatenate((ELECTROENG_LOCATION_FIRST, ELECTROENG_LOCATION_SECOND))\n",
    "ELECTROENG_STATUS_LIST = np.concatenate((ELECTROENG_STATUS_FIRST, ELECTROENG_STATUS_SECOND))\n",
    "ELECTROENG_SALARY_LIST = np.concatenate((ELECTROENG_SALARY_FIRST, ELECTROENG_SALARY_SECOND))\n",
    "ELECTROENG_SALARY_MIN_LIST = np.concatenate((ELECTROENG_SALARY_MIN_FIRST, ELECTROENG_SALARY_MIN_SECOND))\n",
    "ELECTROENG_SALARY_MAX_LIST = np.concatenate((ELECTROENG_SALARY_MAX_FIRST, ELECTROENG_SALARY_MAX_SECOND))\n",
    "ELECTROENG_DESCRIPTION_LIST = np.concatenate((ELECTROENG_DESCRIPTION_FIRST, ELECTROENG_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Electronics Engineering (JOBLUM) \n",
    "ELECTROENG={'Website': \"Joblum\",\n",
    "      'Job Title': ELECTROENG_TITLE_LIST, \n",
    "      'Category': \"Electronics Engineering\", \n",
    "      'Company': ELECTROENG_COMPANY_LIST, \n",
    "      'Date Posted': ELECTROENG_DATE_LIST, \n",
    "      'Location': ELECTROENG_LOCATION_LIST, \n",
    "      'Status': ELECTROENG_STATUS_LIST, \n",
    "      'Salary': ELECTROENG_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': ELECTROENG_DESCRIPTION_LIST,\n",
    "      'Min Salary': ELECTROENG_SALARY_MIN_LIST,\n",
    "      'Max Salary': ELECTROENG_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "ELECTROENG_df = pd.DataFrame(data=ELECTROENG)\n",
    "ELECTROENG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELECTROENG_df.to_csv ('JOBLUM-ELECTROENG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Environmental (JOBLUM) - FIRST HALF\n",
    "\n",
    "ENVI_TITLE_FIRST = []\n",
    "ENVI_COMPANY_FIRST = []\n",
    "ENVI_DATE_FIRST = []\n",
    "ENVI_LOCATION_FIRST = []\n",
    "ENVI_STATUS_FIRST = []\n",
    "ENVI_SALARY_FIRST = []\n",
    "ENVI_SALARY_MIN_FIRST = []\n",
    "ENVI_SALARY_MAX_FIRST = []\n",
    "ENVI_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-environmental?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ENVI_TITLE_FIRST, ENVI_COMPANY_FIRST, ENVI_DATE_FIRST, \n",
    "              ENVI_STATUS_FIRST, ENVI_LOCATION_FIRST, ENVI_SALARY_FIRST, \n",
    "              ENVI_SALARY_MIN_FIRST, ENVI_SALARY_MAX_FIRST, ENVI_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Environmental (JOBLUM) - SECOND HALF\n",
    "\n",
    "ENVI_TITLE_SECOND = []\n",
    "ENVI_COMPANY_SECOND = []\n",
    "ENVI_DATE_SECOND = []\n",
    "ENVI_LOCATION_SECOND = []\n",
    "ENVI_STATUS_SECOND = []\n",
    "ENVI_SALARY_SECOND = []\n",
    "ENVI_SALARY_MIN_SECOND = []\n",
    "ENVI_SALARY_MAX_SECOND = []\n",
    "ENVI_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ENVI_TITLE_SECOND, ENVI_COMPANY_SECOND, ENVI_DATE_SECOND, \n",
    "              ENVI_STATUS_SECOND, ENVI_LOCATION_SECOND, ENVI_SALARY_SECOND, \n",
    "              ENVI_SALARY_MIN_SECOND, ENVI_SALARY_MAX_SECOND, ENVI_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Environmental (JOBLUM) \n",
    "\n",
    "ENVI_TITLE_LIST = np.concatenate((ENVI_TITLE_FIRST, ENVI_TITLE_SECOND))\n",
    "ENVI_COMPANY_LIST = np.concatenate((ENVI_COMPANY_FIRST, ENVI_COMPANY_SECOND))\n",
    "ENVI_DATE_LIST = np.concatenate((ENVI_DATE_FIRST, ENVI_DATE_SECOND))\n",
    "ENVI_LOCATION_LIST = np.concatenate((ENVI_LOCATION_FIRST, ENVI_LOCATION_SECOND))\n",
    "ENVI_STATUS_LIST = np.concatenate((ENVI_STATUS_FIRST, ENVI_STATUS_SECOND))\n",
    "ENVI_SALARY_LIST = np.concatenate((ENVI_SALARY_FIRST, ENVI_SALARY_SECOND))\n",
    "ENVI_SALARY_MIN_LIST = np.concatenate((ENVI_SALARY_MIN_FIRST, ENVI_SALARY_MIN_SECOND))\n",
    "ENVI_SALARY_MAX_LIST = np.concatenate((ENVI_SALARY_MAX_FIRST, ENVI_SALARY_MAX_SECOND))\n",
    "ENVI_DESCRIPTION_LIST = np.concatenate((ENVI_DESCRIPTION_FIRST, ENVI_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Environmental (JOBLUM) \n",
    "ENVI={'Website': \"Joblum\",\n",
    "      'Job Title': ENVI_TITLE_LIST, \n",
    "      'Category': \"Environmental\", \n",
    "      'Company': ENVI_COMPANY_LIST, \n",
    "      'Date Posted': ENVI_DATE_LIST, \n",
    "      'Location': ENVI_LOCATION_LIST, \n",
    "      'Status': ENVI_STATUS_LIST, \n",
    "      'Salary': ENVI_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': ENVI_DESCRIPTION_LIST,\n",
    "      'Min Salary': ENVI_SALARY_MIN_LIST,\n",
    "      'Max Salary': ENVI_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Science\"}\n",
    "ENVI_df = pd.DataFrame(data=ENVI)\n",
    "ENVI_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENVI_df.to_csv ('JOBLUM-ENVI.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Environmental Engineering (JOBLUM) - FIRST HALF\n",
    "\n",
    "ENVIENG_TITLE_FIRST = []\n",
    "ENVIENG_COMPANY_FIRST = []\n",
    "ENVIENG_DATE_FIRST = []\n",
    "ENVIENG_LOCATION_FIRST = []\n",
    "ENVIENG_STATUS_FIRST = []\n",
    "ENVIENG_SALARY_FIRST = []\n",
    "ENVIENG_SALARY_MIN_FIRST = []\n",
    "ENVIENG_SALARY_MAX_FIRST = []\n",
    "ENVIENG_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-environmental-engineering?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ENVIENG_TITLE_FIRST, ENVIENG_COMPANY_FIRST, ENVIENG_DATE_FIRST, \n",
    "              ENVIENG_STATUS_FIRST, ENVIENG_LOCATION_FIRST, ENVIENG_SALARY_FIRST, \n",
    "              ENVIENG_SALARY_MIN_FIRST, ENVIENG_SALARY_MAX_FIRST, ENVIENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Environmental Engineering (JOBLUM) - SECOND HALF\n",
    "\n",
    "ENVIENG_TITLE_SECOND = []\n",
    "ENVIENG_COMPANY_SECOND = []\n",
    "ENVIENG_DATE_SECOND = []\n",
    "ENVIENG_LOCATION_SECOND = []\n",
    "ENVIENG_STATUS_SECOND = []\n",
    "ENVIENG_SALARY_SECOND = []\n",
    "ENVIENG_SALARY_MIN_SECOND = []\n",
    "ENVIENG_SALARY_MAX_SECOND = []\n",
    "ENVIENG_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ENVIENG_TITLE_SECOND, ENVIENG_COMPANY_SECOND, ENVIENG_DATE_SECOND, \n",
    "              ENVIENG_STATUS_SECOND, ENVIENG_LOCATION_SECOND, ENVIENG_SALARY_SECOND, \n",
    "              ENVIENG_SALARY_MIN_SECOND, ENVIENG_SALARY_MAX_SECOND, ENVIENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Environmental Engineering (JOBLUM) \n",
    "\n",
    "ENVIENG_TITLE_LIST = np.concatenate((ENVIENG_TITLE_FIRST, ENVIENG_TITLE_SECOND))\n",
    "ENVIENG_COMPANY_LIST = np.concatenate((ENVIENG_COMPANY_FIRST, ENVIENG_COMPANY_SECOND))\n",
    "ENVIENG_DATE_LIST = np.concatenate((ENVIENG_DATE_FIRST, ENVIENG_DATE_SECOND))\n",
    "ENVIENG_LOCATION_LIST = np.concatenate((ENVIENG_LOCATION_FIRST, ENVIENG_LOCATION_SECOND))\n",
    "ENVIENG_STATUS_LIST = np.concatenate((ENVIENG_STATUS_FIRST, ENVIENG_STATUS_SECOND))\n",
    "ENVIENG_SALARY_LIST = np.concatenate((ENVIENG_SALARY_FIRST, ENVIENG_SALARY_SECOND))\n",
    "ENVIENG_SALARY_MIN_LIST = np.concatenate((ENVIENG_SALARY_MIN_FIRST, ENVIENG_SALARY_MIN_SECOND))\n",
    "ENVIENG_SALARY_MAX_LIST = np.concatenate((ENVIENG_SALARY_MAX_FIRST, ENVIENG_SALARY_MAX_SECOND))\n",
    "ENVIENG_DESCRIPTION_LIST = np.concatenate((ENVIENG_DESCRIPTION_FIRST, ENVIENG_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Environmental Engineering (JOBLUM) \n",
    "ENVIENG={'Website': \"Joblum\",\n",
    "      'Job Title': ENVIENG_TITLE_LIST, \n",
    "      'Category': \"Environmental Engineering\", \n",
    "      'Company': ENVIENG_COMPANY_LIST, \n",
    "      'Date Posted': ENVIENG_DATE_LIST, \n",
    "      'Location': ENVIENG_LOCATION_LIST, \n",
    "      'Status': ENVIENG_STATUS_LIST, \n",
    "      'Salary': ENVIENG_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': ENVIENG_DESCRIPTION_LIST,\n",
    "      'Min Salary': ENVIENG_SALARY_MIN_LIST,\n",
    "      'Max Salary': ENVIENG_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "ENVIENG_df = pd.DataFrame(data=ENVIENG)\n",
    "ENVIENG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENVIENG_df.to_csv ('JOBLUM-ENVIENG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Food Tech/Nutritionist (JOBLUM) - FIRST HALF\n",
    "\n",
    "NUTRI_TITLE_FIRST = []\n",
    "NUTRI_COMPANY_FIRST = []\n",
    "NUTRI_DATE_FIRST = []\n",
    "NUTRI_LOCATION_FIRST = []\n",
    "NUTRI_STATUS_FIRST = []\n",
    "NUTRI_SALARY_FIRST = []\n",
    "NUTRI_SALARY_MIN_FIRST = []\n",
    "NUTRI_SALARY_MAX_FIRST = []\n",
    "NUTRI_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-food-tech-nutritionist?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, NUTRI_TITLE_FIRST, NUTRI_COMPANY_FIRST, NUTRI_DATE_FIRST, \n",
    "              NUTRI_STATUS_FIRST, NUTRI_LOCATION_FIRST, NUTRI_SALARY_FIRST, \n",
    "              NUTRI_SALARY_MIN_FIRST, NUTRI_SALARY_MAX_FIRST, NUTRI_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Food Tech/Nutritionist (JOBLUM) - SECOND HALF\n",
    "\n",
    "NUTRI_TITLE_SECOND = []\n",
    "NUTRI_COMPANY_SECOND = []\n",
    "NUTRI_DATE_SECOND = []\n",
    "NUTRI_LOCATION_SECOND = []\n",
    "NUTRI_STATUS_SECOND = []\n",
    "NUTRI_SALARY_SECOND = []\n",
    "NUTRI_SALARY_MIN_SECOND = []\n",
    "NUTRI_SALARY_MAX_SECOND = []\n",
    "NUTRI_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, NUTRI_TITLE_SECOND, NUTRI_COMPANY_SECOND, NUTRI_DATE_SECOND, \n",
    "              NUTRI_STATUS_SECOND, NUTRI_LOCATION_SECOND, NUTRI_SALARY_SECOND, \n",
    "              NUTRI_SALARY_MIN_SECOND, NUTRI_SALARY_MAX_SECOND, NUTRI_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Food Tech/Nutritionist (JOBLUM) \n",
    "\n",
    "NUTRI_TITLE_LIST = np.concatenate((NUTRI_TITLE_FIRST, NUTRI_TITLE_SECOND))\n",
    "NUTRI_COMPANY_LIST = np.concatenate((NUTRI_COMPANY_FIRST, NUTRI_COMPANY_SECOND))\n",
    "NUTRI_DATE_LIST = np.concatenate((NUTRI_DATE_FIRST, NUTRI_DATE_SECOND))\n",
    "NUTRI_LOCATION_LIST = np.concatenate((NUTRI_LOCATION_FIRST, NUTRI_LOCATION_SECOND))\n",
    "NUTRI_STATUS_LIST = np.concatenate((NUTRI_STATUS_FIRST, NUTRI_STATUS_SECOND))\n",
    "NUTRI_SALARY_LIST = np.concatenate((NUTRI_SALARY_FIRST, NUTRI_SALARY_SECOND))\n",
    "NUTRI_SALARY_MIN_LIST = np.concatenate((NUTRI_SALARY_MIN_FIRST, NUTRI_SALARY_MIN_SECOND))\n",
    "NUTRI_SALARY_MAX_LIST = np.concatenate((NUTRI_SALARY_MAX_FIRST, NUTRI_SALARY_MAX_SECOND))\n",
    "NUTRI_DESCRIPTION_LIST = np.concatenate((NUTRI_DESCRIPTION_FIRST, NUTRI_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Food Tech/Nutritionist (JOBLUM) \n",
    "NUTRI={'Website': \"Joblum\",\n",
    "      'Job Title': NUTRI_TITLE_LIST, \n",
    "      'Category': \"Food Tech/Nutritionist\", \n",
    "      'Company': NUTRI_COMPANY_LIST, \n",
    "      'Date Posted': NUTRI_DATE_LIST, \n",
    "      'Location': NUTRI_LOCATION_LIST, \n",
    "      'Status': NUTRI_STATUS_LIST, \n",
    "      'Salary': NUTRI_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': NUTRI_DESCRIPTION_LIST,\n",
    "      'Min Salary': NUTRI_SALARY_MIN_LIST,\n",
    "      'Max Salary': NUTRI_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Science\"}\n",
    "NUTRI_df = pd.DataFrame(data=NUTRI)\n",
    "NUTRI_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTRI_df.to_csv ('JOBLUM-NUTRI.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Geology/Geophysics (JOBLUM) - FIRST HALF\n",
    "\n",
    "GEO_TITLE_FIRST = []\n",
    "GEO_COMPANY_FIRST = []\n",
    "GEO_DATE_FIRST = []\n",
    "GEO_LOCATION_FIRST = []\n",
    "GEO_STATUS_FIRST = []\n",
    "GEO_SALARY_FIRST = []\n",
    "GEO_SALARY_MIN_FIRST = []\n",
    "GEO_SALARY_MAX_FIRST = []\n",
    "GEO_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-geology-geophysics?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, GEO_TITLE_FIRST, GEO_COMPANY_FIRST, GEO_DATE_FIRST, \n",
    "              GEO_STATUS_FIRST, GEO_LOCATION_FIRST, GEO_SALARY_FIRST, \n",
    "              GEO_SALARY_MIN_FIRST, GEO_SALARY_MAX_FIRST, GEO_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Geology/Geophysics (JOBLUM) - SECOND HALF\n",
    "\n",
    "GEO_TITLE_SECOND = []\n",
    "GEO_COMPANY_SECOND = []\n",
    "GEO_DATE_SECOND = []\n",
    "GEO_LOCATION_SECOND = []\n",
    "GEO_STATUS_SECOND = []\n",
    "GEO_SALARY_SECOND = []\n",
    "GEO_SALARY_MIN_SECOND = []\n",
    "GEO_SALARY_MAX_SECOND = []\n",
    "GEO_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, GEO_TITLE_SECOND, GEO_COMPANY_SECOND, GEO_DATE_SECOND, \n",
    "              GEO_STATUS_SECOND, GEO_LOCATION_SECOND, GEO_SALARY_SECOND, \n",
    "              GEO_SALARY_MIN_SECOND, GEO_SALARY_MAX_SECOND, GEO_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Geology/Geophysics (JOBLUM) \n",
    "\n",
    "GEO_TITLE_LIST = np.concatenate((GEO_TITLE_FIRST, GEO_TITLE_SECOND))\n",
    "GEO_COMPANY_LIST = np.concatenate((GEO_COMPANY_FIRST, GEO_COMPANY_SECOND))\n",
    "GEO_DATE_LIST = np.concatenate((GEO_DATE_FIRST, GEO_DATE_SECOND))\n",
    "GEO_LOCATION_LIST = np.concatenate((GEO_LOCATION_FIRST, GEO_LOCATION_SECOND))\n",
    "GEO_STATUS_LIST = np.concatenate((GEO_STATUS_FIRST, GEO_STATUS_SECOND))\n",
    "GEO_SALARY_LIST = np.concatenate((GEO_SALARY_FIRST, GEO_SALARY_SECOND))\n",
    "GEO_SALARY_MIN_LIST = np.concatenate((GEO_SALARY_MIN_FIRST, GEO_SALARY_MIN_SECOND))\n",
    "GEO_SALARY_MAX_LIST = np.concatenate((GEO_SALARY_MAX_FIRST, GEO_SALARY_MAX_SECOND))\n",
    "GEO_DESCRIPTION_LIST = np.concatenate((GEO_DESCRIPTION_FIRST, GEO_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Geology/Geophysics (JOBLUM) \n",
    "GEO={'Website': \"Joblum\",\n",
    "      'Job Title': GEO_TITLE_LIST, \n",
    "      'Category': \"Geology/Geophysics\", \n",
    "      'Company': GEO_COMPANY_LIST, \n",
    "      'Date Posted': GEO_DATE_LIST, \n",
    "      'Location': GEO_LOCATION_LIST, \n",
    "      'Status': GEO_STATUS_LIST, \n",
    "      'Salary': GEO_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': GEO_DESCRIPTION_LIST,\n",
    "      'Min Salary': GEO_SALARY_MIN_LIST,\n",
    "      'Max Salary': GEO_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Science\"}\n",
    "GEO_df = pd.DataFrame(data=GEO)\n",
    "GEO_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_df.to_csv ('JOBLUM-GEO.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Industrial Engineering (JOBLUM) - FIRST HALF\n",
    "\n",
    "INDUSENG_TITLE_FIRST = []\n",
    "INDUSENG_COMPANY_FIRST = []\n",
    "INDUSENG_DATE_FIRST = []\n",
    "INDUSENG_LOCATION_FIRST = []\n",
    "INDUSENG_STATUS_FIRST = []\n",
    "INDUSENG_SALARY_FIRST = []\n",
    "INDUSENG_SALARY_MIN_FIRST = []\n",
    "INDUSENG_SALARY_MAX_FIRST = []\n",
    "INDUSENG_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-industrial-engineering?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, INDUSENG_TITLE_FIRST, INDUSENG_COMPANY_FIRST, INDUSENG_DATE_FIRST, \n",
    "              INDUSENG_STATUS_FIRST, INDUSENG_LOCATION_FIRST, INDUSENG_SALARY_FIRST, \n",
    "              INDUSENG_SALARY_MIN_FIRST, INDUSENG_SALARY_MAX_FIRST, INDUSENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Industrial Engineering (JOBLUM) - SECOND HALF\n",
    "\n",
    "INDUSENG_TITLE_SECOND = []\n",
    "INDUSENG_COMPANY_SECOND = []\n",
    "INDUSENG_DATE_SECOND = []\n",
    "INDUSENG_LOCATION_SECOND = []\n",
    "INDUSENG_STATUS_SECOND = []\n",
    "INDUSENG_SALARY_SECOND = []\n",
    "INDUSENG_SALARY_MIN_SECOND = []\n",
    "INDUSENG_SALARY_MAX_SECOND = []\n",
    "INDUSENG_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, INDUSENG_TITLE_SECOND, INDUSENG_COMPANY_SECOND, INDUSENG_DATE_SECOND, \n",
    "              INDUSENG_STATUS_SECOND, INDUSENG_LOCATION_SECOND, INDUSENG_SALARY_SECOND, \n",
    "              INDUSENG_SALARY_MIN_SECOND, INDUSENG_SALARY_MAX_SECOND, INDUSENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Industrial Engineering (JOBLUM) \n",
    "\n",
    "INDUSENG_TITLE_LIST = np.concatenate((INDUSENG_TITLE_FIRST, INDUSENG_TITLE_SECOND))\n",
    "INDUSENG_COMPANY_LIST = np.concatenate((INDUSENG_COMPANY_FIRST, INDUSENG_COMPANY_SECOND))\n",
    "INDUSENG_DATE_LIST = np.concatenate((INDUSENG_DATE_FIRST, INDUSENG_DATE_SECOND))\n",
    "INDUSENG_LOCATION_LIST = np.concatenate((INDUSENG_LOCATION_FIRST, INDUSENG_LOCATION_SECOND))\n",
    "INDUSENG_STATUS_LIST = np.concatenate((INDUSENG_STATUS_FIRST, INDUSENG_STATUS_SECOND))\n",
    "INDUSENG_SALARY_LIST = np.concatenate((INDUSENG_SALARY_FIRST, INDUSENG_SALARY_SECOND))\n",
    "INDUSENG_SALARY_MIN_LIST = np.concatenate((INDUSENG_SALARY_MIN_FIRST, INDUSENG_SALARY_MIN_SECOND))\n",
    "INDUSENG_SALARY_MAX_LIST = np.concatenate((INDUSENG_SALARY_MAX_FIRST, INDUSENG_SALARY_MAX_SECOND))\n",
    "INDUSENG_DESCRIPTION_LIST = np.concatenate((INDUSENG_DESCRIPTION_FIRST, INDUSENG_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Industrial Engineering (JOBLUM) \n",
    "INDUSENG={'Website': \"Joblum\",\n",
    "      'Job Title': INDUSENG_TITLE_LIST, \n",
    "      'Category': \"Industrial Engineering\", \n",
    "      'Company': INDUSENG_COMPANY_LIST, \n",
    "      'Date Posted': INDUSENG_DATE_LIST, \n",
    "      'Location': INDUSENG_LOCATION_LIST, \n",
    "      'Status': INDUSENG_STATUS_LIST, \n",
    "      'Salary': INDUSENG_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': INDUSENG_DESCRIPTION_LIST,\n",
    "      'Min Salary': INDUSENG_SALARY_MIN_LIST,\n",
    "      'Max Salary': INDUSENG_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "INDUSENG_df = pd.DataFrame(data=INDUSENG)\n",
    "INDUSENG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDUSENG_df.to_csv ('JOBLUM-INDUSENG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of IT - Hardware (JOBLUM) - FIRST HALF\n",
    "\n",
    "IT_HARDWARE_TITLE_FIRST = []\n",
    "IT_HARDWARE_COMPANY_FIRST = []\n",
    "IT_HARDWARE_DATE_FIRST = []\n",
    "IT_HARDWARE_LOCATION_FIRST = []\n",
    "IT_HARDWARE_STATUS_FIRST = []\n",
    "IT_HARDWARE_SALARY_FIRST = []\n",
    "IT_HARDWARE_SALARY_MIN_FIRST = []\n",
    "IT_HARDWARE_SALARY_MAX_FIRST = []\n",
    "IT_HARDWARE_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-it-hardware?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, IT_HARDWARE_TITLE_FIRST, IT_HARDWARE_COMPANY_FIRST, IT_HARDWARE_DATE_FIRST, \n",
    "              IT_HARDWARE_STATUS_FIRST, IT_HARDWARE_LOCATION_FIRST, IT_HARDWARE_SALARY_FIRST, \n",
    "              IT_HARDWARE_SALARY_MIN_FIRST, IT_HARDWARE_SALARY_MAX_FIRST, IT_HARDWARE_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of IT - Hardware (JOBLUM) - SECOND HALF\n",
    "\n",
    "IT_HARDWARE_TITLE_SECOND = []\n",
    "IT_HARDWARE_COMPANY_SECOND = []\n",
    "IT_HARDWARE_DATE_SECOND = []\n",
    "IT_HARDWARE_LOCATION_SECOND = []\n",
    "IT_HARDWARE_STATUS_SECOND = []\n",
    "IT_HARDWARE_SALARY_SECOND = []\n",
    "IT_HARDWARE_SALARY_MIN_SECOND = []\n",
    "IT_HARDWARE_SALARY_MAX_SECOND = []\n",
    "IT_HARDWARE_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, IT_HARDWARE_TITLE_SECOND, IT_HARDWARE_COMPANY_SECOND, IT_HARDWARE_DATE_SECOND, \n",
    "              IT_HARDWARE_STATUS_SECOND, IT_HARDWARE_LOCATION_SECOND, IT_HARDWARE_SALARY_SECOND, \n",
    "              IT_HARDWARE_SALARY_MIN_SECOND, IT_HARDWARE_SALARY_MAX_SECOND, IT_HARDWARE_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of IT - Hardware (JOBLUM) \n",
    "\n",
    "IT_HARDWARE_TITLE_LIST = np.concatenate((IT_HARDWARE_TITLE_FIRST, IT_HARDWARE_TITLE_SECOND))\n",
    "IT_HARDWARE_COMPANY_LIST = np.concatenate((IT_HARDWARE_COMPANY_FIRST, IT_HARDWARE_COMPANY_SECOND))\n",
    "IT_HARDWARE_DATE_LIST = np.concatenate((IT_HARDWARE_DATE_FIRST, IT_HARDWARE_DATE_SECOND))\n",
    "IT_HARDWARE_LOCATION_LIST = np.concatenate((IT_HARDWARE_LOCATION_FIRST, IT_HARDWARE_LOCATION_SECOND))\n",
    "IT_HARDWARE_STATUS_LIST = np.concatenate((IT_HARDWARE_STATUS_FIRST, IT_HARDWARE_STATUS_SECOND))\n",
    "IT_HARDWARE_SALARY_LIST = np.concatenate((IT_HARDWARE_SALARY_FIRST, IT_HARDWARE_SALARY_SECOND))\n",
    "IT_HARDWARE_SALARY_MIN_LIST = np.concatenate((IT_HARDWARE_SALARY_MIN_FIRST, IT_HARDWARE_SALARY_MIN_SECOND))\n",
    "IT_HARDWARE_SALARY_MAX_LIST = np.concatenate((IT_HARDWARE_SALARY_MAX_FIRST, IT_HARDWARE_SALARY_MAX_SECOND))\n",
    "IT_HARDWARE_DESCRIPTION_LIST = np.concatenate((IT_HARDWARE_DESCRIPTION_FIRST, IT_HARDWARE_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for IT - Hardware (JOBLUM) \n",
    "IT_HARDWARE={'Website': \"Joblum\",\n",
    "      'Job Title': IT_HARDWARE_TITLE_LIST, \n",
    "      'Category': \"IT - Hardware\", \n",
    "      'Company': IT_HARDWARE_COMPANY_LIST, \n",
    "      'Date Posted': IT_HARDWARE_DATE_LIST, \n",
    "      'Location': IT_HARDWARE_LOCATION_LIST, \n",
    "      'Status': IT_HARDWARE_STATUS_LIST, \n",
    "      'Salary': IT_HARDWARE_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': IT_HARDWARE_DESCRIPTION_LIST,\n",
    "      'Min Salary': IT_HARDWARE_SALARY_MIN_LIST,\n",
    "      'Max Salary': IT_HARDWARE_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"IT\"}\n",
    "IT_HARDWARE_df = pd.DataFrame(data=IT_HARDWARE)\n",
    "IT_HARDWARE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "IT_HARDWARE_df.to_csv ('JOBLUM-IT_HARDWARE.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of IT - Network/Sys/DB Admin (JOBLUM) - FIRST HALF\n",
    "\n",
    "IT_SYS_TITLE_FIRST = []\n",
    "IT_SYS_COMPANY_FIRST = []\n",
    "IT_SYS_DATE_FIRST = []\n",
    "IT_SYS_LOCATION_FIRST = []\n",
    "IT_SYS_STATUS_FIRST = []\n",
    "IT_SYS_SALARY_FIRST = []\n",
    "IT_SYS_SALARY_MIN_FIRST = []\n",
    "IT_SYS_SALARY_MAX_FIRST = []\n",
    "IT_SYS_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-it-network-sys-db-admin?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, IT_SYS_TITLE_FIRST, IT_SYS_COMPANY_FIRST, IT_SYS_DATE_FIRST, \n",
    "              IT_SYS_STATUS_FIRST, IT_SYS_LOCATION_FIRST, IT_SYS_SALARY_FIRST, \n",
    "              IT_SYS_SALARY_MIN_FIRST, IT_SYS_SALARY_MAX_FIRST, IT_SYS_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of IT - Network/Sys/DB Admin (JOBLUM) - SECOND HALF\n",
    "\n",
    "IT_SYS_TITLE_SECOND = []\n",
    "IT_SYS_COMPANY_SECOND = []\n",
    "IT_SYS_DATE_SECOND = []\n",
    "IT_SYS_LOCATION_SECOND = []\n",
    "IT_SYS_STATUS_SECOND = []\n",
    "IT_SYS_SALARY_SECOND = []\n",
    "IT_SYS_SALARY_MIN_SECOND = []\n",
    "IT_SYS_SALARY_MAX_SECOND = []\n",
    "IT_SYS_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, IT_SYS_TITLE_SECOND, IT_SYS_COMPANY_SECOND, IT_SYS_DATE_SECOND, \n",
    "              IT_SYS_STATUS_SECOND, IT_SYS_LOCATION_SECOND, IT_SYS_SALARY_SECOND, \n",
    "              IT_SYS_SALARY_MIN_SECOND, IT_SYS_SALARY_MAX_SECOND, IT_SYS_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of IT - Network/Sys/DB Admin (JOBLUM) \n",
    "\n",
    "IT_SYS_TITLE_LIST = np.concatenate((IT_SYS_TITLE_FIRST, IT_SYS_TITLE_SECOND))\n",
    "IT_SYS_COMPANY_LIST = np.concatenate((IT_SYS_COMPANY_FIRST, IT_SYS_COMPANY_SECOND))\n",
    "IT_SYS_DATE_LIST = np.concatenate((IT_SYS_DATE_FIRST, IT_SYS_DATE_SECOND))\n",
    "IT_SYS_LOCATION_LIST = np.concatenate((IT_SYS_LOCATION_FIRST, IT_SYS_LOCATION_SECOND))\n",
    "IT_SYS_STATUS_LIST = np.concatenate((IT_SYS_STATUS_FIRST, IT_SYS_STATUS_SECOND))\n",
    "IT_SYS_SALARY_LIST = np.concatenate((IT_SYS_SALARY_FIRST, IT_SYS_SALARY_SECOND))\n",
    "IT_SYS_SALARY_MIN_LIST = np.concatenate((IT_SYS_SALARY_MIN_FIRST, IT_SYS_SALARY_MIN_SECOND))\n",
    "IT_SYS_SALARY_MAX_LIST = np.concatenate((IT_SYS_SALARY_MAX_FIRST, IT_SYS_SALARY_MAX_SECOND))\n",
    "IT_SYS_DESCRIPTION_LIST = np.concatenate((IT_SYS_DESCRIPTION_FIRST, IT_SYS_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for IT - Network/Sys/DB Admin (JOBLUM) \n",
    "IT_SYS={'Website': \"Joblum\",\n",
    "      'Job Title': IT_SYS_TITLE_LIST, \n",
    "      'Category': \"IT - Network/Sys/DB Admin\", \n",
    "      'Company': IT_SYS_COMPANY_LIST, \n",
    "      'Date Posted': IT_SYS_DATE_LIST, \n",
    "      'Location': IT_SYS_LOCATION_LIST, \n",
    "      'Status': IT_SYS_STATUS_LIST, \n",
    "      'Salary': IT_SYS_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': IT_SYS_DESCRIPTION_LIST,\n",
    "      'Min Salary': IT_SYS_SALARY_MIN_LIST,\n",
    "      'Max Salary': IT_SYS_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"IT\"}\n",
    "IT_SYS_df = pd.DataFrame(data=IT_SYS)\n",
    "IT_SYS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "IT_SYS_df.to_csv ('JOBLUM-IT_SYS.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of IT - Software (JOBLUM) - FIRST HALF\n",
    "\n",
    "IT_SOFTWARE_TITLE_FIRST = []\n",
    "IT_SOFTWARE_COMPANY_FIRST = []\n",
    "IT_SOFTWARE_DATE_FIRST = []\n",
    "IT_SOFTWARE_LOCATION_FIRST = []\n",
    "IT_SOFTWARE_STATUS_FIRST = []\n",
    "IT_SOFTWARE_SALARY_FIRST = []\n",
    "IT_SOFTWARE_SALARY_MIN_FIRST = []\n",
    "IT_SOFTWARE_SALARY_MAX_FIRST = []\n",
    "IT_SOFTWARE_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-it-software?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, IT_SOFTWARE_TITLE_FIRST, IT_SOFTWARE_COMPANY_FIRST, IT_SOFTWARE_DATE_FIRST, \n",
    "              IT_SOFTWARE_STATUS_FIRST, IT_SOFTWARE_LOCATION_FIRST, IT_SOFTWARE_SALARY_FIRST, \n",
    "              IT_SOFTWARE_SALARY_MIN_FIRST, IT_SOFTWARE_SALARY_MAX_FIRST, IT_SOFTWARE_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of IT - Software (JOBLUM) - SECOND HALF\n",
    "\n",
    "IT_SOFTWARE_TITLE_SECOND = []\n",
    "IT_SOFTWARE_COMPANY_SECOND = []\n",
    "IT_SOFTWARE_DATE_SECOND = []\n",
    "IT_SOFTWARE_LOCATION_SECOND = []\n",
    "IT_SOFTWARE_STATUS_SECOND = []\n",
    "IT_SOFTWARE_SALARY_SECOND = []\n",
    "IT_SOFTWARE_SALARY_MIN_SECOND = []\n",
    "IT_SOFTWARE_SALARY_MAX_SECOND = []\n",
    "IT_SOFTWARE_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, IT_SOFTWARE_TITLE_SECOND, IT_SOFTWARE_COMPANY_SECOND, IT_SOFTWARE_DATE_SECOND, \n",
    "              IT_SOFTWARE_STATUS_SECOND, IT_SOFTWARE_LOCATION_SECOND, IT_SOFTWARE_SALARY_SECOND, \n",
    "              IT_SOFTWARE_SALARY_MIN_SECOND, IT_SOFTWARE_SALARY_MAX_SECOND, IT_SOFTWARE_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of IT - Software (JOBLUM) \n",
    "\n",
    "IT_SOFTWARE_TITLE_LIST = np.concatenate((IT_SOFTWARE_TITLE_FIRST, IT_SOFTWARE_TITLE_SECOND))\n",
    "IT_SOFTWARE_COMPANY_LIST = np.concatenate((IT_SOFTWARE_COMPANY_FIRST, IT_SOFTWARE_COMPANY_SECOND))\n",
    "IT_SOFTWARE_DATE_LIST = np.concatenate((IT_SOFTWARE_DATE_FIRST, IT_SOFTWARE_DATE_SECOND))\n",
    "IT_SOFTWARE_LOCATION_LIST = np.concatenate((IT_SOFTWARE_LOCATION_FIRST, IT_SOFTWARE_LOCATION_SECOND))\n",
    "IT_SOFTWARE_STATUS_LIST = np.concatenate((IT_SOFTWARE_STATUS_FIRST, IT_SOFTWARE_STATUS_SECOND))\n",
    "IT_SOFTWARE_SALARY_LIST = np.concatenate((IT_SOFTWARE_SALARY_FIRST, IT_SOFTWARE_SALARY_SECOND))\n",
    "IT_SOFTWARE_SALARY_MIN_LIST = np.concatenate((IT_SOFTWARE_SALARY_MIN_FIRST, IT_SOFTWARE_SALARY_MIN_SECOND))\n",
    "IT_SOFTWARE_SALARY_MAX_LIST = np.concatenate((IT_SOFTWARE_SALARY_MAX_FIRST, IT_SOFTWARE_SALARY_MAX_SECOND))\n",
    "IT_SOFTWARE_DESCRIPTION_LIST = np.concatenate((IT_SOFTWARE_DESCRIPTION_FIRST, IT_SOFTWARE_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for IT - Software (JOBLUM) \n",
    "IT_SOFTWARE={'Website': \"Joblum\",\n",
    "      'Job Title': IT_SOFTWARE_TITLE_LIST, \n",
    "      'Category': \"IT - Software\", \n",
    "      'Company': IT_SOFTWARE_COMPANY_LIST, \n",
    "      'Date Posted': IT_SOFTWARE_DATE_LIST, \n",
    "      'Location': IT_SOFTWARE_LOCATION_LIST, \n",
    "      'Status': IT_SOFTWARE_STATUS_LIST, \n",
    "      'Salary': IT_SOFTWARE_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': IT_SOFTWARE_DESCRIPTION_LIST,\n",
    "      'Min Salary': IT_SOFTWARE_SALARY_MIN_LIST,\n",
    "      'Max Salary': IT_SOFTWARE_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"IT\"}\n",
    "IT_SOFTWARE_df = pd.DataFrame(data=IT_SOFTWARE)\n",
    "IT_SOFTWARE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "IT_SOFTWARE_df.to_csv ('JOBLUM-IT_SOFTWARE.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Maintenance (JOBLUM) - FIRST HALF\n",
    "\n",
    "MAINTENANCE_TITLE_FIRST = []\n",
    "MAINTENANCE_COMPANY_FIRST = []\n",
    "MAINTENANCE_DATE_FIRST = []\n",
    "MAINTENANCE_LOCATION_FIRST = []\n",
    "MAINTENANCE_STATUS_FIRST = []\n",
    "MAINTENANCE_SALARY_FIRST = []\n",
    "MAINTENANCE_SALARY_MIN_FIRST = []\n",
    "MAINTENANCE_SALARY_MAX_FIRST = []\n",
    "MAINTENANCE_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-maintenance?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, MAINTENANCE_TITLE_FIRST, MAINTENANCE_COMPANY_FIRST, MAINTENANCE_DATE_FIRST, \n",
    "              MAINTENANCE_STATUS_FIRST, MAINTENANCE_LOCATION_FIRST, MAINTENANCE_SALARY_FIRST, \n",
    "              MAINTENANCE_SALARY_MIN_FIRST, MAINTENANCE_SALARY_MAX_FIRST, MAINTENANCE_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Maintenance (JOBLUM) - SECOND HALF\n",
    "\n",
    "MAINTENANCE_TITLE_SECOND = []\n",
    "MAINTENANCE_COMPANY_SECOND = []\n",
    "MAINTENANCE_DATE_SECOND = []\n",
    "MAINTENANCE_LOCATION_SECOND = []\n",
    "MAINTENANCE_STATUS_SECOND = []\n",
    "MAINTENANCE_SALARY_SECOND = []\n",
    "MAINTENANCE_SALARY_MIN_SECOND = []\n",
    "MAINTENANCE_SALARY_MAX_SECOND = []\n",
    "MAINTENANCE_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, MAINTENANCE_TITLE_SECOND, MAINTENANCE_COMPANY_SECOND, MAINTENANCE_DATE_SECOND, \n",
    "              MAINTENANCE_STATUS_SECOND, MAINTENANCE_LOCATION_SECOND, MAINTENANCE_SALARY_SECOND, \n",
    "              MAINTENANCE_SALARY_MIN_SECOND, MAINTENANCE_SALARY_MAX_SECOND, MAINTENANCE_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Maintenance (JOBLUM) \n",
    "\n",
    "MAINTENANCE_TITLE_LIST = np.concatenate((MAINTENANCE_TITLE_FIRST, MAINTENANCE_TITLE_SECOND))\n",
    "MAINTENANCE_COMPANY_LIST = np.concatenate((MAINTENANCE_COMPANY_FIRST, MAINTENANCE_COMPANY_SECOND))\n",
    "MAINTENANCE_DATE_LIST = np.concatenate((MAINTENANCE_DATE_FIRST, MAINTENANCE_DATE_SECOND))\n",
    "MAINTENANCE_LOCATION_LIST = np.concatenate((MAINTENANCE_LOCATION_FIRST, MAINTENANCE_LOCATION_SECOND))\n",
    "MAINTENANCE_STATUS_LIST = np.concatenate((MAINTENANCE_STATUS_FIRST, MAINTENANCE_STATUS_SECOND))\n",
    "MAINTENANCE_SALARY_LIST = np.concatenate((MAINTENANCE_SALARY_FIRST, MAINTENANCE_SALARY_SECOND))\n",
    "MAINTENANCE_SALARY_MIN_LIST = np.concatenate((MAINTENANCE_SALARY_MIN_FIRST, MAINTENANCE_SALARY_MIN_SECOND))\n",
    "MAINTENANCE_SALARY_MAX_LIST = np.concatenate((MAINTENANCE_SALARY_MAX_FIRST, MAINTENANCE_SALARY_MAX_SECOND))\n",
    "MAINTENANCE_DESCRIPTION_LIST = np.concatenate((MAINTENANCE_DESCRIPTION_FIRST, MAINTENANCE_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Maintenance (JOBLUM) \n",
    "MAINTENANCE={'Website': \"Joblum\",\n",
    "      'Job Title': MAINTENANCE_TITLE_LIST, \n",
    "      'Category': \"Maintenance\", \n",
    "      'Company': MAINTENANCE_COMPANY_LIST, \n",
    "      'Date Posted': MAINTENANCE_DATE_LIST, \n",
    "      'Location': MAINTENANCE_LOCATION_LIST, \n",
    "      'Status': MAINTENANCE_STATUS_LIST, \n",
    "      'Salary': MAINTENANCE_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': MAINTENANCE_DESCRIPTION_LIST,\n",
    "      'Min Salary': MAINTENANCE_SALARY_MIN_LIST,\n",
    "      'Max Salary': MAINTENANCE_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "MAINTENANCE_df = pd.DataFrame(data=MAINTENANCE)\n",
    "MAINTENANCE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAINTENANCE_df.to_csv ('JOBLUM-MAINTENANCE.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Mechanical (JOBLUM) - FIRST HALF\n",
    "\n",
    "MECH_TITLE_FIRST = []\n",
    "MECH_COMPANY_FIRST = []\n",
    "MECH_DATE_FIRST = []\n",
    "MECH_LOCATION_FIRST = []\n",
    "MECH_STATUS_FIRST = []\n",
    "MECH_SALARY_FIRST = []\n",
    "MECH_SALARY_MIN_FIRST = []\n",
    "MECH_SALARY_MAX_FIRST = []\n",
    "MECH_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-mechanical?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, MECH_TITLE_FIRST, MECH_COMPANY_FIRST, MECH_DATE_FIRST, \n",
    "              MECH_STATUS_FIRST, MECH_LOCATION_FIRST, MECH_SALARY_FIRST, \n",
    "              MECH_SALARY_MIN_FIRST, MECH_SALARY_MAX_FIRST, MECH_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Mechanical (JOBLUM) - SECOND HALF\n",
    "\n",
    "MECH_TITLE_SECOND = []\n",
    "MECH_COMPANY_SECOND = []\n",
    "MECH_DATE_SECOND = []\n",
    "MECH_LOCATION_SECOND = []\n",
    "MECH_STATUS_SECOND = []\n",
    "MECH_SALARY_SECOND = []\n",
    "MECH_SALARY_MIN_SECOND = []\n",
    "MECH_SALARY_MAX_SECOND = []\n",
    "MECH_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, MECH_TITLE_SECOND, MECH_COMPANY_SECOND, MECH_DATE_SECOND, \n",
    "              MECH_STATUS_SECOND, MECH_LOCATION_SECOND, MECH_SALARY_SECOND, \n",
    "              MECH_SALARY_MIN_SECOND, MECH_SALARY_MAX_SECOND, MECH_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Mechanical (JOBLUM) \n",
    "\n",
    "MECH_TITLE_LIST = np.concatenate((MECH_TITLE_FIRST, MECH_TITLE_SECOND))\n",
    "MECH_COMPANY_LIST = np.concatenate((MECH_COMPANY_FIRST, MECH_COMPANY_SECOND))\n",
    "MECH_DATE_LIST = np.concatenate((MECH_DATE_FIRST, MECH_DATE_SECOND))\n",
    "MECH_LOCATION_LIST = np.concatenate((MECH_LOCATION_FIRST, MECH_LOCATION_SECOND))\n",
    "MECH_STATUS_LIST = np.concatenate((MECH_STATUS_FIRST, MECH_STATUS_SECOND))\n",
    "MECH_SALARY_LIST = np.concatenate((MECH_SALARY_FIRST, MECH_SALARY_SECOND))\n",
    "MECH_SALARY_MIN_LIST = np.concatenate((MECH_SALARY_MIN_FIRST, MECH_SALARY_MIN_SECOND))\n",
    "MECH_SALARY_MAX_LIST = np.concatenate((MECH_SALARY_MAX_FIRST, MECH_SALARY_MAX_SECOND))\n",
    "MECH_DESCRIPTION_LIST = np.concatenate((MECH_DESCRIPTION_FIRST, MECH_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Mechanical (JOBLUM) \n",
    "MECH={'Website': \"Joblum\",\n",
    "      'Job Title': MECH_TITLE_LIST, \n",
    "      'Category': \"Mechanical\", \n",
    "      'Company': MECH_COMPANY_LIST, \n",
    "      'Date Posted': MECH_DATE_LIST, \n",
    "      'Location': MECH_LOCATION_LIST, \n",
    "      'Status': MECH_STATUS_LIST, \n",
    "      'Salary': MECH_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': MECH_DESCRIPTION_LIST,\n",
    "      'Min Salary': MECH_SALARY_MIN_LIST,\n",
    "      'Max Salary': MECH_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "MECH_df = pd.DataFrame(data=MECH)\n",
    "MECH_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "MECH_df.to_csv ('JOBLUM-MECH.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Mechanical/Automotive Engineering (JOBLUM) - FIRST HALF\n",
    "\n",
    "MECHENG_TITLE_FIRST = []\n",
    "MECHENG_COMPANY_FIRST = []\n",
    "MECHENG_DATE_FIRST = []\n",
    "MECHENG_LOCATION_FIRST = []\n",
    "MECHENG_STATUS_FIRST = []\n",
    "MECHENG_SALARY_FIRST = []\n",
    "MECHENG_SALARY_MIN_FIRST = []\n",
    "MECHENG_SALARY_MAX_FIRST = []\n",
    "MECHENG_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-mechanical-automotive-engineering?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, MECHENG_TITLE_FIRST, MECHENG_COMPANY_FIRST, MECHENG_DATE_FIRST, \n",
    "              MECHENG_STATUS_FIRST, MECHENG_LOCATION_FIRST, MECHENG_SALARY_FIRST, \n",
    "              MECHENG_SALARY_MIN_FIRST, MECHENG_SALARY_MAX_FIRST, MECHENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Mechanical/Automotive Engineering (JOBLUM) - SECOND HALF\n",
    "\n",
    "MECHENG_TITLE_SECOND = []\n",
    "MECHENG_COMPANY_SECOND = []\n",
    "MECHENG_DATE_SECOND = []\n",
    "MECHENG_LOCATION_SECOND = []\n",
    "MECHENG_STATUS_SECOND = []\n",
    "MECHENG_SALARY_SECOND = []\n",
    "MECHENG_SALARY_MIN_SECOND = []\n",
    "MECHENG_SALARY_MAX_SECOND = []\n",
    "MECHENG_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, MECHENG_TITLE_SECOND, MECHENG_COMPANY_SECOND, MECHENG_DATE_SECOND, \n",
    "              MECHENG_STATUS_SECOND, MECHENG_LOCATION_SECOND, MECHENG_SALARY_SECOND, \n",
    "              MECHENG_SALARY_MIN_SECOND, MECHENG_SALARY_MAX_SECOND, MECHENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Mechanical/Automotive Engineering (JOBLUM) \n",
    "\n",
    "MECHENG_TITLE_LIST = np.concatenate((MECHENG_TITLE_FIRST, MECHENG_TITLE_SECOND))\n",
    "MECHENG_COMPANY_LIST = np.concatenate((MECHENG_COMPANY_FIRST, MECHENG_COMPANY_SECOND))\n",
    "MECHENG_DATE_LIST = np.concatenate((MECHENG_DATE_FIRST, MECHENG_DATE_SECOND))\n",
    "MECHENG_LOCATION_LIST = np.concatenate((MECHENG_LOCATION_FIRST, MECHENG_LOCATION_SECOND))\n",
    "MECHENG_STATUS_LIST = np.concatenate((MECHENG_STATUS_FIRST, MECHENG_STATUS_SECOND))\n",
    "MECHENG_SALARY_LIST = np.concatenate((MECHENG_SALARY_FIRST, MECHENG_SALARY_SECOND))\n",
    "MECHENG_SALARY_MIN_LIST = np.concatenate((MECHENG_SALARY_MIN_FIRST, MECHENG_SALARY_MIN_SECOND))\n",
    "MECHENG_SALARY_MAX_LIST = np.concatenate((MECHENG_SALARY_MAX_FIRST, MECHENG_SALARY_MAX_SECOND))\n",
    "MECHENG_DESCRIPTION_LIST = np.concatenate((MECHENG_DESCRIPTION_FIRST, MECHENG_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Mechanical/Automotive Engineering (JOBLUM) \n",
    "MECHENG={'Website': \"Joblum\",\n",
    "      'Job Title': MECHENG_TITLE_LIST, \n",
    "      'Category': \"Mechanical/Automotive Engineering\", \n",
    "      'Company': MECHENG_COMPANY_LIST, \n",
    "      'Date Posted': MECHENG_DATE_LIST, \n",
    "      'Location': MECHENG_LOCATION_LIST, \n",
    "      'Status': MECHENG_STATUS_LIST, \n",
    "      'Salary': MECHENG_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': MECHENG_DESCRIPTION_LIST,\n",
    "      'Min Salary': MECHENG_SALARY_MIN_LIST,\n",
    "      'Max Salary': MECHENG_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "MECHENG_df = pd.DataFrame(data=MECHENG)\n",
    "MECHENG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "MECHENG_df.to_csv ('JOBLUM-MECHENG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Nurse/Medical Support (JOBLUM) - FIRST HALF\n",
    "\n",
    "NURSE_TITLE_FIRST = []\n",
    "NURSE_COMPANY_FIRST = []\n",
    "NURSE_DATE_FIRST = []\n",
    "NURSE_LOCATION_FIRST = []\n",
    "NURSE_STATUS_FIRST = []\n",
    "NURSE_SALARY_FIRST = []\n",
    "NURSE_SALARY_MIN_FIRST = []\n",
    "NURSE_SALARY_MAX_FIRST = []\n",
    "NURSE_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-nurse-medical-support?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, NURSE_TITLE_FIRST, NURSE_COMPANY_FIRST, NURSE_DATE_FIRST, \n",
    "              NURSE_STATUS_FIRST, NURSE_LOCATION_FIRST, NURSE_SALARY_FIRST, \n",
    "              NURSE_SALARY_MIN_FIRST, NURSE_SALARY_MAX_FIRST, NURSE_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Nurse/Medical Support (JOBLUM) - SECOND HALF\n",
    "\n",
    "NURSE_TITLE_SECOND = []\n",
    "NURSE_COMPANY_SECOND = []\n",
    "NURSE_DATE_SECOND = []\n",
    "NURSE_LOCATION_SECOND = []\n",
    "NURSE_STATUS_SECOND = []\n",
    "NURSE_SALARY_SECOND = []\n",
    "NURSE_SALARY_MIN_SECOND = []\n",
    "NURSE_SALARY_MAX_SECOND = []\n",
    "NURSE_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, NURSE_TITLE_SECOND, NURSE_COMPANY_SECOND, NURSE_DATE_SECOND, \n",
    "              NURSE_STATUS_SECOND, NURSE_LOCATION_SECOND, NURSE_SALARY_SECOND, \n",
    "              NURSE_SALARY_MIN_SECOND, NURSE_SALARY_MAX_SECOND, NURSE_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Nurse/Medical Support (JOBLUM) \n",
    "\n",
    "NURSE_TITLE_LIST = np.concatenate((NURSE_TITLE_FIRST, NURSE_TITLE_SECOND))\n",
    "NURSE_COMPANY_LIST = np.concatenate((NURSE_COMPANY_FIRST, NURSE_COMPANY_SECOND))\n",
    "NURSE_DATE_LIST = np.concatenate((NURSE_DATE_FIRST, NURSE_DATE_SECOND))\n",
    "NURSE_LOCATION_LIST = np.concatenate((NURSE_LOCATION_FIRST, NURSE_LOCATION_SECOND))\n",
    "NURSE_STATUS_LIST = np.concatenate((NURSE_STATUS_FIRST, NURSE_STATUS_SECOND))\n",
    "NURSE_SALARY_LIST = np.concatenate((NURSE_SALARY_FIRST, NURSE_SALARY_SECOND))\n",
    "NURSE_SALARY_MIN_LIST = np.concatenate((NURSE_SALARY_MIN_FIRST, NURSE_SALARY_MIN_SECOND))\n",
    "NURSE_SALARY_MAX_LIST = np.concatenate((NURSE_SALARY_MAX_FIRST, NURSE_SALARY_MAX_SECOND))\n",
    "NURSE_DESCRIPTION_LIST = np.concatenate((NURSE_DESCRIPTION_FIRST, NURSE_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Nurse/Medical Support (JOBLUM) \n",
    "NURSE={'Website': \"Joblum\",\n",
    "      'Job Title': NURSE_TITLE_LIST, \n",
    "      'Category': \"Nurse/Medical Support\", \n",
    "      'Company': NURSE_COMPANY_LIST, \n",
    "      'Date Posted': NURSE_DATE_LIST, \n",
    "      'Location': NURSE_LOCATION_LIST, \n",
    "      'Status': NURSE_STATUS_LIST, \n",
    "      'Salary': NURSE_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': NURSE_DESCRIPTION_LIST,\n",
    "      'Min Salary': NURSE_SALARY_MIN_LIST,\n",
    "      'Max Salary': NURSE_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Medicine\"}\n",
    "NURSE_df = pd.DataFrame(data=NURSE)\n",
    "NURSE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "NURSE_df.to_csv ('JOBLUM-NURSE.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Oil/Gas (JOBLUM) - FIRST HALF\n",
    "\n",
    "OIL_TITLE_FIRST = []\n",
    "OIL_COMPANY_FIRST = []\n",
    "OIL_DATE_FIRST = []\n",
    "OIL_LOCATION_FIRST = []\n",
    "OIL_STATUS_FIRST = []\n",
    "OIL_SALARY_FIRST = []\n",
    "OIL_SALARY_MIN_FIRST = []\n",
    "OIL_SALARY_MAX_FIRST = []\n",
    "OIL_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-oil-gas?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, OIL_TITLE_FIRST, OIL_COMPANY_FIRST, OIL_DATE_FIRST, \n",
    "              OIL_STATUS_FIRST, OIL_LOCATION_FIRST, OIL_SALARY_FIRST, \n",
    "              OIL_SALARY_MIN_FIRST, OIL_SALARY_MAX_FIRST, OIL_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Oil/Gas (JOBLUM) - SECOND HALF\n",
    "\n",
    "OIL_TITLE_SECOND = []\n",
    "OIL_COMPANY_SECOND = []\n",
    "OIL_DATE_SECOND = []\n",
    "OIL_LOCATION_SECOND = []\n",
    "OIL_STATUS_SECOND = []\n",
    "OIL_SALARY_SECOND = []\n",
    "OIL_SALARY_MIN_SECOND = []\n",
    "OIL_SALARY_MAX_SECOND = []\n",
    "OIL_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, OIL_TITLE_SECOND, OIL_COMPANY_SECOND, OIL_DATE_SECOND, \n",
    "              OIL_STATUS_SECOND, OIL_LOCATION_SECOND, OIL_SALARY_SECOND, \n",
    "              OIL_SALARY_MIN_SECOND, OIL_SALARY_MAX_SECOND, OIL_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Oil/Gas (JOBLUM) \n",
    "\n",
    "OIL_TITLE_LIST = np.concatenate((OIL_TITLE_FIRST, OIL_TITLE_SECOND))\n",
    "OIL_COMPANY_LIST = np.concatenate((OIL_COMPANY_FIRST, OIL_COMPANY_SECOND))\n",
    "OIL_DATE_LIST = np.concatenate((OIL_DATE_FIRST, OIL_DATE_SECOND))\n",
    "OIL_LOCATION_LIST = np.concatenate((OIL_LOCATION_FIRST, OIL_LOCATION_SECOND))\n",
    "OIL_STATUS_LIST = np.concatenate((OIL_STATUS_FIRST, OIL_STATUS_SECOND))\n",
    "OIL_SALARY_LIST = np.concatenate((OIL_SALARY_FIRST, OIL_SALARY_SECOND))\n",
    "OIL_SALARY_MIN_LIST = np.concatenate((OIL_SALARY_MIN_FIRST, OIL_SALARY_MIN_SECOND))\n",
    "OIL_SALARY_MAX_LIST = np.concatenate((OIL_SALARY_MAX_FIRST, OIL_SALARY_MAX_SECOND))\n",
    "OIL_DESCRIPTION_LIST = np.concatenate((OIL_DESCRIPTION_FIRST, OIL_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Oil/Gas (JOBLUM) \n",
    "OIL={'Website': \"Joblum\",\n",
    "      'Job Title': OIL_TITLE_LIST, \n",
    "      'Category': \"Oil/Gas\", \n",
    "      'Company': OIL_COMPANY_LIST, \n",
    "      'Date Posted': OIL_DATE_LIST, \n",
    "      'Location': OIL_LOCATION_LIST, \n",
    "      'Status': OIL_STATUS_LIST, \n",
    "      'Salary': OIL_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': OIL_DESCRIPTION_LIST,\n",
    "      'Min Salary': OIL_SALARY_MIN_LIST,\n",
    "      'Max Salary': OIL_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "OIL_df = pd.DataFrame(data=OIL)\n",
    "OIL_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "OIL_df.to_csv ('JOBLUM-OIL.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Oil/Gas Engineering (JOBLUM) - FIRST HALF\n",
    "\n",
    "OILENG_TITLE_FIRST = []\n",
    "OILENG_COMPANY_FIRST = []\n",
    "OILENG_DATE_FIRST = []\n",
    "OILENG_LOCATION_FIRST = []\n",
    "OILENG_STATUS_FIRST = []\n",
    "OILENG_SALARY_FIRST = []\n",
    "OILENG_SALARY_MIN_FIRST = []\n",
    "OILENG_SALARY_MAX_FIRST = []\n",
    "OILENG_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-oil-gas-engineering?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, OILENG_TITLE_FIRST, OILENG_COMPANY_FIRST, OILENG_DATE_FIRST, \n",
    "              OILENG_STATUS_FIRST, OILENG_LOCATION_FIRST, OILENG_SALARY_FIRST, \n",
    "              OILENG_SALARY_MIN_FIRST, OILENG_SALARY_MAX_FIRST, OILENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Oil/Gas Engineering (JOBLUM) - SECOND HALF\n",
    "\n",
    "OILENG_TITLE_SECOND = []\n",
    "OILENG_COMPANY_SECOND = []\n",
    "OILENG_DATE_SECOND = []\n",
    "OILENG_LOCATION_SECOND = []\n",
    "OILENG_STATUS_SECOND = []\n",
    "OILENG_SALARY_SECOND = []\n",
    "OILENG_SALARY_MIN_SECOND = []\n",
    "OILENG_SALARY_MAX_SECOND = []\n",
    "OILENG_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, OILENG_TITLE_SECOND, OILENG_COMPANY_SECOND, OILENG_DATE_SECOND, \n",
    "              OILENG_STATUS_SECOND, OILENG_LOCATION_SECOND, OILENG_SALARY_SECOND, \n",
    "              OILENG_SALARY_MIN_SECOND, OILENG_SALARY_MAX_SECOND, OILENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Oil/Gas Engineering (JOBLUM) \n",
    "\n",
    "OILENG_TITLE_LIST = np.concatenate((OILENG_TITLE_FIRST, OILENG_TITLE_SECOND))\n",
    "OILENG_COMPANY_LIST = np.concatenate((OILENG_COMPANY_FIRST, OILENG_COMPANY_SECOND))\n",
    "OILENG_DATE_LIST = np.concatenate((OILENG_DATE_FIRST, OILENG_DATE_SECOND))\n",
    "OILENG_LOCATION_LIST = np.concatenate((OILENG_LOCATION_FIRST, OILENG_LOCATION_SECOND))\n",
    "OILENG_STATUS_LIST = np.concatenate((OILENG_STATUS_FIRST, OILENG_STATUS_SECOND))\n",
    "OILENG_SALARY_LIST = np.concatenate((OILENG_SALARY_FIRST, OILENG_SALARY_SECOND))\n",
    "OILENG_SALARY_MIN_LIST = np.concatenate((OILENG_SALARY_MIN_FIRST, OILENG_SALARY_MIN_SECOND))\n",
    "OILENG_SALARY_MAX_LIST = np.concatenate((OILENG_SALARY_MAX_FIRST, OILENG_SALARY_MAX_SECOND))\n",
    "OILENG_DESCRIPTION_LIST = np.concatenate((OILENG_DESCRIPTION_FIRST, OILENG_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Oil/Gas Engineering (JOBLUM) \n",
    "OILENG={'Website': \"Joblum\",\n",
    "      'Job Title': OILENG_TITLE_LIST, \n",
    "      'Category': \"Oil/Gas Engineering\", \n",
    "      'Company': OILENG_COMPANY_LIST, \n",
    "      'Date Posted': OILENG_DATE_LIST, \n",
    "      'Location': OILENG_LOCATION_LIST, \n",
    "      'Status': OILENG_STATUS_LIST, \n",
    "      'Salary': OILENG_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': OILENG_DESCRIPTION_LIST,\n",
    "      'Min Salary': OILENG_SALARY_MIN_LIST,\n",
    "      'Max Salary': OILENG_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "OILENG_df = pd.DataFrame(data=OILENG)\n",
    "OILENG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "OILENG_df.to_csv ('JOBLUM-OILENG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Other Engineering (JOBLUM) - FIRST HALF\n",
    "\n",
    "ENG_TITLE_FIRST = []\n",
    "ENG_COMPANY_FIRST = []\n",
    "ENG_DATE_FIRST = []\n",
    "ENG_LOCATION_FIRST = []\n",
    "ENG_STATUS_FIRST = []\n",
    "ENG_SALARY_FIRST = []\n",
    "ENG_SALARY_MIN_FIRST = []\n",
    "ENG_SALARY_MAX_FIRST = []\n",
    "ENG_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-other-engineering?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ENG_TITLE_FIRST, ENG_COMPANY_FIRST, ENG_DATE_FIRST, \n",
    "              ENG_STATUS_FIRST, ENG_LOCATION_FIRST, ENG_SALARY_FIRST, \n",
    "              ENG_SALARY_MIN_FIRST, ENG_SALARY_MAX_FIRST, ENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Other Engineering (JOBLUM) - SECOND HALF\n",
    "\n",
    "ENG_TITLE_SECOND = []\n",
    "ENG_COMPANY_SECOND = []\n",
    "ENG_DATE_SECOND = []\n",
    "ENG_LOCATION_SECOND = []\n",
    "ENG_STATUS_SECOND = []\n",
    "ENG_SALARY_SECOND = []\n",
    "ENG_SALARY_MIN_SECOND = []\n",
    "ENG_SALARY_MAX_SECOND = []\n",
    "ENG_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, ENG_TITLE_SECOND, ENG_COMPANY_SECOND, ENG_DATE_SECOND, \n",
    "              ENG_STATUS_SECOND, ENG_LOCATION_SECOND, ENG_SALARY_SECOND, \n",
    "              ENG_SALARY_MIN_SECOND, ENG_SALARY_MAX_SECOND, ENG_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Other Engineering (JOBLUM) \n",
    "\n",
    "ENG_TITLE_LIST = np.concatenate((ENG_TITLE_FIRST, ENG_TITLE_SECOND))\n",
    "ENG_COMPANY_LIST = np.concatenate((ENG_COMPANY_FIRST, ENG_COMPANY_SECOND))\n",
    "ENG_DATE_LIST = np.concatenate((ENG_DATE_FIRST, ENG_DATE_SECOND))\n",
    "ENG_LOCATION_LIST = np.concatenate((ENG_LOCATION_FIRST, ENG_LOCATION_SECOND))\n",
    "ENG_STATUS_LIST = np.concatenate((ENG_STATUS_FIRST, ENG_STATUS_SECOND))\n",
    "ENG_SALARY_LIST = np.concatenate((ENG_SALARY_FIRST, ENG_SALARY_SECOND))\n",
    "ENG_SALARY_MIN_LIST = np.concatenate((ENG_SALARY_MIN_FIRST, ENG_SALARY_MIN_SECOND))\n",
    "ENG_SALARY_MAX_LIST = np.concatenate((ENG_SALARY_MAX_FIRST, ENG_SALARY_MAX_SECOND))\n",
    "ENG_DESCRIPTION_LIST = np.concatenate((ENG_DESCRIPTION_FIRST, ENG_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Other Engineering (JOBLUM) \n",
    "ENG={'Website': \"Joblum\",\n",
    "      'Job Title': ENG_TITLE_LIST, \n",
    "      'Category': \"Other Engineering\", \n",
    "      'Company': ENG_COMPANY_LIST, \n",
    "      'Date Posted': ENG_DATE_LIST, \n",
    "      'Location': ENG_LOCATION_LIST, \n",
    "      'Status': ENG_STATUS_LIST, \n",
    "      'Salary': ENG_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': ENG_DESCRIPTION_LIST,\n",
    "      'Min Salary': ENG_SALARY_MIN_LIST,\n",
    "      'Max Salary': ENG_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "ENG_df = pd.DataFrame(data=ENG)\n",
    "ENG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENG_df.to_csv ('JOBLUM-ENG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Pharmacy (JOBLUM) - FIRST HALF\n",
    "\n",
    "PHARMA_TITLE_FIRST = []\n",
    "PHARMA_COMPANY_FIRST = []\n",
    "PHARMA_DATE_FIRST = []\n",
    "PHARMA_LOCATION_FIRST = []\n",
    "PHARMA_STATUS_FIRST = []\n",
    "PHARMA_SALARY_FIRST = []\n",
    "PHARMA_SALARY_MIN_FIRST = []\n",
    "PHARMA_SALARY_MAX_FIRST = []\n",
    "PHARMA_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-pharmacy?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, PHARMA_TITLE_FIRST, PHARMA_COMPANY_FIRST, PHARMA_DATE_FIRST, \n",
    "              PHARMA_STATUS_FIRST, PHARMA_LOCATION_FIRST, PHARMA_SALARY_FIRST, \n",
    "              PHARMA_SALARY_MIN_FIRST, PHARMA_SALARY_MAX_FIRST, PHARMA_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Pharmacy (JOBLUM) - SECOND HALF\n",
    "\n",
    "PHARMA_TITLE_SECOND = []\n",
    "PHARMA_COMPANY_SECOND = []\n",
    "PHARMA_DATE_SECOND = []\n",
    "PHARMA_LOCATION_SECOND = []\n",
    "PHARMA_STATUS_SECOND = []\n",
    "PHARMA_SALARY_SECOND = []\n",
    "PHARMA_SALARY_MIN_SECOND = []\n",
    "PHARMA_SALARY_MAX_SECOND = []\n",
    "PHARMA_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, PHARMA_TITLE_SECOND, PHARMA_COMPANY_SECOND, PHARMA_DATE_SECOND, \n",
    "              PHARMA_STATUS_SECOND, PHARMA_LOCATION_SECOND, PHARMA_SALARY_SECOND, \n",
    "              PHARMA_SALARY_MIN_SECOND, PHARMA_SALARY_MAX_SECOND, PHARMA_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Pharmacy (JOBLUM) \n",
    "\n",
    "PHARMA_TITLE_LIST = np.concatenate((PHARMA_TITLE_FIRST, PHARMA_TITLE_SECOND))\n",
    "PHARMA_COMPANY_LIST = np.concatenate((PHARMA_COMPANY_FIRST, PHARMA_COMPANY_SECOND))\n",
    "PHARMA_DATE_LIST = np.concatenate((PHARMA_DATE_FIRST, PHARMA_DATE_SECOND))\n",
    "PHARMA_LOCATION_LIST = np.concatenate((PHARMA_LOCATION_FIRST, PHARMA_LOCATION_SECOND))\n",
    "PHARMA_STATUS_LIST = np.concatenate((PHARMA_STATUS_FIRST, PHARMA_STATUS_SECOND))\n",
    "PHARMA_SALARY_LIST = np.concatenate((PHARMA_SALARY_FIRST, PHARMA_SALARY_SECOND))\n",
    "PHARMA_SALARY_MIN_LIST = np.concatenate((PHARMA_SALARY_MIN_FIRST, PHARMA_SALARY_MIN_SECOND))\n",
    "PHARMA_SALARY_MAX_LIST = np.concatenate((PHARMA_SALARY_MAX_FIRST, PHARMA_SALARY_MAX_SECOND))\n",
    "PHARMA_DESCRIPTION_LIST = np.concatenate((PHARMA_DESCRIPTION_FIRST, PHARMA_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Pharmacy (JOBLUM) \n",
    "PHARMA={'Website': \"Joblum\",\n",
    "      'Job Title': PHARMA_TITLE_LIST, \n",
    "      'Category': \"Pharmacy\", \n",
    "      'Company': PHARMA_COMPANY_LIST, \n",
    "      'Date Posted': PHARMA_DATE_LIST, \n",
    "      'Location': PHARMA_LOCATION_LIST, \n",
    "      'Status': PHARMA_STATUS_LIST, \n",
    "      'Salary': PHARMA_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': PHARMA_DESCRIPTION_LIST,\n",
    "      'Min Salary': PHARMA_SALARY_MIN_LIST,\n",
    "      'Max Salary': PHARMA_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Medicine\"}\n",
    "PHARMA_df = pd.DataFrame(data=PHARMA)\n",
    "PHARMA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHARMA_df.to_csv ('JOBLUM-PHARMA.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Quality Assurance (JOBLUM) - FIRST HALF\n",
    "\n",
    "QUALITY_TITLE_FIRST = []\n",
    "QUALITY_COMPANY_FIRST = []\n",
    "QUALITY_DATE_FIRST = []\n",
    "QUALITY_LOCATION_FIRST = []\n",
    "QUALITY_STATUS_FIRST = []\n",
    "QUALITY_SALARY_FIRST = []\n",
    "QUALITY_SALARY_MIN_FIRST = []\n",
    "QUALITY_SALARY_MAX_FIRST = []\n",
    "QUALITY_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-quality-assurance?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, QUALITY_TITLE_FIRST, QUALITY_COMPANY_FIRST, QUALITY_DATE_FIRST, \n",
    "              QUALITY_STATUS_FIRST, QUALITY_LOCATION_FIRST, QUALITY_SALARY_FIRST, \n",
    "              QUALITY_SALARY_MIN_FIRST, QUALITY_SALARY_MAX_FIRST, QUALITY_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Quality Assurance (JOBLUM) - SECOND HALF\n",
    "\n",
    "QUALITY_TITLE_SECOND = []\n",
    "QUALITY_COMPANY_SECOND = []\n",
    "QUALITY_DATE_SECOND = []\n",
    "QUALITY_LOCATION_SECOND = []\n",
    "QUALITY_STATUS_SECOND = []\n",
    "QUALITY_SALARY_SECOND = []\n",
    "QUALITY_SALARY_MIN_SECOND = []\n",
    "QUALITY_SALARY_MAX_SECOND = []\n",
    "QUALITY_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, QUALITY_TITLE_SECOND, QUALITY_COMPANY_SECOND, QUALITY_DATE_SECOND, \n",
    "              QUALITY_STATUS_SECOND, QUALITY_LOCATION_SECOND, QUALITY_SALARY_SECOND, \n",
    "              QUALITY_SALARY_MIN_SECOND, QUALITY_SALARY_MAX_SECOND, QUALITY_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Quality Assurance (JOBLUM) \n",
    "\n",
    "QUALITY_TITLE_LIST = np.concatenate((QUALITY_TITLE_FIRST, QUALITY_TITLE_SECOND))\n",
    "QUALITY_COMPANY_LIST = np.concatenate((QUALITY_COMPANY_FIRST, QUALITY_COMPANY_SECOND))\n",
    "QUALITY_DATE_LIST = np.concatenate((QUALITY_DATE_FIRST, QUALITY_DATE_SECOND))\n",
    "QUALITY_LOCATION_LIST = np.concatenate((QUALITY_LOCATION_FIRST, QUALITY_LOCATION_SECOND))\n",
    "QUALITY_STATUS_LIST = np.concatenate((QUALITY_STATUS_FIRST, QUALITY_STATUS_SECOND))\n",
    "QUALITY_SALARY_LIST = np.concatenate((QUALITY_SALARY_FIRST, QUALITY_SALARY_SECOND))\n",
    "QUALITY_SALARY_MIN_LIST = np.concatenate((QUALITY_SALARY_MIN_FIRST, QUALITY_SALARY_MIN_SECOND))\n",
    "QUALITY_SALARY_MAX_LIST = np.concatenate((QUALITY_SALARY_MAX_FIRST, QUALITY_SALARY_MAX_SECOND))\n",
    "QUALITY_DESCRIPTION_LIST = np.concatenate((QUALITY_DESCRIPTION_FIRST, QUALITY_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Quality Assurance (JOBLUM) \n",
    "QUALITY={'Website': \"Joblum\",\n",
    "      'Job Title': QUALITY_TITLE_LIST, \n",
    "      'Category': \"Quality Assurance\", \n",
    "      'Company': QUALITY_COMPANY_LIST, \n",
    "      'Date Posted': QUALITY_DATE_LIST, \n",
    "      'Location': QUALITY_LOCATION_LIST, \n",
    "      'Status': QUALITY_STATUS_LIST, \n",
    "      'Salary': QUALITY_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': QUALITY_DESCRIPTION_LIST,\n",
    "      'Min Salary': QUALITY_SALARY_MIN_LIST,\n",
    "      'Max Salary': QUALITY_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "QUALITY_df = pd.DataFrame(data=QUALITY)\n",
    "QUALITY_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUALITY_df.to_csv ('JOBLUM-QUALITY.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Quantity Surveying (JOBLUM) - FIRST HALF\n",
    "\n",
    "QUANTITY_TITLE_FIRST = []\n",
    "QUANTITY_COMPANY_FIRST = []\n",
    "QUANTITY_DATE_FIRST = []\n",
    "QUANTITY_LOCATION_FIRST = []\n",
    "QUANTITY_STATUS_FIRST = []\n",
    "QUANTITY_SALARY_FIRST = []\n",
    "QUANTITY_SALARY_MIN_FIRST = []\n",
    "QUANTITY_SALARY_MAX_FIRST = []\n",
    "QUANTITY_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-quantity-surveying?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, QUANTITY_TITLE_FIRST, QUANTITY_COMPANY_FIRST, QUANTITY_DATE_FIRST, \n",
    "              QUANTITY_STATUS_FIRST, QUANTITY_LOCATION_FIRST, QUANTITY_SALARY_FIRST, \n",
    "              QUANTITY_SALARY_MIN_FIRST, QUANTITY_SALARY_MAX_FIRST, QUANTITY_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Quantity Surveying (JOBLUM) - SECOND HALF\n",
    "\n",
    "QUANTITY_TITLE_SECOND = []\n",
    "QUANTITY_COMPANY_SECOND = []\n",
    "QUANTITY_DATE_SECOND = []\n",
    "QUANTITY_LOCATION_SECOND = []\n",
    "QUANTITY_STATUS_SECOND = []\n",
    "QUANTITY_SALARY_SECOND = []\n",
    "QUANTITY_SALARY_MIN_SECOND = []\n",
    "QUANTITY_SALARY_MAX_SECOND = []\n",
    "QUANTITY_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, QUANTITY_TITLE_SECOND, QUANTITY_COMPANY_SECOND, QUANTITY_DATE_SECOND, \n",
    "              QUANTITY_STATUS_SECOND, QUANTITY_LOCATION_SECOND, QUANTITY_SALARY_SECOND, \n",
    "              QUANTITY_SALARY_MIN_SECOND, QUANTITY_SALARY_MAX_SECOND, QUANTITY_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Quantity Surveying (JOBLUM) \n",
    "\n",
    "QUANTITY_TITLE_LIST = np.concatenate((QUANTITY_TITLE_FIRST, QUANTITY_TITLE_SECOND))\n",
    "QUANTITY_COMPANY_LIST = np.concatenate((QUANTITY_COMPANY_FIRST, QUANTITY_COMPANY_SECOND))\n",
    "QUANTITY_DATE_LIST = np.concatenate((QUANTITY_DATE_FIRST, QUANTITY_DATE_SECOND))\n",
    "QUANTITY_LOCATION_LIST = np.concatenate((QUANTITY_LOCATION_FIRST, QUANTITY_LOCATION_SECOND))\n",
    "QUANTITY_STATUS_LIST = np.concatenate((QUANTITY_STATUS_FIRST, QUANTITY_STATUS_SECOND))\n",
    "QUANTITY_SALARY_LIST = np.concatenate((QUANTITY_SALARY_FIRST, QUANTITY_SALARY_SECOND))\n",
    "QUANTITY_SALARY_MIN_LIST = np.concatenate((QUANTITY_SALARY_MIN_FIRST, QUANTITY_SALARY_MIN_SECOND))\n",
    "QUANTITY_SALARY_MAX_LIST = np.concatenate((QUANTITY_SALARY_MAX_FIRST, QUANTITY_SALARY_MAX_SECOND))\n",
    "QUANTITY_DESCRIPTION_LIST = np.concatenate((QUANTITY_DESCRIPTION_FIRST, QUANTITY_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Quantity Surveying (JOBLUM) \n",
    "QUANTITY={'Website': \"Joblum\",\n",
    "      'Job Title': QUANTITY_TITLE_LIST, \n",
    "      'Category': \"Quantity Surveying\", \n",
    "      'Company': QUANTITY_COMPANY_LIST, \n",
    "      'Date Posted': QUANTITY_DATE_LIST, \n",
    "      'Location': QUANTITY_LOCATION_LIST, \n",
    "      'Status': QUANTITY_STATUS_LIST, \n",
    "      'Salary': QUANTITY_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': QUANTITY_DESCRIPTION_LIST,\n",
    "      'Min Salary': QUANTITY_SALARY_MIN_LIST,\n",
    "      'Max Salary': QUANTITY_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Engineering\"}\n",
    "QUANTITY_df = pd.DataFrame(data=QUANTITY)\n",
    "QUANTITY_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTITY_df.to_csv ('JOBLUM-QUANTITY.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Science & Technology (JOBLUM) - FIRST HALF\n",
    "\n",
    "SNT_TITLE_FIRST = []\n",
    "SNT_COMPANY_FIRST = []\n",
    "SNT_DATE_FIRST = []\n",
    "SNT_LOCATION_FIRST = []\n",
    "SNT_STATUS_FIRST = []\n",
    "SNT_SALARY_FIRST = []\n",
    "SNT_SALARY_MIN_FIRST = []\n",
    "SNT_SALARY_MAX_FIRST = []\n",
    "SNT_DESCRIPTION_FIRST = []\n",
    "\n",
    "JOBLUM_URLs = 'https://ph.joblum.com/jobs-spec-science-amp-technology?p='\n",
    "soup = getSoup(JOBLUM_URLs)\n",
    "NUM_JOBS = getNumJobs(soup)\n",
    "NUM_PAGES = getNumPages(NUM_JOBS)\n",
    "JOB_LINKS = getLinks(NUM_PAGES, JOBLUM_URLs)\n",
    "FIRST_HALF = math.ceil(NUM_PAGES/2)\n",
    "\n",
    "for i in range(FIRST_HALF):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, SNT_TITLE_FIRST, SNT_COMPANY_FIRST, SNT_DATE_FIRST, \n",
    "              SNT_STATUS_FIRST, SNT_LOCATION_FIRST, SNT_SALARY_FIRST, \n",
    "              SNT_SALARY_MIN_FIRST, SNT_SALARY_MAX_FIRST, SNT_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Science & Technology (JOBLUM) - SECOND HALF\n",
    "\n",
    "SNT_TITLE_SECOND = []\n",
    "SNT_COMPANY_SECOND = []\n",
    "SNT_DATE_SECOND = []\n",
    "SNT_LOCATION_SECOND = []\n",
    "SNT_STATUS_SECOND = []\n",
    "SNT_SALARY_SECOND = []\n",
    "SNT_SALARY_MIN_SECOND = []\n",
    "SNT_SALARY_MAX_SECOND = []\n",
    "SNT_DESCRIPTION_SECOND = []\n",
    "\n",
    "for i in range(FIRST_HALF, NUM_PAGES):\n",
    "    JOBLUM_SOUP = getSoup(JOB_LINKS[i])\n",
    "    URL = getJobURL(JOBLUM_SOUP)\n",
    "    scrapeJob(URL, SNT_TITLE_SECOND, SNT_COMPANY_SECOND, SNT_DATE_SECOND, \n",
    "              SNT_STATUS_SECOND, SNT_LOCATION_SECOND, SNT_SALARY_SECOND, \n",
    "              SNT_SALARY_MIN_SECOND, SNT_SALARY_MAX_SECOND, SNT_DESCRIPTION_FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Scrape data of Science & Technology (JOBLUM) \n",
    "\n",
    "SNT_TITLE_LIST = np.concatenate((SNT_TITLE_FIRST, SNT_TITLE_SECOND))\n",
    "SNT_COMPANY_LIST = np.concatenate((SNT_COMPANY_FIRST, SNT_COMPANY_SECOND))\n",
    "SNT_DATE_LIST = np.concatenate((SNT_DATE_FIRST, SNT_DATE_SECOND))\n",
    "SNT_LOCATION_LIST = np.concatenate((SNT_LOCATION_FIRST, SNT_LOCATION_SECOND))\n",
    "SNT_STATUS_LIST = np.concatenate((SNT_STATUS_FIRST, SNT_STATUS_SECOND))\n",
    "SNT_SALARY_LIST = np.concatenate((SNT_SALARY_FIRST, SNT_SALARY_SECOND))\n",
    "SNT_SALARY_MIN_LIST = np.concatenate((SNT_SALARY_MIN_FIRST, SNT_SALARY_MIN_SECOND))\n",
    "SNT_SALARY_MAX_LIST = np.concatenate((SNT_SALARY_MAX_FIRST, SNT_SALARY_MAX_SECOND))\n",
    "SNT_DESCRIPTION_LIST = np.concatenate((SNT_DESCRIPTION_FIRST, SNT_DESCRIPTION_SECOND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Data Frame for Science & Technology (JOBLUM) \n",
    "SNT={'Website': \"Joblum\",\n",
    "      'Job Title': SNT_TITLE_LIST, \n",
    "      'Category': \"Science & Technology\", \n",
    "      'Company': SNT_COMPANY_LIST, \n",
    "      'Date Posted': SNT_DATE_LIST, \n",
    "      'Location': SNT_LOCATION_LIST, \n",
    "      'Status': SNT_STATUS_LIST, \n",
    "      'Salary': SNT_SALARY_LIST,\n",
    "      'Education': \"Not Specified / In Description\",\n",
    "      'Years of Work Expirience': \"Not Specified / In Description\",\n",
    "      'Job Description': SNT_DESCRIPTION_LIST,\n",
    "      'Min Salary': SNT_SALARY_MIN_LIST,\n",
    "      'Max Salary': SNT_SALARY_MAX_LIST,\n",
    "      'Min Years of Work Expirience': \"Not Specified\",\n",
    "      'Max Years of Work Expirience': \"Not Specified\",\n",
    "      'Field': \"Science\"}\n",
    "SNT_df = pd.DataFrame(data=SNT)\n",
    "SNT_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNT_df.to_csv ('JOBLUM-SNT.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-inspiration",
   "metadata": {},
   "source": [
    "# Data Cleaning (JOBLUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "annoying-wisconsin",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Education</th>\n",
       "      <th>Years of Work Expirience</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>Min Years of Work Expirience</th>\n",
       "      <th>Max Years of Work Expirience</th>\n",
       "      <th>Field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>With Signing Bonus* | Data Visualization Senio...</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Central Luzon, National Capital Reg, Calabarzo...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Go through a faster and more convenient recrui...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Statistician 1</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Philippine National Police Region X - Government</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Northern Mindanao</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : June 11,...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Statistician I</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Municipal Government of Surallah, South Cotaba...</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Soccsksargen</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : June 11,...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Risk Underwriter</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Lightspeed</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>Pasig City</td>\n",
       "      <td>Full Time</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Perks and Benefits Participate in the Lightspe...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Statistician III</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Civil Service Commission - Government</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 31, ...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Mechanic II (34-1998)</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>PHILIPPINE AIR FORCE - Government</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 14, ...</td>\n",
       "      <td>18,251</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Mechanic II (27-1998)</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>PHILIPPINE AIR FORCE - Government</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 14, ...</td>\n",
       "      <td>18,251</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Service Performance Manager</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>1Aviation Groundhandling Services Corporation</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>Pasay City</td>\n",
       "      <td>OJT</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Job Summary Responsible for managing a team to...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Line Mechanic</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>Sumifru (Philippines) Corporation</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>Davao</td>\n",
       "      <td>Full Time</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>The Line Mechanic is responsible for conductin...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Quality Assurance Officer</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>Sumifru (Philippines) Corporation</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>Davao</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>The Quality Assurance Officer is responsible f...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Website                                          Job Title  \\\n",
       "0     Joblum  With Signing Bonus* | Data Visualization Senio...   \n",
       "1     Joblum                                     Statistician 1   \n",
       "2     Joblum                                     Statistician I   \n",
       "3     Joblum                                   Risk Underwriter   \n",
       "4     Joblum                                   Statistician III   \n",
       "...      ...                                                ...   \n",
       "1309  Joblum                     Aircraft Mechanic II (34-1998)   \n",
       "1310  Joblum                     Aircraft Mechanic II (27-1998)   \n",
       "1311  Joblum                        Service Performance Manager   \n",
       "1312  Joblum                                      Line Mechanic   \n",
       "1313  Joblum                          Quality Assurance Officer   \n",
       "\n",
       "                  Category                                            Company  \\\n",
       "0     Actuarial/Statistics                                          Accenture   \n",
       "1     Actuarial/Statistics   Philippine National Police Region X - Government   \n",
       "2     Actuarial/Statistics  Municipal Government of Surallah, South Cotaba...   \n",
       "3     Actuarial/Statistics                                         Lightspeed   \n",
       "4     Actuarial/Statistics              Civil Service Commission - Government   \n",
       "...                    ...                                                ...   \n",
       "1309              Aviation                  PHILIPPINE AIR FORCE - Government   \n",
       "1310              Aviation                  PHILIPPINE AIR FORCE - Government   \n",
       "1311              Aviation      1Aviation Groundhandling Services Corporation   \n",
       "1312              Aviation                  Sumifru (Philippines) Corporation   \n",
       "1313              Aviation                  Sumifru (Philippines) Corporation   \n",
       "\n",
       "     Date Posted                                           Location  \\\n",
       "0     2021-05-29  Central Luzon, National Capital Reg, Calabarzo...   \n",
       "1     2021-05-29                                  Northern Mindanao   \n",
       "2     2021-05-29                                       Soccsksargen   \n",
       "3     2021-05-28                                         Pasig City   \n",
       "4     2021-05-28                               National Capital Reg   \n",
       "...          ...                                                ...   \n",
       "1309  2021-05-12                               National Capital Reg   \n",
       "1310  2021-05-12                               National Capital Reg   \n",
       "1311  2021-05-11                                         Pasay City   \n",
       "1312  2021-05-09                                              Davao   \n",
       "1313  2021-05-09                                              Davao   \n",
       "\n",
       "             Status  Salary                       Education  \\\n",
       "0     Not Specified          Not Specified / In Description   \n",
       "1     Not Specified          Not Specified / In Description   \n",
       "2     Not Specified          Not Specified / In Description   \n",
       "3         Full Time          Not Specified / In Description   \n",
       "4     Not Specified          Not Specified / In Description   \n",
       "...             ...     ...                             ...   \n",
       "1309            OJT  18,251  Not Specified / In Description   \n",
       "1310            OJT  18,251  Not Specified / In Description   \n",
       "1311            OJT          Not Specified / In Description   \n",
       "1312      Full Time          Not Specified / In Description   \n",
       "1313  Not Specified          Not Specified / In Description   \n",
       "\n",
       "            Years of Work Expirience  \\\n",
       "0     Not Specified / In Description   \n",
       "1     Not Specified / In Description   \n",
       "2     Not Specified / In Description   \n",
       "3     Not Specified / In Description   \n",
       "4     Not Specified / In Description   \n",
       "...                              ...   \n",
       "1309  Not Specified / In Description   \n",
       "1310  Not Specified / In Description   \n",
       "1311  Not Specified / In Description   \n",
       "1312  Not Specified / In Description   \n",
       "1313  Not Specified / In Description   \n",
       "\n",
       "                                        Job Description     Min Salary  \\\n",
       "0     Go through a faster and more convenient recrui...  Not Specified   \n",
       "1     Deadline for accepting applications : June 11,...  Not Specified   \n",
       "2     Deadline for accepting applications : June 11,...  Not Specified   \n",
       "3     Perks and Benefits Participate in the Lightspe...  Not Specified   \n",
       "4     Deadline for accepting applications : May 31, ...  Not Specified   \n",
       "...                                                 ...            ...   \n",
       "1309  Deadline for accepting applications : May 14, ...         18,251   \n",
       "1310  Deadline for accepting applications : May 14, ...         18,251   \n",
       "1311  Job Summary Responsible for managing a team to...  Not Specified   \n",
       "1312  The Line Mechanic is responsible for conductin...  Not Specified   \n",
       "1313  The Quality Assurance Officer is responsible f...  Not Specified   \n",
       "\n",
       "         Max Salary Min Years of Work Expirience Max Years of Work Expirience  \\\n",
       "0     Not Specified                Not Specified                Not Specified   \n",
       "1     Not Specified                Not Specified                Not Specified   \n",
       "2     Not Specified                Not Specified                Not Specified   \n",
       "3     Not Specified                Not Specified                Not Specified   \n",
       "4     Not Specified                Not Specified                Not Specified   \n",
       "...             ...                          ...                          ...   \n",
       "1309         18,251                Not Specified                Not Specified   \n",
       "1310         18,251                Not Specified                Not Specified   \n",
       "1311  Not Specified                Not Specified                Not Specified   \n",
       "1312  Not Specified                Not Specified                Not Specified   \n",
       "1313  Not Specified                Not Specified                Not Specified   \n",
       "\n",
       "            Field  \n",
       "0     Mathematics  \n",
       "1     Mathematics  \n",
       "2     Mathematics  \n",
       "3     Mathematics  \n",
       "4     Mathematics  \n",
       "...           ...  \n",
       "1309  Mathematics  \n",
       "1310  Mathematics  \n",
       "1311  Mathematics  \n",
       "1312  Mathematics  \n",
       "1313  Mathematics  \n",
       "\n",
       "[1314 rows x 16 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate all df (JOBLUM)\n",
    "JOBLUM_df = pd.concat([STAT_df, AGRI_df, ARCHI_df, AVI_df, BIOMED_df, BIOTECH_df, \n",
    "                       CHEMENG_df, CHEM_df, CIVILENG_df, CONSTRUCTION_df, DIAGNOSIS_df, \n",
    "                       DOCTOR_df, ELEC_df, ELECENG_df, ELECTRO_df, ELECTROENG_df, ENVI_df, \n",
    "                       ENVIENG_df, NUTRI_df, GEO_df, INDUSENG_df, IT_HARDWARE_df, IT_SYS_df, \n",
    "                       IT_SOFTWARE_df, MAINTENANCE_df, MECH_df, MECHENG_df, NURSE_df, OIL_df, \n",
    "                       OILENG_df, ENG_df, PHARMA_df, QUALITY_df, QUANTITY_df, SNT_df], \n",
    "                      ignore_index=True, sort=False)\n",
    "JOBLUM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "raising-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all test job post (JOBLUM)\n",
    "test_index = JOBLUM_df[JOBLUM_df['Job Title'].str.contains('Test')].index\n",
    "JOBLUM_df = JOBLUM_df.drop(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "early-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_education(description):\n",
    "    eduoutput = (description.replace('/', ''))\n",
    "    education_list1 = ['Bachelor','Degree','BS', 'College graduate', 'University graduate', 'Graduate']\n",
    "    education_list2 = ['Master', 'Post graduate']\n",
    "    if any(x in eduoutput for x in education_list2):\n",
    "        return \"Master's Degree\"\n",
    "    if any(x in eduoutput for x in education_list1):\n",
    "        return \"Bachelor's Degree\"\n",
    "    else:\n",
    "        return \"Not Specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "former-cookie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Education</th>\n",
       "      <th>Years of Work Expirience</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>Min Years of Work Expirience</th>\n",
       "      <th>Max Years of Work Expirience</th>\n",
       "      <th>Field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>With Signing Bonus* | Data Visualization Senio...</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Central Luzon, National Capital Reg, Calabarzo...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Go through a faster and more convenient recrui...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Statistician 1</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Philippine National Police Region X - Government</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Northern Mindanao</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : June 11,...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Statistician I</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Municipal Government of Surallah, South Cotaba...</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>Soccsksargen</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : June 11,...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Risk Underwriter</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Lightspeed</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>Pasig City</td>\n",
       "      <td>Full Time</td>\n",
       "      <td></td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Perks and Benefits Participate in the Lightspe...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Statistician III</td>\n",
       "      <td>Actuarial/Statistics</td>\n",
       "      <td>Civil Service Commission - Government</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 31, ...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Mechanic II (34-1998)</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>PHILIPPINE AIR FORCE - Government</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 14, ...</td>\n",
       "      <td>18,251</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Aircraft Mechanic II (27-1998)</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>PHILIPPINE AIR FORCE - Government</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>National Capital Reg</td>\n",
       "      <td>OJT</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Deadline for accepting applications : May 14, ...</td>\n",
       "      <td>18,251</td>\n",
       "      <td>18,251</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Service Performance Manager</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>1Aviation Groundhandling Services Corporation</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>Pasay City</td>\n",
       "      <td>OJT</td>\n",
       "      <td></td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>Job Summary Responsible for managing a team to...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Line Mechanic</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>Sumifru (Philippines) Corporation</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>Davao</td>\n",
       "      <td>Full Time</td>\n",
       "      <td></td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>The Line Mechanic is responsible for conductin...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>Joblum</td>\n",
       "      <td>Quality Assurance Officer</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>Sumifru (Philippines) Corporation</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>Davao</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td></td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Not Specified / In Description</td>\n",
       "      <td>The Quality Assurance Officer is responsible f...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1310 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Website                                          Job Title  \\\n",
       "0     Joblum  With Signing Bonus* | Data Visualization Senio...   \n",
       "1     Joblum                                     Statistician 1   \n",
       "2     Joblum                                     Statistician I   \n",
       "3     Joblum                                   Risk Underwriter   \n",
       "4     Joblum                                   Statistician III   \n",
       "...      ...                                                ...   \n",
       "1309  Joblum                     Aircraft Mechanic II (34-1998)   \n",
       "1310  Joblum                     Aircraft Mechanic II (27-1998)   \n",
       "1311  Joblum                        Service Performance Manager   \n",
       "1312  Joblum                                      Line Mechanic   \n",
       "1313  Joblum                          Quality Assurance Officer   \n",
       "\n",
       "                  Category                                            Company  \\\n",
       "0     Actuarial/Statistics                                          Accenture   \n",
       "1     Actuarial/Statistics   Philippine National Police Region X - Government   \n",
       "2     Actuarial/Statistics  Municipal Government of Surallah, South Cotaba...   \n",
       "3     Actuarial/Statistics                                         Lightspeed   \n",
       "4     Actuarial/Statistics              Civil Service Commission - Government   \n",
       "...                    ...                                                ...   \n",
       "1309              Aviation                  PHILIPPINE AIR FORCE - Government   \n",
       "1310              Aviation                  PHILIPPINE AIR FORCE - Government   \n",
       "1311              Aviation      1Aviation Groundhandling Services Corporation   \n",
       "1312              Aviation                  Sumifru (Philippines) Corporation   \n",
       "1313              Aviation                  Sumifru (Philippines) Corporation   \n",
       "\n",
       "     Date Posted                                           Location  \\\n",
       "0     2021-05-29  Central Luzon, National Capital Reg, Calabarzo...   \n",
       "1     2021-05-29                                  Northern Mindanao   \n",
       "2     2021-05-29                                       Soccsksargen   \n",
       "3     2021-05-28                                         Pasig City   \n",
       "4     2021-05-28                               National Capital Reg   \n",
       "...          ...                                                ...   \n",
       "1309  2021-05-12                               National Capital Reg   \n",
       "1310  2021-05-12                               National Capital Reg   \n",
       "1311  2021-05-11                                         Pasay City   \n",
       "1312  2021-05-09                                              Davao   \n",
       "1313  2021-05-09                                              Davao   \n",
       "\n",
       "             Status  Salary          Education  \\\n",
       "0     Not Specified          Bachelor's Degree   \n",
       "1     Not Specified          Bachelor's Degree   \n",
       "2     Not Specified          Bachelor's Degree   \n",
       "3         Full Time          Bachelor's Degree   \n",
       "4     Not Specified          Bachelor's Degree   \n",
       "...             ...     ...                ...   \n",
       "1309            OJT  18,251      Not Specified   \n",
       "1310            OJT  18,251      Not Specified   \n",
       "1311            OJT          Bachelor's Degree   \n",
       "1312      Full Time          Bachelor's Degree   \n",
       "1313  Not Specified          Bachelor's Degree   \n",
       "\n",
       "            Years of Work Expirience  \\\n",
       "0     Not Specified / In Description   \n",
       "1     Not Specified / In Description   \n",
       "2     Not Specified / In Description   \n",
       "3     Not Specified / In Description   \n",
       "4     Not Specified / In Description   \n",
       "...                              ...   \n",
       "1309  Not Specified / In Description   \n",
       "1310  Not Specified / In Description   \n",
       "1311  Not Specified / In Description   \n",
       "1312  Not Specified / In Description   \n",
       "1313  Not Specified / In Description   \n",
       "\n",
       "                                        Job Description     Min Salary  \\\n",
       "0     Go through a faster and more convenient recrui...  Not Specified   \n",
       "1     Deadline for accepting applications : June 11,...  Not Specified   \n",
       "2     Deadline for accepting applications : June 11,...  Not Specified   \n",
       "3     Perks and Benefits Participate in the Lightspe...  Not Specified   \n",
       "4     Deadline for accepting applications : May 31, ...  Not Specified   \n",
       "...                                                 ...            ...   \n",
       "1309  Deadline for accepting applications : May 14, ...         18,251   \n",
       "1310  Deadline for accepting applications : May 14, ...         18,251   \n",
       "1311  Job Summary Responsible for managing a team to...  Not Specified   \n",
       "1312  The Line Mechanic is responsible for conductin...  Not Specified   \n",
       "1313  The Quality Assurance Officer is responsible f...  Not Specified   \n",
       "\n",
       "         Max Salary Min Years of Work Expirience Max Years of Work Expirience  \\\n",
       "0     Not Specified                Not Specified                Not Specified   \n",
       "1     Not Specified                Not Specified                Not Specified   \n",
       "2     Not Specified                Not Specified                Not Specified   \n",
       "3     Not Specified                Not Specified                Not Specified   \n",
       "4     Not Specified                Not Specified                Not Specified   \n",
       "...             ...                          ...                          ...   \n",
       "1309         18,251                Not Specified                Not Specified   \n",
       "1310         18,251                Not Specified                Not Specified   \n",
       "1311  Not Specified                Not Specified                Not Specified   \n",
       "1312  Not Specified                Not Specified                Not Specified   \n",
       "1313  Not Specified                Not Specified                Not Specified   \n",
       "\n",
       "            Field  \n",
       "0     Mathematics  \n",
       "1     Mathematics  \n",
       "2     Mathematics  \n",
       "3     Mathematics  \n",
       "4     Mathematics  \n",
       "...           ...  \n",
       "1309  Mathematics  \n",
       "1310  Mathematics  \n",
       "1311  Mathematics  \n",
       "1312  Mathematics  \n",
       "1313  Mathematics  \n",
       "\n",
       "[1310 rows x 16 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JOBLUM_df[\"Education\"] = JOBLUM_df[\"Job Description\"].apply(find_education)\n",
    "JOBLUM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "equal-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOBLUM_df.to_csv ('JOBLUM.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-laptop",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
